{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e37f417-35b1-4a07-b04e-c3605c64ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from parser.utils import load_json, dfs_cardinality, estimate_scan_in_mb\n",
    "from models.feature.single_xgboost_feature import find_top_k_operators, featurize_one_plan, get_top_k_table_by_size\n",
    "from utils.load_brad_trace import load_trace, create_concurrency_dataset, load_trace_all_version\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from models.single.stage import SingleStage\n",
    "from models.concurrency.complex_models import ConcurrentRNN\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcda267a-3fcc-432f-bd0b-acbc375cbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_queries_path = \"/Users/ziniuw/Desktop/research/Data/AWS_trace/mixed_aurora/aurora_mixed_parsed_queries.json\"\n",
    "plans = load_json(parsed_queries_path, namespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80d4313f-35a3-4670-8f18-7a10b91df1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"mixed_aurora\"\n",
    "directory = f\"/Users/ziniuw/Desktop/research/Data/AWS_trace/{folder_name}/\"\n",
    "all_raw_trace, all_trace = load_trace_all_version(directory, 8, concat=True)\n",
    "all_concurrency_df = []\n",
    "for trace in all_trace:\n",
    "    concurrency_df = create_concurrency_dataset(trace, engine=None, pre_exec_interval=200)\n",
    "    all_concurrency_df.append(concurrency_df)\n",
    "concurrency_df = pd.concat(all_concurrency_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5b9d1cb-14a1-41e1-8c29-4f16e8164b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_since_execution_s</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>query_idx</th>\n",
       "      <th>run_time_s</th>\n",
       "      <th>engine</th>\n",
       "      <th>g_offset_since_start</th>\n",
       "      <th>g_offset_since_start_s</th>\n",
       "      <th>g_issue_gap_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-15 19:31:48.824876+00:00</td>\n",
       "      <td>9.645261</td>\n",
       "      <td>00:16</td>\n",
       "      <td>29</td>\n",
       "      <td>110.210543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>2024-02-15 19:31:41.425990+00:00</td>\n",
       "      <td>1.873206</td>\n",
       "      <td>00:03</td>\n",
       "      <td>143</td>\n",
       "      <td>3.958360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>2024-02-15 19:31:43.079819+00:00</td>\n",
       "      <td>2.760294</td>\n",
       "      <td>00:04</td>\n",
       "      <td>135</td>\n",
       "      <td>3.479030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:01.653829</td>\n",
       "      <td>0.887088</td>\n",
       "      <td>0.887088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>2024-02-15 19:31:48.642502+00:00</td>\n",
       "      <td>8.322977</td>\n",
       "      <td>00:13</td>\n",
       "      <td>75</td>\n",
       "      <td>63.228388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:07.216512</td>\n",
       "      <td>6.449771</td>\n",
       "      <td>5.562683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>2024-02-15 19:31:48.316405+00:00</td>\n",
       "      <td>8.388999</td>\n",
       "      <td>00:13</td>\n",
       "      <td>36</td>\n",
       "      <td>0.853417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:06.890415</td>\n",
       "      <td>6.515793</td>\n",
       "      <td>6.515793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            timestamp  time_since_execution_s time_of_day  \\\n",
       "0    2024-02-15 19:31:48.824876+00:00                9.645261       00:16   \n",
       "823  2024-02-15 19:31:41.425990+00:00                1.873206       00:03   \n",
       "2337 2024-02-15 19:31:43.079819+00:00                2.760294       00:04   \n",
       "2338 2024-02-15 19:31:48.642502+00:00                8.322977       00:13   \n",
       "1575 2024-02-15 19:31:48.316405+00:00                8.388999       00:13   \n",
       "\n",
       "      query_idx  run_time_s  engine   g_offset_since_start  \\\n",
       "0            29  110.210543     NaN        0 days 00:00:00   \n",
       "823         143    3.958360     NaN        0 days 00:00:00   \n",
       "2337        135    3.479030     NaN 0 days 00:00:01.653829   \n",
       "2338         75   63.228388     NaN 0 days 00:00:07.216512   \n",
       "1575         36    0.853417     NaN 0 days 00:00:06.890415   \n",
       "\n",
       "      g_offset_since_start_s  g_issue_gap_s  \n",
       "0                   0.000000       0.000000  \n",
       "823                 0.000000       0.000000  \n",
       "2337                0.887088       0.887088  \n",
       "2338                6.449771       5.562683  \n",
       "1575                6.515793       6.515793  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trace[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42fb3b5-f5cf-4c0a-bf49-48218b41abde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43967 10907\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "train_idx = np.random.choice(len(concurrency_df), size=int(0.8 * len(concurrency_df)), replace=False)\n",
    "test_idx = [i for i in range(len(concurrency_df)) if i not in train_idx]\n",
    "train_trace_df = copy.deepcopy(concurrency_df.iloc[train_idx])\n",
    "eval_trace_df = concurrency_df.iloc[test_idx]\n",
    "eval_trace_df = copy.deepcopy(eval_trace_df[eval_trace_df['num_concurrent_queries'] > 0])\n",
    "print(len(train_trace_df), len(eval_trace_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa82df9c-fb54-4a44-b711-393530a8eb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 operators contains 0.9650782102582758 total operators\n"
     ]
    }
   ],
   "source": [
    "ss = SingleStage(use_table_features=True, true_card=True)\n",
    "df = ss.featurize_data(train_trace_df, parsed_queries_path)\n",
    "ss.train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85cfdad2-8fc0-4bd1-b721-379c6e296f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import l1_loss, mse_loss\n",
    "from tqdm import tqdm\n",
    "from models.concurrency.seq_to_seq import RNN, LSTM, TransformerModel\n",
    "from models.feature.complex_rnn_features import (\n",
    "    collate_fn_padding,\n",
    "    collate_fn_padding_transformer,\n",
    "    QueryFeatureSeparatedDataset,\n",
    "    featurize_queries_complex,\n",
    ")\n",
    "\n",
    "\n",
    "def q_loss_func(input, target, min_val=0.001, small_val=5.0, penalty_negative=1e5, lambda_small=0.1):\n",
    "    \"\"\"\n",
    "    :param min_val: the minimal runtime you want the model to predict\n",
    "    :param small_val: q_loss naturally favors small pred/label, put less weight on those values\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    qerror = []\n",
    "    for i in range(len(target)):\n",
    "        # penalty for negative/too small estimates\n",
    "        if (input[i] < min_val).data.numpy():\n",
    "            # influence on loss for a negative estimate is >= penalty_negative constant\n",
    "            q_err = (1 - input[i]) * penalty_negative\n",
    "        # use l1_loss for small values, q_loss would explode\n",
    "        elif (input[i] < small_val).data.numpy() and (target[i] < small_val).data.numpy():\n",
    "            q_err = torch.abs(target[i] - input[i]) * lambda_small\n",
    "        # otherwise normal q error\n",
    "        else:\n",
    "            if (input[i] > target[i]).data.numpy():\n",
    "                q_err = torch.log(input[i]) - torch.log(target[i])\n",
    "            else:\n",
    "                q_err = torch.log(target[i]) - torch.log(input[i])\n",
    "        qerror.append(q_err)\n",
    "    loss = torch.mean(torch.cat(qerror))\n",
    "    return loss\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, layers=3):\n",
    "        super(MLP, self).__init__()\n",
    "        model = []\n",
    "        model.append(nn.Linear(input_dim, hidden_dim))\n",
    "        model.append(nn.ReLU())\n",
    "        for i in range(layers):\n",
    "            model.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            model.append(nn.ReLU())\n",
    "        model.append(nn.Dropout(0.9))\n",
    "        model.append(nn.Linear(hidden_dim, 1))\n",
    "        self.model = nn.Sequential(*model)\n",
    "        self.is_train = True\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        y1 = self.model(x1, x2)\n",
    "        if self.is_train:\n",
    "            pred = self.model(y1, x3)\n",
    "        else:\n",
    "            pred = y1\n",
    "        return torch.maximum(pred, torch.tensor(0.01))\n",
    "\n",
    "\n",
    "class ConcurrentRNN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        stage_model,\n",
    "        input_size,\n",
    "        embedding_dim,\n",
    "        hidden_size,\n",
    "        output_size=1,\n",
    "        num_head=4,\n",
    "        num_layers=4,\n",
    "        batch_size=128,\n",
    "        dropout=0.2,\n",
    "        include_exit=False,\n",
    "        last_output=True,\n",
    "        rnn_type=\"lstm\",\n",
    "    ):\n",
    "        self.stage_model = stage_model\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_head = num_head\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.include_exit = include_exit\n",
    "        self.batch_size = batch_size\n",
    "        self.rnn_type = rnn_type\n",
    "        self.loss_func = None\n",
    "        self.last_output = last_output\n",
    "        if rnn_type == \"vanilla\":\n",
    "            self.model = RNN(input_size, hidden_size, output_size, num_layers)\n",
    "        elif rnn_type == \"lstm\":\n",
    "            self.model = LSTM(\n",
    "                input_size, embedding_dim, hidden_size, output_size, num_layers, dropout, last_output\n",
    "            )\n",
    "        elif rnn_type == \"transformer\":\n",
    "            self.model = TransformerModel(input_size, embedding_dim, num_head, hidden_size, num_layers, dropout, output_size)\n",
    "        else:\n",
    "            # Todo: implement transformer\n",
    "            assert False, f\"unrecognized rnn type: {rnn_type}\"\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        df,\n",
    "        test_df=None,\n",
    "        lr=0.001,\n",
    "        weight_decay=2e-5,\n",
    "        epochs=200,\n",
    "        loss_function=\"l1_loss\",\n",
    "        report_every=5,\n",
    "        val_on_test=False,\n",
    "    ):\n",
    "        self.loss_func = loss_function\n",
    "        predictions = self.stage_model.cache.running_average\n",
    "        single_query_features = dict()\n",
    "        for i, f in enumerate(self.stage_model.all_feature):\n",
    "            single_query_features[i] = f\n",
    "\n",
    "        if val_on_test:\n",
    "            assert (\n",
    "                test_df is not None\n",
    "            ), \"must provide test dataframe to evaluate on test\"\n",
    "            val_df = test_df\n",
    "            train_df = df\n",
    "        else:\n",
    "            # random train-eval split\n",
    "            train_idx = np.random.choice(\n",
    "                len(df), size=int(0.85 * len(df)), replace=False\n",
    "            )\n",
    "            val_idx = [i for i in range(len(df)) if i not in train_idx]\n",
    "            val_df = df.iloc[val_idx]\n",
    "            train_df = df.iloc[train_idx]\n",
    "\n",
    "        val_x, val_y, val_pre_info_length, val_query_idx = featurize_queries_complex(\n",
    "            val_df, predictions, single_query_features, include_exit=self.include_exit\n",
    "        )\n",
    "        train_x, train_y, train_pre_info_length, train_query_idx = featurize_queries_complex(\n",
    "            train_df, predictions, single_query_features, include_exit=self.include_exit\n",
    "        )\n",
    "\n",
    "        train_dataset = QueryFeatureSeparatedDataset(\n",
    "            train_x, train_y, train_pre_info_length, train_query_idx\n",
    "        )\n",
    "        if self.rnn_type == \"transformer\":\n",
    "            collate_fn = collate_fn_padding_transformer()\n",
    "        else:\n",
    "            collate_fn = collate_fn_padding\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "        val_dataset = QueryFeatureSeparatedDataset(val_x, val_y, val_pre_info_length, val_query_idx)\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "        optimizer = optim.Adam(\n",
    "            self.model.parameters(), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        for epoch in range(epochs):\n",
    "            batch_loss = 0\n",
    "            num_batch = 0\n",
    "            self.model.train()\n",
    "            for X, x_lengths, y, pre_info_length, query_idx in train_dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = self.model(X, x_lengths)\n",
    "                y = y.reshape(-1, 1)\n",
    "                if loss_function == \"l1_loss\":\n",
    "                    loss = l1_loss(pred, y)\n",
    "                elif loss_function == \"mse_loss\":\n",
    "                    loss = mse_loss(pred, y)\n",
    "                elif loss_function == \"q_loss\":\n",
    "                    loss = q_loss_func(pred, y)\n",
    "                else:\n",
    "                    assert False, f\"loss function {loss_function} is unrecognized\"\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), 2)\n",
    "                optimizer.step()\n",
    "                batch_loss += loss.item()\n",
    "                num_batch += 1\n",
    "            if epoch % report_every == 0:\n",
    "                train_loss = batch_loss / num_batch\n",
    "                # Todo: implement eval loss\n",
    "                print(\n",
    "                    f\"********Epoch {epoch}, training loss: {train_loss} || evaluation loss: ********\"\n",
    "                )\n",
    "                _ = self.evaluate(val_dataloader, return_per_query=False)\n",
    "\n",
    "    def predict(self, df, return_per_query=True):\n",
    "        predictions = self.stage_model.cache.running_average\n",
    "        single_query_features = dict()\n",
    "        for i, f in enumerate(self.stage_model.all_feature):\n",
    "            single_query_features[i] = f\n",
    "        val_x, val_y, val_pre_info_length, val_query_idx = featurize_queries_complex(\n",
    "            df, predictions, single_query_features, include_exit=self.include_exit\n",
    "        )\n",
    "        val_dataset = QueryFeatureSeparatedDataset(val_x, val_y, val_pre_info_length, val_query_idx)\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn_padding,\n",
    "        )\n",
    "        return self.evaluate(val_dataloader, return_per_query=return_per_query)\n",
    "\n",
    "    def evaluate(self, val_dataloader, return_per_query=False):\n",
    "        self.model.eval()\n",
    "        all_pred = []\n",
    "        all_label = []\n",
    "        all_query_idx = []\n",
    "        for X, x_lengths, y, pre_info_length, query_idx in tqdm(val_dataloader):\n",
    "            pred = self.model(X, x_lengths)\n",
    "            pred = pred.reshape(-1).detach().numpy()\n",
    "            label = y.numpy()\n",
    "            all_pred.append(pred)\n",
    "            all_label.append(label)\n",
    "            all_query_idx.append(query_idx.numpy())\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "        all_pred = np.maximum(all_pred, 0.01)\n",
    "        all_label = np.concatenate(all_label)\n",
    "        all_query_idx = np.concatenate(all_query_idx)\n",
    "        abs_error = np.abs(all_pred - all_label)\n",
    "        q_error = np.maximum(all_pred / all_label, all_label / all_pred)\n",
    "        for p in [50, 90, 95]:\n",
    "            p_a = np.percentile(abs_error, p)\n",
    "            p_q = np.percentile(q_error, p)\n",
    "            print(f\"{p}% absolute error is {p_a}, q-error is {p_q}\")\n",
    "        if return_per_query:\n",
    "            preds_per_query = dict()\n",
    "            labels_per_query = dict()\n",
    "            for i in range(len(all_query_idx)):\n",
    "                q_idx = int(all_query_idx[i])\n",
    "                if q_idx not in preds_per_query:\n",
    "                    preds_per_query[q_idx] = []\n",
    "                    labels_per_query[q_idx] = []\n",
    "                preds_per_query[q_idx].append(all_pred[i])\n",
    "                labels_per_query[q_idx].append(all_label[i])\n",
    "            return preds_per_query, labels_per_query\n",
    "        return all_pred, all_label\n",
    "\n",
    "    def save_model(self, directory):\n",
    "        model_path = os.path.join(directory, f\"{self.rnn_type}_{self.hidden_size}_{self.num_layers}_{self.loss_func}\")\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "    def load_model(self, directory):\n",
    "        model_path = os.path.join(directory, f\"{self.rnn_type}_{self.hidden_size}_{self.num_layers}_{self.loss_func}\")\n",
    "        self.model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06161e91-bb89-4da5-9b06-07c6e265b18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Epoch 0, training loss: 162.67211886755257 || evaluation loss: ********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 86/86 [00:01<00:00, 49.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% absolute error is 4.17140007019043, q-error is 2.1920669078826904\n",
      "90% absolute error is 100.94978942871089, q-error is 8.855450630187985\n",
      "95% absolute error is 175.7823715209958, q-error is 13.901780033111567\n",
      "********Epoch 5, training loss: 2.9005175814205826 || evaluation loss: ********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 86/86 [00:01<00:00, 68.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% absolute error is 3.0919952392578125, q-error is 1.524682641029358\n",
      "90% absolute error is 43.867123413085885, q-error is 4.50993366241455\n",
      "95% absolute error is 101.89528427124, q-error is 7.29283876419066\n",
      "********Epoch 10, training loss: 7.3729971156910405 || evaluation loss: ********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 86/86 [00:01<00:00, 60.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% absolute error is 2.6798553466796875, q-error is 1.4273020029067993\n",
      "90% absolute error is 31.294233322143537, q-error is 4.263333320617674\n",
      "95% absolute error is 74.66441497802728, q-error is 7.143231248855589\n",
      "********Epoch 15, training loss: 5.791060749051529 || evaluation loss: ********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 86/86 [00:01<00:00, 54.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% absolute error is 2.6489524841308594, q-error is 1.4011907577514648\n",
      "90% absolute error is 29.342442321777344, q-error is 3.974243402481079\n",
      "95% absolute error is 64.0548316955564, q-error is 6.5441845893859645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m rnn \u001b[38;5;241m=\u001b[39m ConcurrentRNN(ss, \n\u001b[1;32m      2\u001b[0m                     input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(ss\u001b[38;5;241m.\u001b[39mall_feature[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m7\u001b[39m,\n\u001b[1;32m      3\u001b[0m                     embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      4\u001b[0m                     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m      5\u001b[0m                     num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      6\u001b[0m                    )\n\u001b[0;32m----> 7\u001b[0m rnn\u001b[38;5;241m.\u001b[39mtrain(train_trace_df, eval_trace_df, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_on_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[77], line 174\u001b[0m, in \u001b[0;36mConcurrentRNN.train\u001b[0;34m(self, df, test_df, lr, weight_decay, epochs, loss_function, report_every, val_on_test)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, x_lengths, y, pre_info_length, query_idx \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m    173\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 174\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(X, x_lengths)\n\u001b[1;32m    175\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_function \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/exploration/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/exploration/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/research/perf_prediction/exploration/debug/../models/concurrency/seq_to_seq.py:101\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, x_len, pre_info_length)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output)):\n\u001b[1;32m    100\u001b[0m         y[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(output[i, :\u001b[38;5;28mint\u001b[39m(x_len[i]), :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m     output \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    102\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(output)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, (hn, cn)\n",
      "File \u001b[0;32m~/Desktop/research/perf_prediction/exploration/debug/../models/concurrency/seq_to_seq.py:84\u001b[0m, in \u001b[0;36mmodel_forward\u001b[0;34m(self, x, x_len)\u001b[0m\n\u001b[1;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     83\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n\u001b[0;32m---> 84\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m     86\u001b[0m packed_input \u001b[38;5;241m=\u001b[39m pack_padded_sequence(\n\u001b[1;32m     87\u001b[0m     x, x_len, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     88\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/exploration/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/exploration/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/exploration/lib/python3.11/site-packages/torch/nn/modules/rnn.py:881\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    878\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    879\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n\u001b[1;32m    883\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    884\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn = ConcurrentRNN(ss, \n",
    "                    input_size=len(ss.all_feature[0]) * 2 + 7,\n",
    "                    embedding_dim=128,\n",
    "                    hidden_size=256,\n",
    "                    num_layers=2\n",
    "                   )\n",
    "rnn.train(train_trace_df, eval_trace_df, lr=0.001, loss_function=\"q_loss\", val_on_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13fb34ac-1ea3-4aac-b057-77d43c76173f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds, labels \u001b[38;5;241m=\u001b[39m rnn\u001b[38;5;241m.\u001b[39mpredict(eval_trace_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rnn' is not defined"
     ]
    }
   ],
   "source": [
    "preds, labels = rnn.predict(eval_trace_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972ed179-e8af-47ab-8cb4-2f010ebacf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.model.state_dict(), \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f1b937c-2a52-4865-8bbb-0892cb32e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rnn.stage_model.cache.running_average\n",
    "single_query_features = dict()\n",
    "for i, f in enumerate(rnn.stage_model.all_feature):\n",
    "    single_query_features[i] = f\n",
    "val_x, val_y, val_pre_info_length, val_query_idx = featurize_queries_complex(\n",
    "    eval_trace_df, predictions, single_query_features, include_exit=rnn.include_exit\n",
    ")\n",
    "val_dataset = QueryFeatureSeparatedDataset(val_x, val_y, val_pre_info_length, val_query_idx)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=rnn.batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn_padding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88f2367c-5af4-4f3a-adb9-1fcd2a42c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 52, 117]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for X, x_lengths, y, pre_info_length, query_idx in val_dataloader:\n",
    "    print(X.shape, x_lengths.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f436aae1-2180-4f29-80bf-5a819513503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = []\n",
    "all_label = []\n",
    "all_query_idx = []\n",
    "for X, x_lengths, y, pre_info_length, query_idx in val_dataloader:\n",
    "    pred = rnn.model(X, x_lengths)\n",
    "    pred = pred.reshape(-1).detach().numpy()\n",
    "    label = y.numpy()\n",
    "    all_pred.append(pred)\n",
    "    all_label.append(label)\n",
    "    all_query_idx.append(query_idx.numpy())\n",
    "all_query_idx = np.concatenate(all_query_idx)\n",
    "all_pred = np.concatenate(all_pred)\n",
    "all_pred = np.maximum(all_pred, 0.01)\n",
    "all_label = np.concatenate(all_label)\n",
    "preds_per_query = dict()\n",
    "labels_per_query = dict()\n",
    "for i in range(len(all_query_idx)):\n",
    "    q_idx = int(all_query_idx[i])\n",
    "    if q_idx not in preds_per_query:\n",
    "        preds_per_query[q_idx] = []\n",
    "        labels_per_query[q_idx] = []\n",
    "    preds_per_query[q_idx].append(all_pred[i])\n",
    "    labels_per_query[q_idx].append(all_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78df5c89-980b-4ee2-bf4c-6e8a2e1d74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds_per_query\n",
    "labels = labels_per_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ce7ae9a-7c7b-494e-95fd-f0a1c1c3197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  3.0798578,   3.3398259],\n",
       "       [  3.239337 ,  82.04062  ],\n",
       "       [  3.4771993,   3.0326128],\n",
       "       [  3.734077 ,   3.1415386],\n",
       "       [  3.7889369,   3.1945686],\n",
       "       [  3.8987195,   3.3115742],\n",
       "       [  3.9441261,   3.3261871],\n",
       "       [  4.0396805,   3.157771 ],\n",
       "       [  4.2118206,   8.695362 ],\n",
       "       [  4.2364755,   3.0918634],\n",
       "       [  4.2902536,  15.797157 ],\n",
       "       [  4.3081965,   2.8220966],\n",
       "       [  4.312231 ,   3.8185828],\n",
       "       [  4.317485 ,   3.8665023],\n",
       "       [  4.318064 ,   4.8590245],\n",
       "       [  4.3205786,   3.99297  ],\n",
       "       [  4.3352427,   3.5229752],\n",
       "       [  4.372223 ,   4.0343885],\n",
       "       [  4.4770455,   3.8076053],\n",
       "       [  4.481619 ,  12.0486765],\n",
       "       [  4.5407114,  10.00433  ],\n",
       "       [  4.5709867,  12.684139 ],\n",
       "       [  4.6152844,   3.1525   ],\n",
       "       [  4.629574 ,   3.3944745],\n",
       "       [  4.638817 ,   2.8921077],\n",
       "       [  4.696923 ,   6.6521206],\n",
       "       [  4.7498617,   3.2533658],\n",
       "       [  4.7544203,  93.3347   ],\n",
       "       [  4.7711816,   4.6056075],\n",
       "       [  4.87172  ,   3.5520713],\n",
       "       [  5.0020514,   3.2762587],\n",
       "       [  5.012315 ,   6.0121107],\n",
       "       [  5.097207 ,   6.975404 ],\n",
       "       [  5.115263 ,  65.502625 ],\n",
       "       [  5.1717625,  21.147865 ],\n",
       "       [  5.468131 ,   8.1688   ],\n",
       "       [  5.668705 ,   4.554105 ],\n",
       "       [  5.7102876,   5.862767 ],\n",
       "       [  5.737154 ,   4.3429656],\n",
       "       [  6.1429977,  79.540054 ],\n",
       "       [  6.2744656,   5.9918165],\n",
       "       [  6.614726 ,  12.624166 ],\n",
       "       [  6.6264396,   4.971461 ],\n",
       "       [  7.7576356,   4.92858  ],\n",
       "       [ 11.522484 ,  27.415741 ],\n",
       "       [ 12.172943 ,  13.367556 ],\n",
       "       [ 16.366835 ,  10.253399 ],\n",
       "       [ 17.399954 ,  12.565598 ],\n",
       "       [ 41.33113  ,  45.403458 ],\n",
       "       [ 45.993885 ,  42.062935 ],\n",
       "       [ 55.187897 ,  95.604164 ],\n",
       "       [ 74.77326  ,  70.396706 ],\n",
       "       [137.54404  , 126.10994  ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 210\n",
    "idx = np.argsort(preds[i])\n",
    "print(len(idx))\n",
    "np.stack((np.asarray(preds[i])[idx], np.asarray(labels[i])[idx]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143bf6c1-2927-4f6f-bc2e-8124745b10db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nested Loop', 'Index Scan', 'Gather', 'Finalize Aggregate', 'Partial Aggregate', 'Index Only Scan', 'Seq Scan', 'Parallel Seq Scan', 'Parallel Index Scan', 'Hash', 'Hash Join', 'Merge Join', 'Parallel Hash', 'Parallel Hash Join', 'Sort', 'Gather Merge', 'Materialize', 'Aggregate', 'Finalize GroupAggregate', 'Parallel Index Only Scan']\n"
     ]
    }
   ],
   "source": [
    "get_top_k_table_by_size(plans=plans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e68f48d-66fe-4ea6-8ddd-0977ed2f83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature = []\n",
    "for i in range(len(plans[\"parsed_plans\"])):\n",
    "    plan = plans[\"parsed_plans\"][i]\n",
    "    feature = featurize_one_plan(plan, operators, use_size=True, use_log=True, true_card=False)\n",
    "    all_feature.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ada28dd-3322-471c-9188-e5bcae408d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = [None] * len(concurrency_df)\n",
    "for i, rows in concurrency_df.groupby(\"query_idx\"):\n",
    "    feature = all_feature[i]\n",
    "    row_idx = rows[\"index\"].values\n",
    "    for j in row_idx:\n",
    "        features_df[j] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a350efa9-8f78-42b6-90c6-17c9ac8152bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>query_idx</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>pre_exec_info</th>\n",
       "      <th>concur_info</th>\n",
       "      <th>num_concurrent_queries</th>\n",
       "      <th>concur_info_train</th>\n",
       "      <th>num_concurrent_queries_train</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>110.210543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.210543</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(143, 0.0, 3.958360195159912), (135, 0.887088...</td>\n",
       "      <td>24</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.0, 27.316941050528534, 2.0, 4.5643502748000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>3.958360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.958360</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (135, 0.88708800...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(29, 0.0, 110.210542678833)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 2.0794427916790545, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>3.479030</td>\n",
       "      <td>0.887088</td>\n",
       "      <td>4.366118</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (143, 0.0, 3.958...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (143, 0.0, 3.958...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 14.02569044289473, 1.0, 10.0415088508690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>63.228388</td>\n",
       "      <td>6.449771</td>\n",
       "      <td>69.678159</td>\n",
       "      <td>[(143, 0.0, 3.958360195159912), (135, 0.887088...</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (36, 6.515793, 7...</td>\n",
       "      <td>9</td>\n",
       "      <td>[(29, 0.0, 110.210542678833)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.0, 8.18868967999963, 2.0, 18.64454854869429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>0.853417</td>\n",
       "      <td>6.515793</td>\n",
       "      <td>7.369210</td>\n",
       "      <td>[(143, 0.0, 3.958360195159912), (135, 0.887088...</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (75, 6.449771, 6...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (75, 6.449771, 6...</td>\n",
       "      <td>2</td>\n",
       "      <td>[4.0, 30.921264920644198, 1.0, 2.7725893472395...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  query_idx     runtime  start_time    end_time  \\\n",
       "0      0         29  110.210543    0.000000  110.210543   \n",
       "1      1        143    3.958360    0.000000    3.958360   \n",
       "2      2        135    3.479030    0.887088    4.366118   \n",
       "3      3         75   63.228388    6.449771   69.678159   \n",
       "4      4         36    0.853417    6.515793    7.369210   \n",
       "\n",
       "                                       pre_exec_info  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [(143, 0.0, 3.958360195159912), (135, 0.887088...   \n",
       "4  [(143, 0.0, 3.958360195159912), (135, 0.887088...   \n",
       "\n",
       "                                         concur_info  num_concurrent_queries  \\\n",
       "0  [(143, 0.0, 3.958360195159912), (135, 0.887088...                      24   \n",
       "1  [(29, 0.0, 110.210542678833), (135, 0.88708800...                       2   \n",
       "2  [(29, 0.0, 110.210542678833), (143, 0.0, 3.958...                       2   \n",
       "3  [(29, 0.0, 110.210542678833), (36, 6.515793, 7...                       9   \n",
       "4  [(29, 0.0, 110.210542678833), (75, 6.449771, 6...                       2   \n",
       "\n",
       "                                   concur_info_train  \\\n",
       "0                                                 []   \n",
       "1                      [(29, 0.0, 110.210542678833)]   \n",
       "2  [(29, 0.0, 110.210542678833), (143, 0.0, 3.958...   \n",
       "3                      [(29, 0.0, 110.210542678833)]   \n",
       "4  [(29, 0.0, 110.210542678833), (75, 6.449771, 6...   \n",
       "\n",
       "   num_concurrent_queries_train  \\\n",
       "0                             0   \n",
       "1                             1   \n",
       "2                             2   \n",
       "3                             1   \n",
       "4                             2   \n",
       "\n",
       "                                            features  \n",
       "0  [2.0, 27.316941050528534, 2.0, 4.5643502748000...  \n",
       "1  [0.0, 0.0, 1.0, 2.0794427916790545, 0.0, 0.0, ...  \n",
       "2  [1.0, 14.02569044289473, 1.0, 10.0415088508690...  \n",
       "3  [2.0, 8.18868967999963, 2.0, 18.64454854869429...  \n",
       "4  [4.0, 30.921264920644198, 1.0, 2.7725893472395...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concurrency_df[\"features\"] = features_df\n",
    "concurrency_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5a5704c-4df0-4a97-947b-fc0dadc22641",
   "metadata": {},
   "outputs": [],
   "source": [
    "concurrency_df.to_csv(directory + \"temp.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8413812c-0885-41a2-ba29-1714089572a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(directory + \"temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a998d43-518b-4ce3-aae4-aa130ec3a599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>query_idx</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>pre_exec_info</th>\n",
       "      <th>concur_info</th>\n",
       "      <th>num_concurrent_queries</th>\n",
       "      <th>concur_info_train</th>\n",
       "      <th>num_concurrent_queries_train</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>110.210543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.210543</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(143, 0.0, 3.958360195159912), (135, 0.887088...</td>\n",
       "      <td>24</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.0, 27.316941050528534, 2.0, 4.5643502748000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>3.958360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.958360</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (135, 0.88708800...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(29, 0.0, 110.210542678833)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 2.0794427916790545, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>3.479030</td>\n",
       "      <td>0.887088</td>\n",
       "      <td>4.366118</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (143, 0.0, 3.958...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (143, 0.0, 3.958...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 14.02569044289473, 1.0, 10.0415088508690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>63.228388</td>\n",
       "      <td>6.449771</td>\n",
       "      <td>69.678159</td>\n",
       "      <td>[(143, 0.0, 3.958360195159912), (135, 0.887088...</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (36, 6.515793, 7...</td>\n",
       "      <td>9</td>\n",
       "      <td>[(29, 0.0, 110.210542678833)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.0, 8.18868967999963, 2.0, 18.64454854869429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>0.853417</td>\n",
       "      <td>6.515793</td>\n",
       "      <td>7.369210</td>\n",
       "      <td>[(143, 0.0, 3.958360195159912), (135, 0.887088...</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (75, 6.449771, 6...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(29, 0.0, 110.210542678833), (75, 6.449771, 6...</td>\n",
       "      <td>2</td>\n",
       "      <td>[4.0, 30.921264920644198, 1.0, 2.7725893472395...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  query_idx     runtime  start_time    end_time  \\\n",
       "0      0         29  110.210543    0.000000  110.210543   \n",
       "1      1        143    3.958360    0.000000    3.958360   \n",
       "2      2        135    3.479030    0.887088    4.366118   \n",
       "3      3         75   63.228388    6.449771   69.678159   \n",
       "4      4         36    0.853417    6.515793    7.369210   \n",
       "\n",
       "                                       pre_exec_info  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [(143, 0.0, 3.958360195159912), (135, 0.887088...   \n",
       "4  [(143, 0.0, 3.958360195159912), (135, 0.887088...   \n",
       "\n",
       "                                         concur_info  num_concurrent_queries  \\\n",
       "0  [(143, 0.0, 3.958360195159912), (135, 0.887088...                      24   \n",
       "1  [(29, 0.0, 110.210542678833), (135, 0.88708800...                       2   \n",
       "2  [(29, 0.0, 110.210542678833), (143, 0.0, 3.958...                       2   \n",
       "3  [(29, 0.0, 110.210542678833), (36, 6.515793, 7...                       9   \n",
       "4  [(29, 0.0, 110.210542678833), (75, 6.449771, 6...                       2   \n",
       "\n",
       "                                   concur_info_train  \\\n",
       "0                                                 []   \n",
       "1                      [(29, 0.0, 110.210542678833)]   \n",
       "2  [(29, 0.0, 110.210542678833), (143, 0.0, 3.958...   \n",
       "3                      [(29, 0.0, 110.210542678833)]   \n",
       "4  [(29, 0.0, 110.210542678833), (75, 6.449771, 6...   \n",
       "\n",
       "   num_concurrent_queries_train  \\\n",
       "0                             0   \n",
       "1                             1   \n",
       "2                             2   \n",
       "3                             1   \n",
       "4                             2   \n",
       "\n",
       "                                            features  \n",
       "0  [2.0, 27.316941050528534, 2.0, 4.5643502748000...  \n",
       "1  [0.0, 0.0, 1.0, 2.0794427916790545, 0.0, 0.0, ...  \n",
       "2  [1.0, 14.02569044289473, 1.0, 10.0415088508690...  \n",
       "3  [2.0, 8.18868967999963, 2.0, 18.64454854869429...  \n",
       "4  [4.0, 30.921264920644198, 1.0, 2.7725893472395...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7afcbee-1f66-4a52-94db-9cb155247c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = concurrency_df[\"features\"].iloc[:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74042453-7abd-4891-a569-8639073cf796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        , 27.31694105,  2.        ,  4.56435027,  1.        ,\n",
       "         3.46573622,  1.        ,  2.77258935,  1.        ,  2.77258935,\n",
       "         0.        ,  0.        ,  1.        ,  6.10479325,  0.        ,\n",
       "         0.        ,  1.        , 15.30238121,  1.        ,  6.10479325,\n",
       "         1.        , 14.60034318,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  2.07944279,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        , 12.89763858,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        , 13.30310368,\n",
       "         1.        , 12.81920212,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        , 12.12605494,  0.        ,  0.        ],\n",
       "       [ 1.        , 14.02569044,  1.        , 10.04150885,  1.        ,\n",
       "         5.48063897,  1.        ,  4.78749183,  1.        ,  4.78749183,\n",
       "         0.        ,  0.        ,  1.        ,  6.77992192,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  6.77992192,\n",
       "         1.        , 12.81428266,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 2.        ,  8.18868968,  2.        , 18.64454855,  1.        ,\n",
       "         3.17805425,  1.        ,  2.48490748,  1.        ,  2.48490748,\n",
       "         1.        ,  1.38629686,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  8.39208338,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  2.99573277,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 4.        , 30.92126492,  1.        ,  2.77258935,  1.        ,\n",
       "         4.15888324,  1.        ,  3.46573622,  1.        ,  3.46573622,\n",
       "         3.        ,  8.43555424,  1.        ,  6.1136822 ,  0.        ,\n",
       "         0.        ,  1.        , 10.65414864,  1.        ,  6.1136822 ,\n",
       "         1.        ,  6.82871208,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(list(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62047ba2-627a-44fe-b116-512fec6cacc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plain_content': [],\n",
       " 'plan_parameters': {'op_name': 'Finalize Aggregate',\n",
       "  'est_startup_cost': 1124502.37,\n",
       "  'est_cost': 1124502.38,\n",
       "  'est_card': 1.0,\n",
       "  'est_width': 8.0,\n",
       "  'act_startup_cost': 7210.412,\n",
       "  'act_time': 7213.45,\n",
       "  'act_card': 1.0,\n",
       "  'output_columns': [{'aggregation': 'MIN', 'columns': [100]}],\n",
       "  'act_children_card': 3.0,\n",
       "  'est_children_card': 2.0,\n",
       "  'workers_planned': 0},\n",
       " 'children': [{'plain_content': [],\n",
       "   'plan_parameters': {'op_name': 'Gather',\n",
       "    'est_startup_cost': 1124502.16,\n",
       "    'est_cost': 1124502.37,\n",
       "    'est_card': 2.0,\n",
       "    'est_width': 8.0,\n",
       "    'act_startup_cost': 7210.403,\n",
       "    'act_time': 7213.444,\n",
       "    'act_card': 3.0,\n",
       "    'workers_planned': 0,\n",
       "    'output_columns': [{'aggregation': 'MIN', 'columns': [100]}],\n",
       "    'act_children_card': 1.0,\n",
       "    'est_children_card': 1.0},\n",
       "   'children': [{'plain_content': [],\n",
       "     'plan_parameters': {'op_name': 'Partial Aggregate',\n",
       "      'est_startup_cost': 1123502.16,\n",
       "      'est_cost': 1123502.17,\n",
       "      'est_card': 1.0,\n",
       "      'est_width': 8.0,\n",
       "      'act_startup_cost': 7205.811,\n",
       "      'act_time': 7205.816,\n",
       "      'act_card': 1.0,\n",
       "      'output_columns': [{'aggregation': 'MIN', 'columns': [100]}],\n",
       "      'act_children_card': 25.0,\n",
       "      'est_children_card': 4182.0,\n",
       "      'workers_planned': 2},\n",
       "     'children': [{'plain_content': [],\n",
       "       'plan_parameters': {'op_name': 'Hash Join',\n",
       "        'est_startup_cost': 56.89,\n",
       "        'est_cost': 1123491.7,\n",
       "        'est_card': 4182.0,\n",
       "        'est_width': 8.0,\n",
       "        'act_startup_cost': 174.373,\n",
       "        'act_time': 7205.769,\n",
       "        'act_card': 25.0,\n",
       "        'output_columns': [{'aggregation': 'None', 'columns': [100]}],\n",
       "        'inner_unique': True,\n",
       "        'act_children_card': 175.0,\n",
       "        'est_children_card': 3847575.0,\n",
       "        'workers_planned': 2},\n",
       "       'children': [{'plain_content': [],\n",
       "         'plan_parameters': {'op_name': 'Nested Loop',\n",
       "          'est_startup_cost': 26.25,\n",
       "          'est_cost': 1123449.97,\n",
       "          'est_card': 4205.0,\n",
       "          'est_width': 8.0,\n",
       "          'act_startup_cost': 174.3,\n",
       "          'act_time': 7205.64,\n",
       "          'act_card': 25.0,\n",
       "          'output_columns': [{'aggregation': 'None', 'columns': [100]}],\n",
       "          'inner_unique': True,\n",
       "          'act_children_card': 25.0,\n",
       "          'est_children_card': 4205.0,\n",
       "          'workers_planned': 2},\n",
       "         'children': [{'plain_content': [],\n",
       "           'plan_parameters': {'op_name': 'Nested Loop',\n",
       "            'est_startup_cost': 25.68,\n",
       "            'est_cost': 1096481.91,\n",
       "            'est_card': 4205.0,\n",
       "            'est_width': 16.0,\n",
       "            'act_startup_cost': 171.199,\n",
       "            'act_time': 7082.593,\n",
       "            'act_card': 25.0,\n",
       "            'output_columns': [{'aggregation': 'None', 'columns': [54]},\n",
       "             {'aggregation': 'None', 'columns': [59]}],\n",
       "            'inner_unique': True,\n",
       "            'act_children_card': 0.0,\n",
       "            'est_children_card': 4816.0,\n",
       "            'workers_planned': 2},\n",
       "           'children': [{'plain_content': [],\n",
       "             'plan_parameters': {'op_name': 'Nested Loop',\n",
       "              'est_startup_cost': 25.25,\n",
       "              'est_cost': 1077815.6,\n",
       "              'est_card': 4816.0,\n",
       "              'est_width': 24.0,\n",
       "              'act_startup_cost': 84.199,\n",
       "              'act_time': 4746.434,\n",
       "              'act_card': 2457.0,\n",
       "              'output_columns': [{'aggregation': 'None', 'columns': [55]},\n",
       "               {'aggregation': 'None', 'columns': [54]},\n",
       "               {'aggregation': 'None', 'columns': [59]}],\n",
       "              'act_children_card': 0.0,\n",
       "              'est_children_card': 31455.0,\n",
       "              'workers_planned': 2},\n",
       "             'children': [{'plain_content': [],\n",
       "               'plan_parameters': {'op_name': 'Hash Join',\n",
       "                'est_startup_cost': 24.81,\n",
       "                'est_cost': 856336.52,\n",
       "                'est_card': 31455.0,\n",
       "                'est_width': 16.0,\n",
       "                'act_startup_cost': 56.496,\n",
       "                'act_time': 4216.307,\n",
       "                'act_card': 130541.0,\n",
       "                'output_columns': [{'aggregation': 'None', 'columns': [55]},\n",
       "                 {'aggregation': 'None', 'columns': [54]}],\n",
       "                'inner_unique': True,\n",
       "                'act_children_card': 522164.0,\n",
       "                'est_children_card': 20760543.0,\n",
       "                'workers_planned': 2},\n",
       "               'children': [{'plain_content': [],\n",
       "                 'plan_parameters': {'table': 91,\n",
       "                  'op_name': 'Parallel Seq Scan',\n",
       "                  'est_startup_cost': 0.0,\n",
       "                  'est_cost': 856228.22,\n",
       "                  'est_card': 31599.0,\n",
       "                  'est_width': 24.0,\n",
       "                  'act_startup_cost': 56.452,\n",
       "                  'act_time': 4182.841,\n",
       "                  'act_card': 130541.0,\n",
       "                  'filter_columns': {'column': None,\n",
       "                   'operator': 'AND',\n",
       "                   'literal': None,\n",
       "                   'literal_feature': None,\n",
       "                   'children': [{'column': 48,\n",
       "                     'operator': '>=',\n",
       "                     'literal': '1672658   ',\n",
       "                     'literal_feature': 0,\n",
       "                     'children': []},\n",
       "                    {'column': 57,\n",
       "                     'operator': 'LIKE',\n",
       "                     'literal': \"'%(Sp%ain)%'::text        \",\n",
       "                     'literal_feature': 3,\n",
       "                     'children': []}]},\n",
       "                  'filter_text': \"((movie_companies_brad_source.id >= 1672658) AND ((movie_companies_brad_source.note)::text ~~ '%(Sp%ain)%'::text))\",\n",
       "                  'output_columns': [{'aggregation': 'None', 'columns': [55]},\n",
       "                   {'aggregation': 'None', 'columns': [56]},\n",
       "                   {'aggregation': 'None', 'columns': [54]}],\n",
       "                  'act_children_card': 1,\n",
       "                  'est_children_card': 1,\n",
       "                  'workers_planned': 2},\n",
       "                 'children': [],\n",
       "                 'plan_runtime': 0,\n",
       "                 'is_brad': False},\n",
       "                {'plain_content': [],\n",
       "                 'plan_parameters': {'op_name': 'Hash',\n",
       "                  'est_startup_cost': 16.6,\n",
       "                  'est_cost': 16.6,\n",
       "                  'est_card': 657.0,\n",
       "                  'est_width': 4.0,\n",
       "                  'act_startup_cost': 0.018,\n",
       "                  'act_time': 0.019,\n",
       "                  'act_card': 4.0,\n",
       "                  'output_columns': [{'aggregation': 'None',\n",
       "                    'columns': [143]}],\n",
       "                  'act_children_card': 4.0,\n",
       "                  'est_children_card': 657.0,\n",
       "                  'workers_planned': 2},\n",
       "                 'children': [{'plain_content': [],\n",
       "                   'plan_parameters': {'table': 18,\n",
       "                    'op_name': 'Seq Scan',\n",
       "                    'est_startup_cost': 0.0,\n",
       "                    'est_cost': 16.6,\n",
       "                    'est_card': 657.0,\n",
       "                    'est_width': 4.0,\n",
       "                    'act_startup_cost': 0.013,\n",
       "                    'act_time': 0.014,\n",
       "                    'act_card': 4.0,\n",
       "                    'filter_columns': {'column': 143,\n",
       "                     'operator': 'IS NOT NULL',\n",
       "                     'literal': '         ',\n",
       "                     'literal_feature': 0,\n",
       "                     'children': []},\n",
       "                    'filter_text': '(company_type_brad_source.id IS NOT NULL)',\n",
       "                    'output_columns': [{'aggregation': 'None',\n",
       "                      'columns': [143]}],\n",
       "                    'act_children_card': 1,\n",
       "                    'est_children_card': 1,\n",
       "                    'workers_planned': 2},\n",
       "                   'children': [],\n",
       "                   'plan_runtime': 0,\n",
       "                   'is_brad': False}],\n",
       "                 'plan_runtime': 0,\n",
       "                 'is_brad': False}],\n",
       "               'plan_runtime': 0,\n",
       "               'is_brad': False},\n",
       "              {'plain_content': [],\n",
       "               'plan_parameters': {'table': 93,\n",
       "                'op_name': 'Index Scan',\n",
       "                'est_startup_cost': 0.44,\n",
       "                'est_cost': 7.03,\n",
       "                'est_card': 1.0,\n",
       "                'est_width': 8.0,\n",
       "                'act_startup_cost': 0.003,\n",
       "                'act_time': 0.003,\n",
       "                'act_card': 0.0,\n",
       "                'filter_columns': {'column': None,\n",
       "                 'operator': 'AND',\n",
       "                 'literal': None,\n",
       "                 'literal_feature': None,\n",
       "                 'children': [{'column': 59,\n",
       "                   'operator': '=',\n",
       "                   'literal': 'movie_companies_brad_source.movie_id  ',\n",
       "                   'literal_feature': 0,\n",
       "                   'children': []},\n",
       "                  {'column': 61,\n",
       "                   'operator': 'LIKE',\n",
       "                   'literal': \"'%7.%1%'::text        \",\n",
       "                   'literal_feature': 3,\n",
       "                   'children': []}]},\n",
       "                'filter_text': \"((movie_info_idx_brad_source.info)::text ~~ '%7.%1%'::text)\",\n",
       "                'output_columns': [{'aggregation': 'None', 'columns': [19]},\n",
       "                 {'aggregation': 'None', 'columns': [59]},\n",
       "                 {'aggregation': 'None', 'columns': [60]},\n",
       "                 {'aggregation': 'None', 'columns': [61]},\n",
       "                 {'aggregation': 'None', 'columns': [62]}],\n",
       "                'act_children_card': 1,\n",
       "                'est_children_card': 1,\n",
       "                'workers_planned': 2},\n",
       "               'children': [],\n",
       "               'plan_runtime': 0,\n",
       "               'is_brad': False}],\n",
       "             'plan_runtime': 0,\n",
       "             'is_brad': False},\n",
       "            {'plain_content': [],\n",
       "             'plan_parameters': {'table': 16,\n",
       "              'op_name': 'Index Scan',\n",
       "              'est_startup_cost': 0.43,\n",
       "              'est_cost': 3.88,\n",
       "              'est_card': 1.0,\n",
       "              'est_width': 4.0,\n",
       "              'act_startup_cost': 0.949,\n",
       "              'act_time': 0.949,\n",
       "              'act_card': 0.0,\n",
       "              'filter_columns': {'column': None,\n",
       "               'operator': 'AND',\n",
       "               'literal': None,\n",
       "               'literal_feature': None,\n",
       "               'children': [{'column': 9,\n",
       "                 'operator': '=',\n",
       "                 'literal': 'movie_companies_brad_source.company_id  ',\n",
       "                 'literal_feature': 0,\n",
       "                 'children': []},\n",
       "                {'column': 29,\n",
       "                 'operator': 'NOT LIKE',\n",
       "                 'literal': \"'%[e%s]%'::text         \",\n",
       "                 'literal_feature': 3,\n",
       "                 'children': []}]},\n",
       "              'filter_text': \"((company_name_brad_source.country_code)::text !~~ '%[e%s]%'::text)\",\n",
       "              'output_columns': [{'aggregation': 'None', 'columns': [9]},\n",
       "               {'aggregation': 'None', 'columns': [28]},\n",
       "               {'aggregation': 'None', 'columns': [29]},\n",
       "               {'aggregation': 'None', 'columns': [30]},\n",
       "               {'aggregation': 'None', 'columns': [32]},\n",
       "               {'aggregation': 'None', 'columns': [35]},\n",
       "               {'aggregation': 'None', 'columns': [36]}],\n",
       "              'act_children_card': 1,\n",
       "              'est_children_card': 1,\n",
       "              'workers_planned': 2},\n",
       "             'children': [],\n",
       "             'plan_runtime': 0,\n",
       "             'is_brad': False}],\n",
       "           'plan_runtime': 0,\n",
       "           'is_brad': False},\n",
       "          {'plain_content': [],\n",
       "           'plan_parameters': {'table': 103,\n",
       "            'op_name': 'Index Scan',\n",
       "            'est_startup_cost': 0.56,\n",
       "            'est_cost': 6.4,\n",
       "            'est_card': 1.0,\n",
       "            'est_width': 12.0,\n",
       "            'act_startup_cost': 4.85,\n",
       "            'act_time': 4.85,\n",
       "            'act_card': 1.0,\n",
       "            'filter_columns': {'column': 97,\n",
       "             'operator': '=',\n",
       "             'literal': 'movie_info_idx_brad_source.movie_id  ',\n",
       "             'literal_feature': 0,\n",
       "             'children': []},\n",
       "            'output_columns': [{'aggregation': 'None', 'columns': [97]},\n",
       "             {'aggregation': 'None', 'columns': [98]},\n",
       "             {'aggregation': 'None', 'columns': [99]},\n",
       "             {'aggregation': 'None', 'columns': [100]},\n",
       "             {'aggregation': 'None', 'columns': [92]},\n",
       "             {'aggregation': 'None', 'columns': [101]},\n",
       "             {'aggregation': 'None', 'columns': [102]},\n",
       "             {'aggregation': 'None', 'columns': [103]},\n",
       "             {'aggregation': 'None', 'columns': [104]},\n",
       "             {'aggregation': 'None', 'columns': [105]},\n",
       "             {'aggregation': 'None', 'columns': [106]},\n",
       "             {'aggregation': 'None', 'columns': [107]}],\n",
       "            'act_children_card': 1,\n",
       "            'est_children_card': 1,\n",
       "            'workers_planned': 2},\n",
       "           'children': [],\n",
       "           'plan_runtime': 0,\n",
       "           'is_brad': False}],\n",
       "         'plan_runtime': 0,\n",
       "         'is_brad': False},\n",
       "        {'plain_content': [],\n",
       "         'plan_parameters': {'op_name': 'Hash',\n",
       "          'est_startup_cost': 19.2,\n",
       "          'est_cost': 19.2,\n",
       "          'est_card': 915.0,\n",
       "          'est_width': 4.0,\n",
       "          'act_startup_cost': 0.012,\n",
       "          'act_time': 0.013,\n",
       "          'act_card': 7.0,\n",
       "          'output_columns': [{'aggregation': 'None', 'columns': [146]}],\n",
       "          'act_children_card': 7.0,\n",
       "          'est_children_card': 915.0,\n",
       "          'workers_planned': 2},\n",
       "         'children': [{'plain_content': [],\n",
       "           'plan_parameters': {'table': 87,\n",
       "            'op_name': 'Seq Scan',\n",
       "            'est_startup_cost': 0.0,\n",
       "            'est_cost': 19.2,\n",
       "            'est_card': 915.0,\n",
       "            'est_width': 4.0,\n",
       "            'act_startup_cost': 0.007,\n",
       "            'act_time': 0.008,\n",
       "            'act_card': 7.0,\n",
       "            'filter_columns': {'column': 146,\n",
       "             'operator': 'IS NOT NULL',\n",
       "             'literal': '         ',\n",
       "             'literal_feature': 0,\n",
       "             'children': []},\n",
       "            'filter_text': '(kind_type_brad_source.id IS NOT NULL)',\n",
       "            'output_columns': [{'aggregation': 'None', 'columns': [146]}],\n",
       "            'act_children_card': 1,\n",
       "            'est_children_card': 1,\n",
       "            'workers_planned': 2},\n",
       "           'children': [],\n",
       "           'plan_runtime': 0,\n",
       "           'is_brad': False}],\n",
       "         'plan_runtime': 0,\n",
       "         'is_brad': False}],\n",
       "       'plan_runtime': 0,\n",
       "       'is_brad': False}],\n",
       "     'plan_runtime': 0,\n",
       "     'is_brad': False}],\n",
       "   'plan_runtime': 0,\n",
       "   'is_brad': False}],\n",
       " 'plan_runtime': 4465.240666666667,\n",
       " 'is_brad': False,\n",
       " 'tables': ['kind_type_brad_source',\n",
       "  'company_type_brad_source',\n",
       "  'movie_info_idx_brad_source',\n",
       "  'title_brad_source',\n",
       "  'movie_companies_brad_source',\n",
       "  'company_name_brad_source'],\n",
       " 'num_tables': 6}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans['parsed_plans'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdc26ddf-8f1c-4c6f-8a04-b166174356fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "print(list(my_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b23c9bfa-47ec-401c-a8c0-92590879da75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['parsed_plans', 'parsed_queries', 'sql_queries', 'database_stats', 'run_kwargs', 'skipped', 'blocks_accessed'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fb5a5c-2ba7-4d79-ada5-9e3e0942581f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relname': 'aka_title_brad_source',\n",
       " 'reltuples': 361472.0,\n",
       " 'relpages': 7338,\n",
       " 'relcols': 13}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans[\"database_stats\"][\"table_stats\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6045f74c-b330-4974-85ed-f689d312c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "batch_size = 3\n",
    "seq_lengths = [10, 8, 6]  # Lengths of sequences in the batch\n",
    "max_seq_length = max(seq_lengths)\n",
    "input_data = torch.randn(batch_size, max_seq_length, input_size)  # Random input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51d538f-c74d-4549-b6f7-7284fec2361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_input = pack_padded_sequence(input_data, seq_lengths, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f140522-71fd-41a4-8628-e4983cb4a3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_input.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a34b8afa-1716-4afd-ae9a-9b081408ea49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d446cfaa-35ec-48ef-9d42-419ec8c125aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 0]])\n",
      "tensor([[6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Assuming you have a custom dataset class, replace YourDataset with your actual dataset class\n",
    "class YourDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "# Example sequences (list of tensors)\n",
    "sequences = [torch.tensor([1, 2, 3]), torch.tensor([4, 5]), torch.tensor([6])]\n",
    "\n",
    "# Create a PyTorch dataset\n",
    "dataset = YourDataset(sequences)\n",
    "\n",
    "# Define a collate function to pad sequences\n",
    "def collate_fn(batch):\n",
    "    # Sort batch by sequence length (optional but recommended for efficiency)\n",
    "    batch.sort(key=lambda x: len(x), reverse=True)\n",
    "    # Pad sequences to the maximum length per batch\n",
    "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=0)\n",
    "    return padded_batch\n",
    "\n",
    "# Create a DataLoader with the collate_fn\n",
    "# Adjust batch_size and other DataLoader parameters as needed\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "# Example usage of the DataLoader\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023e2ca-149f-420e-98ab-c86fe9a3db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(np.asarray(1), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7f8f172-2fbb-435e-9b9b-48b89f3c7a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29, 0.0, 110.210542678833), (135, 0.8870880000000001, 4.366118370712281)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concurrency_df[\"concur_info\"].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41ea24f8-1715-487e-832d-ba4e42993a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = concurrency_df[\"concur_info_train\"].iloc[1][0]\n",
    "b = concurrency_df[\"concur_info\"].iloc[1][0]\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "324fa7e4-37f2-4adb-870c-0c62c16d22d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(np.ones(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "302d00b0-69a7-4a7e-b6a1-e44e7e3c8d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.ones(5), torch.ones(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a87bf34e-63c1-43be-a77d-6c18878f2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_key_padding_mask = torch.zeros((5, 10), dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef2b9950-2575-436f-bf92-90ddd1ed62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((5, 10, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "391d9399-a39c-4f33-8708-a81507dd24fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce4b260e-0e22-4396-9c22-877917827688",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([8, 5, 2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c24c016e-178c-4328-a5ea-383e8add8460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 11])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[torch.arange(a.shape[0]), b].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d3a0533-b707-4e9c-80b8-c5c53486fb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 11])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf20e767-fc40-4e61-9bed-95a361010182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_info_length = torch.zeros(10, dtype=int)\n",
    "torch.maximum(pre_info_length, torch.ones(len(pre_info_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85dcee0d-0f9b-4bca-9b1c-783f290e8f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(pre_info_length[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15fd8ac1-fb42-4923-a1a1-a7431d2171af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import l1_loss, mse_loss\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Assuming B is the output of some nn.Module\n",
    "# Example:\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class MyModule2(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyModule2, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x, B):\n",
    "        A_modified = x.clone()  # Detach to prevent gradients from flowing back to A\n",
    "        A_modified[:, 0, :] = B\n",
    "        y = self.linear(A_modified.mean(dim=1))\n",
    "        output = torch.zeros((len(y)+5, 1), requires_grad=False)\n",
    "        output[:len(y)] = y\n",
    "        return output[:len(y)]\n",
    "        \n",
    "# Define A and B\n",
    "l = 10\n",
    "n = 5\n",
    "model1 = MyModule(l, n)\n",
    "\n",
    "model2 = MyModule2(n, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18d52e52-6131-4f96-bb32-c1dc62a6e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth1 = torch.randn(l, n, requires_grad=False) * 10\n",
    "ground_truth2 = torch.randn(n, requires_grad=False) * 10\n",
    "\n",
    "\n",
    "length = 1000\n",
    "training_A = torch.randn(length, l, n)\n",
    "training_B = torch.randn(length, l)\n",
    "\n",
    "def get_label():\n",
    "    temp = torch.matmul(training_B, ground_truth1)\n",
    "    temp2 = training_A.clone()\n",
    "    temp2[:, 0, :] = temp\n",
    "    temp2 = temp2.mean(dim=1)\n",
    "    training_Y = torch.matmul(temp, ground_truth2)\n",
    "    return training_Y\n",
    "training_Y = get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eadf661e-61fe-4dec-b447-02879c6f7a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 5])\n",
      "torch.Size([1000, 1])\n",
      "tensor(nan, grad_fn=<MseLossBackward0>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Backward pass\n",
    "output1 = model1(training_B)\n",
    "print(output1.shape)\n",
    "output2 = model2(training_A, output1)  # Example of using A in another nn.Module\n",
    "\n",
    "print(output2.shape)\n",
    "\n",
    "\n",
    "loss = mse_loss(output2.reshape(-1), training_Y)\n",
    "print(loss)\n",
    "# Backward pass\n",
    "#output.backward(torch.ones_like(output), retain_graph=True)  # Retain the computational graph until B\n",
    "loss.backward()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD([\n",
    "    {'params': model1.parameters()},\n",
    "    {'params': model2.parameters()}\n",
    "], lr=learning_rate)\n",
    "optimizer.step()\n",
    "\n",
    "# Clear gradients\n",
    "optimizer.zero_grad()\n",
    "print(model1.linear.weight.grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c21ceb55-0b35-41d3-8f55-44cbb450dbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(56862.0586, grad_fn=<MseLossBackward0>)\n",
      "tensor(42278.6797, grad_fn=<MseLossBackward0>)\n",
      "tensor(30535.4531, grad_fn=<MseLossBackward0>)\n",
      "tensor(21471.6523, grad_fn=<MseLossBackward0>)\n",
      "tensor(14750.1699, grad_fn=<MseLossBackward0>)\n",
      "tensor(9945.3652, grad_fn=<MseLossBackward0>)\n",
      "tensor(6621.5918, grad_fn=<MseLossBackward0>)\n",
      "tensor(4387.2656, grad_fn=<MseLossBackward0>)\n",
      "tensor(2921.5955, grad_fn=<MseLossBackward0>)\n",
      "tensor(1979.6499, grad_fn=<MseLossBackward0>)\n",
      "tensor(1384.4246, grad_fn=<MseLossBackward0>)\n",
      "tensor(1013.4185, grad_fn=<MseLossBackward0>)\n",
      "tensor(784.6998, grad_fn=<MseLossBackward0>)\n",
      "tensor(644.9218, grad_fn=<MseLossBackward0>)\n",
      "tensor(560.0806, grad_fn=<MseLossBackward0>)\n",
      "tensor(508.8540, grad_fn=<MseLossBackward0>)\n",
      "tensor(478.0446, grad_fn=<MseLossBackward0>)\n",
      "tensor(459.5656, grad_fn=<MseLossBackward0>)\n",
      "tensor(448.4995, grad_fn=<MseLossBackward0>)\n",
      "tensor(441.8748, grad_fn=<MseLossBackward0>)\n",
      "tensor(437.9044, grad_fn=<MseLossBackward0>)\n",
      "tensor(435.5167, grad_fn=<MseLossBackward0>)\n",
      "tensor(434.0715, grad_fn=<MseLossBackward0>)\n",
      "tensor(433.1866, grad_fn=<MseLossBackward0>)\n",
      "tensor(432.6349, grad_fn=<MseLossBackward0>)\n",
      "tensor(432.2813, grad_fn=<MseLossBackward0>)\n",
      "tensor(432.0448, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.8782, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.7528, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.6523, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.5662, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.4889, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.4169, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.3479, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.2808, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.2148, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.0845, grad_fn=<MseLossBackward0>)\n",
      "tensor(431.0200, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.9554, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.8914, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.8270, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.7628, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.6986, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.6346, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.5706, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.5066, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.4426, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.3786, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.3146, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.2507, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.1868, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.1228, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.0588, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.9952, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.9312, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.8675, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.8038, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.7401, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.6764, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.6125, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.5489, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.4851, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.4215, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.3579, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.2942, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.2306, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.1669, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.1035, grad_fn=<MseLossBackward0>)\n",
      "tensor(429.0399, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.9763, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.9129, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.8493, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.7858, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.7224, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.6590, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.5955, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.5321, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.4688, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.4055, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.3421, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.2787, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.2154, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.1521, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.0888, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.0256, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.9623, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.8993, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.8360, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.7727, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.7097, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.6466, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.5835, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.5203, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.4572, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.3942, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.3312, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.2681, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.2052, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.0792, grad_fn=<MseLossBackward0>)\n",
      "tensor(427.0162, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.9533, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.8906, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.8276, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.7646, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.7019, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.6390, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.5763, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.5135, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.4507, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.3879, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.3252, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.2625, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.1998, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.1371, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.0745, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.0118, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.9492, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.8865, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.8241, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.7614, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.6989, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.6365, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.5739, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.5114, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.4489, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.3864, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.3240, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.2617, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.1992, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.1368, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.0746, grad_fn=<MseLossBackward0>)\n",
      "tensor(425.0121, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.9499, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.8875, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.8253, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.7629, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.7007, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.6385, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.5763, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.5141, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.4521, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.3898, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.3278, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.2656, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.2035, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.1414, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.0793, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.0173, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.9553, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.8934, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.8312, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.7693, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.7074, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.6455, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.5835, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.5217, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.4598, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.3980, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.3362, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.2743, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.2125, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.1508, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.0889, grad_fn=<MseLossBackward0>)\n",
      "tensor(423.0273, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.9655, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.9038, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.8422, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.7805, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.7188, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.6572, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.5956, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.5339, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.4724, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.4107, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.3493, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.2878, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.2263, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.1647, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.1033, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.0418, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.9804, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.9192, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.8577, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.7962, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.7349, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.6736, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.6123, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.5510, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.4897, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.4284, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.3672, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.3059, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.2448, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.1834, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.1223, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.0612, grad_fn=<MseLossBackward0>)\n",
      "tensor(421.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.9389, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.8779, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.8168, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.7558, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.6948, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.6337, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.5727, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.5117, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.4508, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.3897, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.3289, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.2679, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.2070, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.1461, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.0852, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.0244, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.9636, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.9026, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.8419, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.7812, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.7204, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.6597, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.5989, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.5382, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.4775, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.4170, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.3563, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.2956, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.2351, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.1746, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.1139, grad_fn=<MseLossBackward0>)\n",
      "tensor(419.0533, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.9928, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.9322, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.8718, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.8112, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.7509, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.6904, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.6299, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.5696, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.5091, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.4488, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.3884, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.3281, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.2678, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.2074, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.1472, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.0869, grad_fn=<MseLossBackward0>)\n",
      "tensor(418.0266, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.9664, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.9061, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.8460, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.7859, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.7256, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.6654, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.6054, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.5453, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.4852, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.4252, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.3651, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.3050, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.2450, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.1851, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.1250, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.0651, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.0051, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.9452, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.8853, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.8254, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.7655, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.7057, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.6457, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.5860, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.5262, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.4664, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.4066, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.3469, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.2872, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.2274, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.1678, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.1081, grad_fn=<MseLossBackward0>)\n",
      "tensor(416.0483, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.9887, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.9291, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.8695, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.8100, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.7503, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.6908, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.6311, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.5716, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.5122, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.4527, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.3932, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.3338, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.2743, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.2149, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.1555, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.0962, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.0368, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.9775, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.9181, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.8589, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.7996, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.7403, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.6810, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.6217, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.5625, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.5033, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.4441, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.3850, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.3258, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.2666, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.2076, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.1485, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.0894, grad_fn=<MseLossBackward0>)\n",
      "tensor(414.0303, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.9713, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.9122, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.8532, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.7942, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.7352, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.6762, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.6173, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.5584, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.4995, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.4406, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.3817, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.3229, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.2641, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.2052, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.1464, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.0876, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.0289, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.9700, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.9113, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.8526, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.7939, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.7353, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.6766, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.6179, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.5593, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.5007, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.4421, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.3835, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.3250, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.2664, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.2079, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.1494, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.0908, grad_fn=<MseLossBackward0>)\n",
      "tensor(412.0323, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.9740, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.9154, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.8571, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.7986, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.7403, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.6819, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.6235, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.5652, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.5069, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.4485, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.3903, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.3320, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.2737, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.2156, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.1573, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.0992, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.0409, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.9828, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.9245, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.8664, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.8083, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.7502, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.6922, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.6341, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.5760, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.5181, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.4601, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.4021, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.3441, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.2860, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.2281, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.1703, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.1122, grad_fn=<MseLossBackward0>)\n",
      "tensor(410.0544, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.9966, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.9387, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.8809, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.8229, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.7651, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.7073, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.6497, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.5919, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.5342, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.4764, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.4187, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.3609, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.3033, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.2458, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.1880, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.1304, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.0728, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.0152, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.9577, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.9001, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.8427, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.7851, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.7275, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.6701, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.6126, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.5551, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.4977, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.4403, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.3829, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.3254, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.2680, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.2107, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.1534, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.0961, grad_fn=<MseLossBackward0>)\n",
      "tensor(408.0388, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.9816, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.9243, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.8670, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.8098, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.7526, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.6953, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.6382, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.5810, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.5238, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.4667, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.4096, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.3525, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.2954, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.2383, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.1812, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.1242, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.0673, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.0102, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.9532, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.8963, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.8394, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.7823, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.7254, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.6685, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.6116, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.5548, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.4980, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.4411, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.3843, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.3274, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.2707, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.2139, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.1571, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.1004, grad_fn=<MseLossBackward0>)\n",
      "tensor(406.0438, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.9871, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.9304, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.8737, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.8170, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.7604, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.7038, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.6472, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.5906, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.5340, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.4774, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.4209, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.3644, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.3078, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.2514, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.1950, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.1385, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.0821, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.0256, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.9692, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.9128, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.8566, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.8002, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.7439, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.6311, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.5749, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.5186, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.4624, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.4062, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.3499, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.2937, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.2376, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.1814, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.1252, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.0692, grad_fn=<MseLossBackward0>)\n",
      "tensor(404.0130, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.9569, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.9007, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.8447, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.7887, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.7325, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.6765, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.6206, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.5645, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.5085, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.4526, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.3967, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.3407, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.2848, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.2288, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.1730, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.1172, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.0613, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.0055, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.9496, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.8939, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.8380, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.7823, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.7265, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.6708, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.6151, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.5594, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.5036, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.4481, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.3924, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.3369, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.2812, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.2255, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.1699, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.1144, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.0588, grad_fn=<MseLossBackward0>)\n",
      "tensor(402.0032, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.9476, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.8922, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.8367, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.7812, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.7258, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.6703, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.6150, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.5596, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.5042, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.4488, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.3933, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.3380, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.2827, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.2274, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.1721, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.1168, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.0616, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.0062, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.9509, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.8958, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.8406, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.7853, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.7302, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.6750, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.6200, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.5648, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.5097, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.4546, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.3996, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.3445, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.2895, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.2344, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.1795, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.1244, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.0694, grad_fn=<MseLossBackward0>)\n",
      "tensor(400.0144, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.9595, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.9045, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.8497, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.7947, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.7398, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.6849, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.6303, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.5753, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.5204, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.4658, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.4110, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.3561, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.3015, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.2467, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.1919, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.1372, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.0826, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.0278, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.9732, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.9185, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.8638, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.8093, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.7548, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.7001, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.6456, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.5911, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.5364, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.4820, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.4275, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.3730, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.3185, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.2641, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.2097, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.1552, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.1007, grad_fn=<MseLossBackward0>)\n",
      "tensor(398.0464, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.9920, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.9376, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.8834, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.8289, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.7746, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.7202, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.6661, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.6118, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.5575, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.5034, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.4491, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.3949, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.3407, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.2865, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.2323, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.1782, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.1241, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.0700, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.0159, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.9618, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.9076, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.8536, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.7996, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.7456, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.6916, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.6376, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.5836, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.5297, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.4757, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.4218, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.3680, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.3139, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.2601, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.2062, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.1523, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.0987, grad_fn=<MseLossBackward0>)\n",
      "tensor(396.0446, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.9909, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.9372, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.8834, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.8297, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.7758, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.7222, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.6684, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.6148, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.5611, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.5074, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.4537, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.4002, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.3465, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.2929, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.2393, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.1858, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.1321, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.0786, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.0251, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.9716, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.9182, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.8646, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.8111, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.7578, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.7043, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.6508, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.5974, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.5441, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.4906, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.3841, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.3307, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.2775, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.2241, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.1708, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.1176, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.0643, grad_fn=<MseLossBackward0>)\n",
      "tensor(394.0112, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.9579, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.9047, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.8514, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.7982, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.7452, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.6920, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.6389, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.5858, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.5326, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.4796, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.4266, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.3734, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.3203, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.2674, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.2144, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.1614, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.1084, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.0025, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.9495, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.8968, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.8438, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.7909, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.7380, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.6851, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.6323, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.5795, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.5266, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.4738, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.4212, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.3683, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.3156, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.2629, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.2101, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.1575, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.1047, grad_fn=<MseLossBackward0>)\n",
      "tensor(392.0521, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.9994, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.9467, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.8941, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.8416, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.7889, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.7364, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.6837, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.6313, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.5787, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.5262, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.4737, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.4212, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.3687, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.3163, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.2638, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.2113, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.1589, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.1064, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.0542, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.0017, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.9494, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.8970, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.8448, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.7924, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.7400, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.6879, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.6355, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.5833, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.5311, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.4789, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.4266, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.3744, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.3223, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.2701, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.2179, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.1657, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.1137, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor(390.0095, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.9574, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.9054, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.8533, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.8013, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.7493, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.6972, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.6453, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.5934, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.5413, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.4894, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.4375, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.3855, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.3336, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.2817, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.2300, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.1781, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.1263, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.0744, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.0226, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.9708, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.9190, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.8672, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.8155, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.7636, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.7120, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.6604, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.6086, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.5570, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.5052, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.4536, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.4020, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.3503, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.2987, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.2473, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.1956, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.1440, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.0925, grad_fn=<MseLossBackward0>)\n",
      "tensor(388.0409, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.9894, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.9380, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.8864, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.8348, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.7835, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.7321, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.6807, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.6292, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.5778, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.5264, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.4750, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.4237, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.3724, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.3211, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.2697, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.2184, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.1671, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.1158, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.0646, grad_fn=<MseLossBackward0>)\n",
      "tensor(387.0133, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.9622, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.9110, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.8597, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.8086, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.7574, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.7062, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.6551, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.6039, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.5529, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.5017, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.4507, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.3997, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.3486, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.2976, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.2464, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.1955, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.1445, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.0935, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.0425, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.9917, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.9406, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.8898, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.8387, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.7879, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.7371, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.6861, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.6353, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.5844, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.5336, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.4829, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.4322, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.3813, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.3305, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.2798, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.2290, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.1783, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.1276, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.0769, grad_fn=<MseLossBackward0>)\n",
      "tensor(385.0262, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.9756, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.9250, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.8743, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.8237, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.7730, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.7224, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.6718, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.6213, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.5708, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.5202, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.4698, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.4193, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.3688, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.3182, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.2679, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.2174, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.1669, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.1164, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.0660, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.0157, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.9653, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.9150, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.8646, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.8143, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.7639, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.7136, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.6633, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.6129, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.5628, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.5125, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.4623, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.4120, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.3618, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.3116, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.2615, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.2113, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.1610, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.1109, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.0609, grad_fn=<MseLossBackward0>)\n",
      "tensor(383.0108, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.9608, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.9106, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.8605, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.8105, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.7603, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.7104, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.6603, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.6104, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.5604, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.5105, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.4604, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.4106, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.3606, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.3107, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.2608, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.2109, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.1610, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.1111, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.0614, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.0114, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.9618, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.9118, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.8622, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.8123, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.7625, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.7127, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.6631, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.6134, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.5636, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.5139, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.4643, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.4145, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.3649, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.3153, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.2658, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.2160, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.1665, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.1170, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.0673, grad_fn=<MseLossBackward0>)\n",
      "tensor(381.0178, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.9683, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.9188, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.8692, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.8198, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.7702, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.7208, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.6713, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.6218, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.5724, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.5230, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.4737, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.4243, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.3750, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.3256, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.2762, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.2269, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.1776, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.1283, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.0790, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.0298, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.9804, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.9311, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.8819, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.8328, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.7835, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.7344, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.6851, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.6360, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.5869, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.5378, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.4887, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.4395, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.3904, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.3413, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.2922, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.2431, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.1941, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.1451, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.0962, grad_fn=<MseLossBackward0>)\n",
      "tensor(379.0471, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.9982, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.9491, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.9002, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.8513, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.8022, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.7534, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.7045, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.6556, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.6068, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.5578, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.5090, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.4602, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.4114, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.3626, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.3138, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.2650, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.2163, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.1676, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.1187, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.0701, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.0213, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.9726, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.9240, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.8753, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.8266, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.7780, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.7293, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.6807, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.6320, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.5835, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.5350, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.4864, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.4378, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.3894, grad_fn=<MseLossBackward0>)\n",
      "tensor(377.3408, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    output1 = model1(training_B)\n",
    "    output2 = model2(training_A, output1)  # Example of using A in another nn.Module    \n",
    "    \n",
    "    loss = mse_loss(output2.reshape(-1), training_Y)\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    # Backward pass\n",
    "    #output.backward(torch.ones_like(output), retain_graph=True)  # Retain the computational graph until B\n",
    "    loss.backward()\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optim.SGD([\n",
    "        {'params': model1.parameters()},\n",
    "        {'params': model2.parameters()}\n",
    "    ], lr=learning_rate)\n",
    "    optimizer.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "251c24c5-5100-472d-b98d-abec041ceff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(10, requires_grad=False)\n",
    "b = torch.ones(5, requires_grad=True)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6c20474-5aa5-4f2a-87c1-db0a2582d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0:5] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "403f2c90-e605-4fcb-8240-4c89c3ff795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = model1(training_B)\n",
    "output2 = model2(training_A, output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "896ab5f6-c0cb-4507-b1a7-a48c367125e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.2346e+02],\n",
       "        [-5.9103e+02],\n",
       "        [ 3.6133e+02],\n",
       "        [ 2.3047e+01],\n",
       "        [ 3.4213e+02],\n",
       "        [-3.9027e+02],\n",
       "        [ 4.2706e+02],\n",
       "        [-4.0829e+02],\n",
       "        [ 8.2597e+02],\n",
       "        [-7.3807e+01],\n",
       "        [-3.1970e+02],\n",
       "        [-1.6464e+01],\n",
       "        [ 4.1696e+02],\n",
       "        [ 4.9313e+02],\n",
       "        [-6.6962e+02],\n",
       "        [ 9.5590e+02],\n",
       "        [-1.0947e+03],\n",
       "        [-5.9370e+01],\n",
       "        [ 4.4486e+02],\n",
       "        [-9.4193e+01],\n",
       "        [-5.4159e+02],\n",
       "        [ 5.8167e+02],\n",
       "        [-2.4766e+02],\n",
       "        [-7.1903e+02],\n",
       "        [ 1.1819e+03],\n",
       "        [ 1.6983e+02],\n",
       "        [ 3.5693e+01],\n",
       "        [-1.7251e+02],\n",
       "        [-4.9521e+02],\n",
       "        [ 4.4691e+01],\n",
       "        [-2.9324e+02],\n",
       "        [-2.6762e+02],\n",
       "        [-1.7327e+02],\n",
       "        [ 1.2206e+03],\n",
       "        [-2.6931e+02],\n",
       "        [-4.4499e+01],\n",
       "        [ 4.2132e+02],\n",
       "        [ 1.2265e+03],\n",
       "        [ 2.6808e+02],\n",
       "        [ 3.8826e+02],\n",
       "        [ 1.3192e+02],\n",
       "        [ 5.8664e+01],\n",
       "        [-4.5859e+02],\n",
       "        [-4.5173e+02],\n",
       "        [ 7.7698e+02],\n",
       "        [-1.1639e+03],\n",
       "        [ 3.4135e+02],\n",
       "        [ 5.3009e+02],\n",
       "        [ 3.8792e+01],\n",
       "        [-2.7847e+02],\n",
       "        [-1.4199e+02],\n",
       "        [-1.7561e+02],\n",
       "        [ 9.3889e+01],\n",
       "        [ 5.6644e+02],\n",
       "        [ 1.3013e+01],\n",
       "        [ 1.3143e+02],\n",
       "        [ 2.5529e+02],\n",
       "        [-1.4498e+02],\n",
       "        [ 1.3577e+03],\n",
       "        [-1.3681e+02],\n",
       "        [ 1.2932e+03],\n",
       "        [ 1.3998e+03],\n",
       "        [ 3.6530e+02],\n",
       "        [-1.0492e+02],\n",
       "        [-8.6817e+02],\n",
       "        [-5.9650e+00],\n",
       "        [-3.3370e+02],\n",
       "        [-9.0318e+02],\n",
       "        [-3.3706e+02],\n",
       "        [ 1.7289e+02],\n",
       "        [-1.3138e+01],\n",
       "        [ 6.1314e+02],\n",
       "        [-3.4270e+02],\n",
       "        [ 1.1040e+02],\n",
       "        [ 1.3262e+02],\n",
       "        [-6.8824e+02],\n",
       "        [ 1.9378e+02],\n",
       "        [-1.2883e+02],\n",
       "        [-1.1064e+02],\n",
       "        [-3.5502e+02],\n",
       "        [ 1.5639e+02],\n",
       "        [-1.5199e+02],\n",
       "        [ 1.1283e+03],\n",
       "        [ 1.2155e+02],\n",
       "        [-5.1073e+00],\n",
       "        [ 2.1208e+02],\n",
       "        [ 1.6928e+02],\n",
       "        [-3.0947e+02],\n",
       "        [-6.1713e+02],\n",
       "        [-1.0757e+02],\n",
       "        [-5.2390e+02],\n",
       "        [-5.4689e+02],\n",
       "        [-5.4634e+02],\n",
       "        [-8.0333e+02],\n",
       "        [ 1.1524e+03],\n",
       "        [-1.1634e+03],\n",
       "        [-4.2032e+02],\n",
       "        [ 7.8046e+02],\n",
       "        [-8.0478e+02],\n",
       "        [ 6.0321e+02],\n",
       "        [ 9.5300e+02],\n",
       "        [-1.4267e+02],\n",
       "        [-1.2423e+02],\n",
       "        [-1.4564e+01],\n",
       "        [ 3.0132e+00],\n",
       "        [ 5.9048e+01],\n",
       "        [-3.2790e+02],\n",
       "        [ 3.8950e+02],\n",
       "        [-6.6212e+02],\n",
       "        [-2.3423e+02],\n",
       "        [ 3.1489e+02],\n",
       "        [-9.1254e+02],\n",
       "        [-2.1364e+02],\n",
       "        [-2.7745e+02],\n",
       "        [-1.0048e+03],\n",
       "        [ 4.3722e+02],\n",
       "        [-8.3159e+01],\n",
       "        [ 1.5816e+02],\n",
       "        [ 6.2627e+02],\n",
       "        [-5.4817e+02],\n",
       "        [ 4.6654e+02],\n",
       "        [ 1.4279e+02],\n",
       "        [-3.7922e+02],\n",
       "        [-9.0793e+01],\n",
       "        [-1.0143e+01],\n",
       "        [ 8.2012e+02],\n",
       "        [ 6.1509e+01],\n",
       "        [ 4.1208e+02],\n",
       "        [ 6.2458e+02],\n",
       "        [-1.7617e+03],\n",
       "        [ 5.9510e+02],\n",
       "        [-6.7224e+01],\n",
       "        [ 1.5247e+02],\n",
       "        [-4.2086e+02],\n",
       "        [-1.9766e+02],\n",
       "        [ 1.6792e+02],\n",
       "        [-6.3632e+02],\n",
       "        [-3.0831e+02],\n",
       "        [ 3.7174e+02],\n",
       "        [ 5.0955e+02],\n",
       "        [-7.4887e+02],\n",
       "        [ 8.4623e+02],\n",
       "        [-3.9031e+02],\n",
       "        [ 1.1497e+03],\n",
       "        [-1.7072e+02],\n",
       "        [ 7.9399e+02],\n",
       "        [ 6.1923e+01],\n",
       "        [ 7.8529e+02],\n",
       "        [-1.9829e+02],\n",
       "        [ 2.4237e+02],\n",
       "        [-3.6761e+02],\n",
       "        [ 8.4175e+01],\n",
       "        [-4.3890e+01],\n",
       "        [ 5.3422e+01],\n",
       "        [-1.8128e+02],\n",
       "        [ 5.0694e+02],\n",
       "        [-2.4608e+01],\n",
       "        [-5.8895e+02],\n",
       "        [-9.4301e+02],\n",
       "        [-2.8399e+01],\n",
       "        [ 1.9294e+02],\n",
       "        [ 1.4690e+02],\n",
       "        [ 3.9095e+02],\n",
       "        [-1.2429e+03],\n",
       "        [-2.1131e+02],\n",
       "        [ 4.0578e+02],\n",
       "        [ 4.0275e+02],\n",
       "        [ 9.7614e+02],\n",
       "        [ 4.6738e+02],\n",
       "        [ 1.7352e+02],\n",
       "        [ 1.5878e+03],\n",
       "        [-6.4047e+02],\n",
       "        [ 5.3481e+02],\n",
       "        [ 7.4811e+02],\n",
       "        [-3.4517e+02],\n",
       "        [-1.0656e+02],\n",
       "        [ 3.1967e+02],\n",
       "        [ 4.0469e+02],\n",
       "        [-1.5588e+02],\n",
       "        [-5.0594e+02],\n",
       "        [-4.3000e+02],\n",
       "        [ 3.8559e+02],\n",
       "        [-9.4166e+02],\n",
       "        [-1.9632e+02],\n",
       "        [ 3.0459e+01],\n",
       "        [-5.8081e+02],\n",
       "        [ 7.0824e+02],\n",
       "        [ 3.2680e+01],\n",
       "        [-8.2199e+02],\n",
       "        [-2.4013e+02],\n",
       "        [-2.9106e+02],\n",
       "        [ 4.1142e+02],\n",
       "        [-1.3875e+02],\n",
       "        [-1.1817e+03],\n",
       "        [ 4.3305e+02],\n",
       "        [ 1.3741e+02],\n",
       "        [ 1.6331e+02],\n",
       "        [-9.2693e+01],\n",
       "        [ 1.3968e+03],\n",
       "        [-2.3447e+02],\n",
       "        [ 2.8441e+01],\n",
       "        [-8.3420e+02],\n",
       "        [ 6.4263e+02],\n",
       "        [ 8.7212e+02],\n",
       "        [ 5.2323e+01],\n",
       "        [-8.8289e+02],\n",
       "        [ 6.6757e+02],\n",
       "        [-4.1934e+02],\n",
       "        [ 1.1662e+02],\n",
       "        [ 6.7879e+01],\n",
       "        [ 2.8874e+02],\n",
       "        [-9.1995e+02],\n",
       "        [ 4.7917e+01],\n",
       "        [-1.2370e+03],\n",
       "        [-1.1969e+02],\n",
       "        [ 4.8559e+02],\n",
       "        [-5.0609e+02],\n",
       "        [ 7.5846e+02],\n",
       "        [-7.5863e+01],\n",
       "        [ 2.6624e+02],\n",
       "        [ 1.3749e+02],\n",
       "        [-1.8476e+02],\n",
       "        [-1.0618e+03],\n",
       "        [-3.2708e+01],\n",
       "        [-3.1282e+02],\n",
       "        [-1.4634e+02],\n",
       "        [-4.9782e+02],\n",
       "        [-3.4073e+02],\n",
       "        [-1.4135e+02],\n",
       "        [ 6.2435e+02],\n",
       "        [-7.1714e+02],\n",
       "        [ 7.0367e+02],\n",
       "        [ 1.1045e+03],\n",
       "        [ 3.4996e+02],\n",
       "        [ 5.4798e+01],\n",
       "        [-8.0649e+02],\n",
       "        [ 2.3149e+02],\n",
       "        [ 4.5323e+02],\n",
       "        [ 4.9647e+02],\n",
       "        [-4.5806e+02],\n",
       "        [ 5.5852e+02],\n",
       "        [-4.0371e+02],\n",
       "        [-9.7762e+01],\n",
       "        [-8.2099e+02],\n",
       "        [-5.6800e+02],\n",
       "        [ 2.1408e+02],\n",
       "        [-1.1584e+03],\n",
       "        [ 7.8549e+02],\n",
       "        [-2.4199e+02],\n",
       "        [ 1.2246e+02],\n",
       "        [ 2.1064e+01],\n",
       "        [ 6.3891e+02],\n",
       "        [ 1.7101e+02],\n",
       "        [ 8.5603e+01],\n",
       "        [-9.6165e+02],\n",
       "        [-7.5744e+02],\n",
       "        [-4.1819e+02],\n",
       "        [-1.0036e+02],\n",
       "        [-1.4058e+02],\n",
       "        [-4.8807e+02],\n",
       "        [ 7.5329e+02],\n",
       "        [ 2.8194e+02],\n",
       "        [ 9.1097e+02],\n",
       "        [ 1.4977e+02],\n",
       "        [ 3.5259e+02],\n",
       "        [-1.1136e+01],\n",
       "        [-2.2018e+01],\n",
       "        [ 1.0553e+03],\n",
       "        [ 5.3666e+01],\n",
       "        [ 1.5412e+02],\n",
       "        [-8.4238e+01],\n",
       "        [ 9.1592e+01],\n",
       "        [ 8.9481e+02],\n",
       "        [ 6.6296e+02],\n",
       "        [-2.2377e+01],\n",
       "        [ 2.8956e+01],\n",
       "        [ 3.9435e+02],\n",
       "        [ 3.4371e+02],\n",
       "        [ 8.5862e+02],\n",
       "        [-6.5719e+02],\n",
       "        [ 3.1881e+02],\n",
       "        [-1.9172e+02],\n",
       "        [-3.2133e+01],\n",
       "        [-2.9775e+02],\n",
       "        [ 2.3058e+02],\n",
       "        [-1.8525e+02],\n",
       "        [ 3.2729e+02],\n",
       "        [-5.0630e+02],\n",
       "        [ 2.0653e+02],\n",
       "        [ 9.4704e+02],\n",
       "        [-1.8565e+02],\n",
       "        [-2.6549e+02],\n",
       "        [-2.9981e+02],\n",
       "        [ 4.7729e+01],\n",
       "        [ 4.0183e+02],\n",
       "        [ 4.0603e+02],\n",
       "        [ 8.0014e+02],\n",
       "        [-9.4956e+02],\n",
       "        [-6.9375e+02],\n",
       "        [-2.0496e+02],\n",
       "        [-1.1542e+03],\n",
       "        [ 5.8513e+01],\n",
       "        [-4.1623e+02],\n",
       "        [ 1.3465e+03],\n",
       "        [-5.4658e+02],\n",
       "        [-3.1584e+02],\n",
       "        [ 1.3081e+02],\n",
       "        [-6.2326e+01],\n",
       "        [-4.2398e+01],\n",
       "        [-1.3858e+03],\n",
       "        [-3.7687e+02],\n",
       "        [ 2.7133e+01],\n",
       "        [-4.9843e+02],\n",
       "        [ 1.3068e+02],\n",
       "        [-1.6196e+02],\n",
       "        [-2.2960e+02],\n",
       "        [-9.2119e+01],\n",
       "        [-6.7872e+02],\n",
       "        [-6.3429e+02],\n",
       "        [-2.0522e+02],\n",
       "        [ 5.6967e+02],\n",
       "        [-7.1216e+01],\n",
       "        [-1.3062e+02],\n",
       "        [-3.4517e+02],\n",
       "        [-3.7834e+02],\n",
       "        [-4.6639e+02],\n",
       "        [-2.0765e+02],\n",
       "        [-4.2757e+01],\n",
       "        [-3.6271e+02],\n",
       "        [ 1.0417e+02],\n",
       "        [-2.2006e+02],\n",
       "        [-3.3236e+02],\n",
       "        [ 3.8673e+02],\n",
       "        [-7.0712e+02],\n",
       "        [-2.7722e+02],\n",
       "        [-1.1263e+02],\n",
       "        [-7.9208e+02],\n",
       "        [-8.4003e+02],\n",
       "        [-5.3609e+02],\n",
       "        [-4.4933e+02],\n",
       "        [-3.6617e+02],\n",
       "        [-7.3880e+02],\n",
       "        [ 7.4509e+02],\n",
       "        [-3.3414e+02],\n",
       "        [ 5.4896e+02],\n",
       "        [-4.7283e+02],\n",
       "        [ 4.9019e+02],\n",
       "        [-9.3883e+02],\n",
       "        [ 4.7717e+02],\n",
       "        [ 6.9388e+02],\n",
       "        [-4.1946e+02],\n",
       "        [ 4.1112e+02],\n",
       "        [-6.1182e+01],\n",
       "        [ 7.3343e+02],\n",
       "        [ 2.1952e+02],\n",
       "        [-9.2346e+02],\n",
       "        [-9.8104e+01],\n",
       "        [-4.6647e+02],\n",
       "        [ 4.5318e+02],\n",
       "        [-3.8263e+02],\n",
       "        [ 3.7489e+02],\n",
       "        [ 9.9289e+02],\n",
       "        [ 6.5034e+01],\n",
       "        [-1.5985e+02],\n",
       "        [ 7.6548e+02],\n",
       "        [ 7.1685e+02],\n",
       "        [-1.0419e+01],\n",
       "        [-1.5419e+01],\n",
       "        [-1.2146e+03],\n",
       "        [-4.5104e+02],\n",
       "        [ 2.5634e+02],\n",
       "        [-4.2795e+02],\n",
       "        [ 1.0731e+03],\n",
       "        [ 3.6597e+02],\n",
       "        [-9.1870e+02],\n",
       "        [ 9.4156e+02],\n",
       "        [ 3.6797e+02],\n",
       "        [ 3.4163e+00],\n",
       "        [ 2.6943e+02],\n",
       "        [-1.1149e+03],\n",
       "        [-4.0242e+02],\n",
       "        [ 1.0026e+03],\n",
       "        [-1.2240e+03],\n",
       "        [ 1.2435e+02],\n",
       "        [ 6.1629e+01],\n",
       "        [-1.2201e+02],\n",
       "        [ 4.7646e+02],\n",
       "        [ 2.5487e+02],\n",
       "        [-5.7595e+02],\n",
       "        [-1.5702e+00],\n",
       "        [ 1.4727e+03],\n",
       "        [ 1.1810e+03],\n",
       "        [-2.0823e+02],\n",
       "        [ 4.7983e+02],\n",
       "        [ 8.2243e+02],\n",
       "        [ 6.8063e+02],\n",
       "        [ 1.9899e+02],\n",
       "        [-9.1925e+01],\n",
       "        [ 9.2503e+02],\n",
       "        [-5.5788e+02],\n",
       "        [-4.5645e+02],\n",
       "        [ 5.0211e+02],\n",
       "        [ 7.3320e-01],\n",
       "        [ 9.5368e+02],\n",
       "        [ 2.3046e+02],\n",
       "        [-5.3136e+02],\n",
       "        [ 4.0986e+02],\n",
       "        [ 2.5893e+02],\n",
       "        [ 4.5150e+02],\n",
       "        [ 5.3563e+02],\n",
       "        [-1.2172e+02],\n",
       "        [ 1.8186e+01],\n",
       "        [ 2.0194e+03],\n",
       "        [-2.9428e+02],\n",
       "        [-9.8720e+02],\n",
       "        [-1.5542e+02],\n",
       "        [ 8.4379e+01],\n",
       "        [-1.1533e+02],\n",
       "        [-6.1716e+02],\n",
       "        [ 4.0643e+01],\n",
       "        [-3.8489e+02],\n",
       "        [-7.1845e+01],\n",
       "        [-5.5638e+02],\n",
       "        [ 4.2334e+02],\n",
       "        [ 5.5297e+02],\n",
       "        [ 3.5540e+00],\n",
       "        [ 1.2249e+03],\n",
       "        [ 3.5817e+02],\n",
       "        [-4.9838e+01],\n",
       "        [ 7.3658e+02],\n",
       "        [-7.5136e+02],\n",
       "        [-6.8524e+02],\n",
       "        [-3.5566e+02],\n",
       "        [ 4.2251e+02],\n",
       "        [-5.0421e+02],\n",
       "        [ 3.5090e+02],\n",
       "        [ 1.1813e+02],\n",
       "        [-6.5206e+02],\n",
       "        [-2.3407e+02],\n",
       "        [ 9.5898e+02],\n",
       "        [ 5.5126e+00],\n",
       "        [ 1.1158e+03],\n",
       "        [-1.0661e+03],\n",
       "        [-4.2754e+02],\n",
       "        [ 4.5012e+02],\n",
       "        [ 1.8473e+02],\n",
       "        [-5.3173e+02],\n",
       "        [-1.0964e+02],\n",
       "        [-3.5264e+02],\n",
       "        [-9.8857e+01],\n",
       "        [ 2.6027e+02],\n",
       "        [-6.6806e+02],\n",
       "        [ 3.5675e+02],\n",
       "        [-5.5624e+02],\n",
       "        [-1.1922e+03],\n",
       "        [-1.1391e+03],\n",
       "        [ 7.5597e+02],\n",
       "        [ 1.3974e+02],\n",
       "        [-6.3630e+02],\n",
       "        [-2.1188e+02],\n",
       "        [ 3.5642e+02],\n",
       "        [-9.1123e+02],\n",
       "        [-5.9444e+02],\n",
       "        [-1.1940e+02],\n",
       "        [-7.7917e+02],\n",
       "        [-8.2299e+02],\n",
       "        [ 1.3687e+02],\n",
       "        [ 1.6259e+02],\n",
       "        [ 6.2478e+02],\n",
       "        [-3.0659e+02],\n",
       "        [-1.7026e+01],\n",
       "        [ 3.4237e+02],\n",
       "        [-1.5333e+02],\n",
       "        [ 8.0078e+02],\n",
       "        [ 3.3128e+02],\n",
       "        [-4.7170e+02],\n",
       "        [ 1.0517e+03],\n",
       "        [-1.2847e+02],\n",
       "        [-1.2930e+02],\n",
       "        [ 6.7195e+01],\n",
       "        [-2.9187e+02],\n",
       "        [-1.0485e+02],\n",
       "        [ 1.8114e+02],\n",
       "        [ 1.0012e+02],\n",
       "        [-6.6520e+02],\n",
       "        [-4.1372e+02],\n",
       "        [ 9.0745e+02],\n",
       "        [ 1.2199e+01],\n",
       "        [-3.1170e+02],\n",
       "        [-8.6701e+02],\n",
       "        [-5.3622e+02],\n",
       "        [ 2.3692e+02],\n",
       "        [ 9.4482e+02],\n",
       "        [-2.6859e+01],\n",
       "        [-7.1065e+01],\n",
       "        [-8.8631e+02],\n",
       "        [-2.6831e+01],\n",
       "        [ 5.9987e+02],\n",
       "        [-4.5534e+02],\n",
       "        [-1.7496e+02],\n",
       "        [ 4.5726e+02],\n",
       "        [-3.1813e+02],\n",
       "        [ 5.4439e+01],\n",
       "        [ 1.3978e+03],\n",
       "        [ 6.0877e+01],\n",
       "        [-1.7331e+03],\n",
       "        [ 7.1945e+02],\n",
       "        [ 7.6462e+01],\n",
       "        [-8.2332e+02],\n",
       "        [ 1.8160e+02],\n",
       "        [-8.7903e+01],\n",
       "        [ 2.7135e+02],\n",
       "        [-9.2597e+01],\n",
       "        [-1.4884e+02],\n",
       "        [-4.4810e+02],\n",
       "        [-9.3040e+01],\n",
       "        [-9.7188e+01],\n",
       "        [-2.7855e+02],\n",
       "        [ 3.2709e+02],\n",
       "        [-5.5320e+02],\n",
       "        [-7.2096e+02],\n",
       "        [-6.4513e+02],\n",
       "        [ 6.4761e+01],\n",
       "        [-4.5550e+01],\n",
       "        [-3.6217e+02],\n",
       "        [ 1.1117e+03],\n",
       "        [-4.7659e+02],\n",
       "        [-2.2037e+01],\n",
       "        [ 2.6609e+02],\n",
       "        [ 9.9932e+02],\n",
       "        [-1.4347e+02],\n",
       "        [-1.5796e+02],\n",
       "        [-3.8991e+02],\n",
       "        [-1.3159e+03],\n",
       "        [ 9.1350e+02],\n",
       "        [-3.3877e+02],\n",
       "        [ 2.9303e+02],\n",
       "        [-1.3996e+03],\n",
       "        [ 7.9876e+02],\n",
       "        [ 7.5258e+02],\n",
       "        [ 1.5533e+02],\n",
       "        [-4.9840e+02],\n",
       "        [-3.5526e+02],\n",
       "        [ 1.2112e+02],\n",
       "        [-3.4098e+02],\n",
       "        [ 5.4809e+02],\n",
       "        [-6.8204e+02],\n",
       "        [ 1.8342e+02],\n",
       "        [ 3.1078e+00],\n",
       "        [ 6.9360e+02],\n",
       "        [ 2.6250e+02],\n",
       "        [ 8.1301e+02],\n",
       "        [-7.8931e+02],\n",
       "        [ 8.1638e+02],\n",
       "        [-6.9000e+02],\n",
       "        [-3.4630e+02],\n",
       "        [-6.8485e+02],\n",
       "        [-4.4412e+02],\n",
       "        [-1.9844e+02],\n",
       "        [-1.1209e+02],\n",
       "        [-8.1906e+01],\n",
       "        [ 5.0947e+02],\n",
       "        [ 1.1871e+01],\n",
       "        [-1.6994e+02],\n",
       "        [ 9.5450e+01],\n",
       "        [-1.0371e+03],\n",
       "        [ 5.8136e+01],\n",
       "        [ 2.2122e+02],\n",
       "        [ 5.8957e+02],\n",
       "        [-1.0396e+03],\n",
       "        [ 6.3019e+02],\n",
       "        [-5.5061e+01],\n",
       "        [ 1.3562e+02],\n",
       "        [ 3.3621e+02],\n",
       "        [ 2.6688e+01],\n",
       "        [ 1.9747e+02],\n",
       "        [-8.4020e+02],\n",
       "        [-1.1019e+03],\n",
       "        [-8.2577e+02],\n",
       "        [ 2.0450e+02],\n",
       "        [ 7.1782e+02],\n",
       "        [-5.2031e+02],\n",
       "        [ 4.1882e+02],\n",
       "        [-1.7589e+02],\n",
       "        [ 2.7421e+02],\n",
       "        [-8.6868e+02],\n",
       "        [ 6.6168e+02],\n",
       "        [ 1.4799e+03],\n",
       "        [-2.2690e+02],\n",
       "        [-1.2492e+03],\n",
       "        [-5.7021e+01],\n",
       "        [-2.0628e+02],\n",
       "        [-8.6173e+01],\n",
       "        [-3.2945e+02],\n",
       "        [-9.9445e+02],\n",
       "        [-5.4439e+02],\n",
       "        [ 1.1799e+03],\n",
       "        [ 2.0563e+02],\n",
       "        [-9.5513e+02],\n",
       "        [-8.9845e+02],\n",
       "        [ 1.7146e+03],\n",
       "        [ 3.2818e+02],\n",
       "        [-7.1482e+02],\n",
       "        [ 2.5324e+02],\n",
       "        [ 2.9709e+02],\n",
       "        [ 3.0144e+02],\n",
       "        [-2.6847e+02],\n",
       "        [ 3.5827e+02],\n",
       "        [ 3.2197e+02],\n",
       "        [ 9.5287e+02],\n",
       "        [-1.4586e+03],\n",
       "        [-1.0814e+03],\n",
       "        [ 2.0963e+01],\n",
       "        [ 8.3621e+02],\n",
       "        [ 3.1077e+02],\n",
       "        [-6.7226e+02],\n",
       "        [-3.9894e+02],\n",
       "        [ 4.5736e+02],\n",
       "        [-9.9485e+02],\n",
       "        [-4.1454e+01],\n",
       "        [ 3.4706e+02],\n",
       "        [ 7.0246e+02],\n",
       "        [-4.8055e+02],\n",
       "        [-8.5635e+02],\n",
       "        [ 4.2324e+02],\n",
       "        [-1.5310e+02],\n",
       "        [ 2.8153e+02],\n",
       "        [-3.5085e+02],\n",
       "        [ 5.3237e+02],\n",
       "        [ 4.0099e+02],\n",
       "        [-9.9271e+02],\n",
       "        [-5.6218e+02],\n",
       "        [-1.0815e+03],\n",
       "        [ 1.5624e+02],\n",
       "        [ 2.3147e+02],\n",
       "        [ 3.1700e+02],\n",
       "        [ 1.8501e+02],\n",
       "        [ 3.8918e+02],\n",
       "        [ 3.6096e+02],\n",
       "        [ 2.3535e+01],\n",
       "        [ 6.5341e+02],\n",
       "        [-6.8233e+02],\n",
       "        [ 1.3551e+01],\n",
       "        [-7.4192e+02],\n",
       "        [ 2.2672e+02],\n",
       "        [ 2.3903e+01],\n",
       "        [ 5.8832e+02],\n",
       "        [-2.7196e+02],\n",
       "        [ 4.5630e+02],\n",
       "        [-6.9259e+02],\n",
       "        [ 3.4637e+02],\n",
       "        [-2.6786e+02],\n",
       "        [ 1.0345e+02],\n",
       "        [-3.9179e+02],\n",
       "        [ 1.4255e+02],\n",
       "        [ 6.2678e+02],\n",
       "        [ 3.1186e+02],\n",
       "        [-8.3817e+02],\n",
       "        [ 7.0568e+02],\n",
       "        [-8.7413e+02],\n",
       "        [ 2.2779e+02],\n",
       "        [ 4.1136e+01],\n",
       "        [-7.4543e+02],\n",
       "        [-4.1088e+02],\n",
       "        [-9.5744e+01],\n",
       "        [ 5.4331e+02],\n",
       "        [ 3.8559e+01],\n",
       "        [ 3.0849e+00],\n",
       "        [-1.7844e+02],\n",
       "        [-4.2364e+02],\n",
       "        [-1.7508e+02],\n",
       "        [ 2.0657e+03],\n",
       "        [ 6.1235e+02],\n",
       "        [ 9.0450e+02],\n",
       "        [-8.1392e+02],\n",
       "        [-4.6130e+02],\n",
       "        [ 1.6634e+02],\n",
       "        [ 4.0636e+02],\n",
       "        [-7.2895e+02],\n",
       "        [-5.1245e+02],\n",
       "        [-2.7626e+02],\n",
       "        [-3.7220e+02],\n",
       "        [ 5.4108e+02],\n",
       "        [ 5.6388e+02],\n",
       "        [-3.6249e+02],\n",
       "        [ 4.2406e+02],\n",
       "        [-2.8505e+02],\n",
       "        [-2.0647e+02],\n",
       "        [-6.3056e+02],\n",
       "        [ 1.0548e+02],\n",
       "        [ 4.0182e+01],\n",
       "        [ 1.1910e+03],\n",
       "        [ 2.6330e+02],\n",
       "        [-7.5241e+02],\n",
       "        [-1.7205e+02],\n",
       "        [ 1.1829e+03],\n",
       "        [-6.7154e+02],\n",
       "        [ 3.1090e+02],\n",
       "        [-3.5877e+02],\n",
       "        [-5.3783e+02],\n",
       "        [ 6.2487e+02],\n",
       "        [-6.6233e+02],\n",
       "        [-8.0699e+02],\n",
       "        [ 8.7632e+02],\n",
       "        [ 3.3604e+02],\n",
       "        [-4.3233e+02],\n",
       "        [ 1.9877e+02],\n",
       "        [ 6.3615e+02],\n",
       "        [ 4.7215e+02],\n",
       "        [-3.7453e+02],\n",
       "        [-8.0797e+01],\n",
       "        [ 2.9736e+02],\n",
       "        [-3.5475e+02],\n",
       "        [-2.5535e+02],\n",
       "        [-7.4103e+02],\n",
       "        [ 6.1858e+01],\n",
       "        [-3.9653e+02],\n",
       "        [-9.0432e+02],\n",
       "        [ 2.7512e+02],\n",
       "        [ 5.9729e+02],\n",
       "        [ 2.2334e+02],\n",
       "        [-2.9711e+02],\n",
       "        [-6.1507e+02],\n",
       "        [-1.4252e+01],\n",
       "        [-1.4294e+02],\n",
       "        [ 8.0707e+01],\n",
       "        [ 5.6200e-01],\n",
       "        [ 4.4004e+02],\n",
       "        [ 5.4007e+02],\n",
       "        [-6.4838e+02],\n",
       "        [-2.3835e+02],\n",
       "        [ 2.1716e+02],\n",
       "        [ 1.2085e+02],\n",
       "        [ 2.7598e+02],\n",
       "        [ 1.3661e+02],\n",
       "        [ 2.4515e+02],\n",
       "        [ 4.7392e+02],\n",
       "        [ 9.9988e+02],\n",
       "        [ 9.3317e+02],\n",
       "        [ 1.1354e+03],\n",
       "        [-8.8330e+01],\n",
       "        [ 1.0473e+02],\n",
       "        [ 9.0061e+02],\n",
       "        [ 4.6728e+02],\n",
       "        [ 6.6200e+02],\n",
       "        [-3.5476e+02],\n",
       "        [ 8.5434e+02],\n",
       "        [-2.3240e+01],\n",
       "        [-2.7104e+02],\n",
       "        [-2.1878e+01],\n",
       "        [-3.2521e+02],\n",
       "        [-3.1545e+02],\n",
       "        [ 2.1939e+02],\n",
       "        [ 4.6849e+02],\n",
       "        [-5.4357e+02],\n",
       "        [-3.9813e+02],\n",
       "        [-1.2224e+03],\n",
       "        [-1.6298e+03],\n",
       "        [ 6.2743e+02],\n",
       "        [ 8.4716e+02],\n",
       "        [ 6.5638e+02],\n",
       "        [ 1.0354e+02],\n",
       "        [ 7.0624e+01],\n",
       "        [ 1.9815e+02],\n",
       "        [-2.4281e+02],\n",
       "        [ 3.1935e+02],\n",
       "        [ 1.3448e+02],\n",
       "        [-1.9279e+02],\n",
       "        [ 1.8904e+02],\n",
       "        [-1.1995e+03],\n",
       "        [-9.3271e+02],\n",
       "        [ 3.8384e+02],\n",
       "        [-3.3701e+02],\n",
       "        [ 5.3302e+02],\n",
       "        [-3.5463e+02],\n",
       "        [ 3.6975e+02],\n",
       "        [ 2.3905e+02],\n",
       "        [-6.8130e+02],\n",
       "        [-1.1042e+02],\n",
       "        [ 3.6416e+02],\n",
       "        [-3.6955e+01],\n",
       "        [-3.1306e+02],\n",
       "        [ 1.4441e+03],\n",
       "        [ 6.4211e+02],\n",
       "        [-6.9209e+02],\n",
       "        [ 5.3527e+02],\n",
       "        [ 7.6800e+02],\n",
       "        [ 3.5756e+01],\n",
       "        [-6.0197e+02],\n",
       "        [-1.0087e+03],\n",
       "        [ 4.0524e+02],\n",
       "        [-3.5400e+02],\n",
       "        [ 1.0980e+02],\n",
       "        [ 6.4348e+01],\n",
       "        [ 3.4189e+02],\n",
       "        [ 7.1406e+02],\n",
       "        [-9.5107e+02],\n",
       "        [-2.0598e+01],\n",
       "        [ 1.0871e+02],\n",
       "        [-1.4923e+02],\n",
       "        [-7.2622e+02],\n",
       "        [-5.7540e+02],\n",
       "        [-2.6264e+02],\n",
       "        [ 1.2853e+03],\n",
       "        [-4.8716e+02],\n",
       "        [-4.1280e+02],\n",
       "        [-1.8988e+02],\n",
       "        [-4.7951e+02],\n",
       "        [-1.1112e+03],\n",
       "        [ 7.8931e+02],\n",
       "        [-4.9308e+02],\n",
       "        [-8.6022e+01],\n",
       "        [-8.1155e+02],\n",
       "        [-2.7917e+02],\n",
       "        [-1.0543e+03],\n",
       "        [-3.9161e+02],\n",
       "        [-5.9051e+01],\n",
       "        [ 1.4165e+02],\n",
       "        [ 9.4772e+01],\n",
       "        [-2.9071e+02],\n",
       "        [ 4.3591e+02],\n",
       "        [ 2.3396e+02],\n",
       "        [-3.5415e+02],\n",
       "        [-4.9328e+02],\n",
       "        [-3.3658e+02],\n",
       "        [ 1.3195e+02],\n",
       "        [ 4.8424e+02],\n",
       "        [ 5.4796e+01],\n",
       "        [-2.4196e+02],\n",
       "        [-8.9671e+02],\n",
       "        [ 1.1519e+03],\n",
       "        [ 4.0180e+02],\n",
       "        [ 2.3716e+02],\n",
       "        [ 2.1746e+02],\n",
       "        [-2.0512e+02],\n",
       "        [ 1.1376e+03],\n",
       "        [-1.0643e+03],\n",
       "        [-2.4151e+02],\n",
       "        [ 7.1003e+02],\n",
       "        [ 1.7547e+01],\n",
       "        [-2.8297e+01],\n",
       "        [-2.9249e+02],\n",
       "        [ 7.7671e+02],\n",
       "        [ 1.5560e+02],\n",
       "        [ 4.9702e+02],\n",
       "        [ 4.7229e+02],\n",
       "        [-9.7054e+02],\n",
       "        [ 2.8128e+02],\n",
       "        [-1.5030e+03],\n",
       "        [ 6.4798e+02],\n",
       "        [-4.3998e+02],\n",
       "        [-4.8407e+02],\n",
       "        [ 5.1213e+02],\n",
       "        [-6.3398e+02],\n",
       "        [ 4.1902e+02],\n",
       "        [-5.4577e+02],\n",
       "        [ 3.7019e+02],\n",
       "        [ 4.0967e+02],\n",
       "        [-1.3206e+02],\n",
       "        [-8.5781e+02],\n",
       "        [ 3.8177e+02],\n",
       "        [ 4.0979e+02],\n",
       "        [-1.1252e+03],\n",
       "        [ 2.8855e+02],\n",
       "        [ 2.7498e+02],\n",
       "        [ 3.0541e+02],\n",
       "        [ 2.3967e+02],\n",
       "        [-1.9080e+02],\n",
       "        [ 2.1751e+02],\n",
       "        [ 1.2824e+03],\n",
       "        [ 3.6332e+01],\n",
       "        [-7.5145e+02],\n",
       "        [-1.0811e+03],\n",
       "        [ 2.1362e+02],\n",
       "        [-1.3299e+02],\n",
       "        [-2.0075e+01],\n",
       "        [-9.0766e+02],\n",
       "        [ 3.1251e+02],\n",
       "        [ 3.6462e+02],\n",
       "        [-4.1944e+02],\n",
       "        [-9.9831e+02],\n",
       "        [-1.2321e+02],\n",
       "        [-4.6829e+01],\n",
       "        [-2.6817e+02],\n",
       "        [ 4.4036e+01],\n",
       "        [-9.3012e+02],\n",
       "        [ 1.3874e+02],\n",
       "        [ 3.1002e+02],\n",
       "        [-1.6430e+02],\n",
       "        [-1.3937e+02],\n",
       "        [-1.7740e+02],\n",
       "        [ 6.7935e+02],\n",
       "        [ 3.4069e+02],\n",
       "        [-2.6778e+02],\n",
       "        [-3.2540e+02],\n",
       "        [-1.4814e+02],\n",
       "        [ 1.8093e+03],\n",
       "        [-6.9002e+02],\n",
       "        [ 5.1947e+02],\n",
       "        [-2.2398e+02],\n",
       "        [-5.6145e+02],\n",
       "        [ 6.7857e+02],\n",
       "        [ 4.9336e+02],\n",
       "        [ 4.8027e+01],\n",
       "        [-4.6987e+02],\n",
       "        [-1.1422e+03],\n",
       "        [ 3.6082e+02],\n",
       "        [ 6.9460e+02],\n",
       "        [ 1.7381e+02],\n",
       "        [-2.5877e+02],\n",
       "        [-4.5526e+02],\n",
       "        [ 6.2414e+01],\n",
       "        [-1.1084e+03],\n",
       "        [-4.3412e+02],\n",
       "        [ 1.2052e+03],\n",
       "        [-3.8721e+02],\n",
       "        [ 4.0397e+02],\n",
       "        [-4.0518e+02],\n",
       "        [ 1.1677e+02],\n",
       "        [-5.5653e+02],\n",
       "        [ 5.4423e+02],\n",
       "        [-1.8984e+02],\n",
       "        [-4.3301e+02],\n",
       "        [ 7.7545e+01],\n",
       "        [ 5.1335e+02],\n",
       "        [ 1.4436e+03],\n",
       "        [-7.7461e+02],\n",
       "        [ 1.2825e+02],\n",
       "        [-9.6895e+02],\n",
       "        [ 5.8097e+02],\n",
       "        [-2.6932e+02],\n",
       "        [ 3.8379e+02],\n",
       "        [ 4.8682e+02],\n",
       "        [ 3.5097e+02],\n",
       "        [ 7.0244e+02],\n",
       "        [-4.1567e+02],\n",
       "        [ 3.6341e+02],\n",
       "        [-3.4579e+02],\n",
       "        [ 2.6835e+02],\n",
       "        [-2.2407e+02],\n",
       "        [ 4.2302e+02],\n",
       "        [ 5.4311e+01],\n",
       "        [ 2.8335e+02],\n",
       "        [-4.0550e+02],\n",
       "        [ 2.6909e+02],\n",
       "        [ 7.8963e+02],\n",
       "        [-1.2717e+03],\n",
       "        [-1.9348e+02],\n",
       "        [-1.3094e+03],\n",
       "        [-1.2058e+03],\n",
       "        [ 7.4021e+02],\n",
       "        [-8.1162e+02],\n",
       "        [ 8.5157e+02],\n",
       "        [ 2.7468e+02],\n",
       "        [ 9.8677e+02],\n",
       "        [ 3.2832e+02],\n",
       "        [ 3.9229e+02],\n",
       "        [ 3.8259e+02],\n",
       "        [-1.4297e+03],\n",
       "        [-2.2180e+02],\n",
       "        [-1.7341e+02],\n",
       "        [-2.0372e+02],\n",
       "        [ 5.2988e+01],\n",
       "        [ 5.9473e+01],\n",
       "        [-4.8667e+02],\n",
       "        [-2.3866e+02],\n",
       "        [ 6.4991e+02],\n",
       "        [ 2.0419e+02],\n",
       "        [-4.8614e+02],\n",
       "        [ 4.4633e+02],\n",
       "        [-2.0558e+02],\n",
       "        [-1.2055e+03],\n",
       "        [-5.5892e+01],\n",
       "        [ 8.0230e+02],\n",
       "        [ 6.2818e+02],\n",
       "        [ 9.3867e+01],\n",
       "        [-5.5690e+02],\n",
       "        [-1.0364e+01],\n",
       "        [-1.0963e+02],\n",
       "        [ 5.2053e+02],\n",
       "        [-7.5285e+02],\n",
       "        [ 1.6107e+01],\n",
       "        [-4.0603e+02],\n",
       "        [-2.4686e+02],\n",
       "        [-7.0290e+01],\n",
       "        [-4.6369e+02],\n",
       "        [ 9.2724e+01],\n",
       "        [ 2.2228e+02],\n",
       "        [ 1.5772e+02],\n",
       "        [-8.6192e+00],\n",
       "        [-1.1353e+02],\n",
       "        [ 1.6876e+02],\n",
       "        [ 4.7606e+02],\n",
       "        [ 9.0874e+02],\n",
       "        [-4.7950e+02],\n",
       "        [ 4.4563e+02],\n",
       "        [-3.8098e+02],\n",
       "        [-5.9762e+01],\n",
       "        [-3.4851e+02],\n",
       "        [ 1.4268e+03]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8ed1254-3981-4a16-ac8d-53c96bed6a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8.6309e+02, -6.0070e+02,  3.7279e+02, -5.2874e+00,  3.4174e+02,\n",
       "        -4.1005e+02,  3.8836e+02, -3.9748e+02,  8.3635e+02, -8.6381e+01,\n",
       "        -3.3652e+02, -3.0860e+01,  3.8735e+02,  4.9341e+02, -6.9179e+02,\n",
       "         9.4613e+02, -1.0771e+03, -3.4364e+01,  4.1431e+02, -9.3627e+01,\n",
       "        -5.2933e+02,  5.6566e+02, -2.7008e+02, -7.2234e+02,  1.1920e+03,\n",
       "         1.3399e+02,  5.9456e+01, -1.7833e+02, -4.8907e+02,  5.3351e+01,\n",
       "        -2.9161e+02, -2.8650e+02, -1.5382e+02,  1.2014e+03, -2.7481e+02,\n",
       "        -3.4673e+01,  4.1682e+02,  1.2285e+03,  2.7759e+02,  3.8001e+02,\n",
       "         1.5427e+02,  4.8381e+01, -4.6552e+02, -4.3498e+02,  7.9393e+02,\n",
       "        -1.1762e+03,  3.2600e+02,  5.4239e+02,  1.1846e+01, -2.8549e+02,\n",
       "        -1.5275e+02, -1.6591e+02,  1.0382e+02,  5.6746e+02,  2.5248e+01,\n",
       "         1.5879e+02,  2.4320e+02, -1.3353e+02,  1.3669e+03, -1.3951e+02,\n",
       "         1.3122e+03,  1.4095e+03,  3.4844e+02, -1.1643e+02, -8.7602e+02,\n",
       "        -8.4981e+00, -3.4938e+02, -9.0152e+02, -3.2832e+02,  1.6293e+02,\n",
       "        -2.6770e+01,  6.3711e+02, -3.7439e+02,  1.2477e+02,  1.1586e+02,\n",
       "        -6.4493e+02,  2.0608e+02, -1.4965e+02, -9.9593e+01, -3.5947e+02,\n",
       "         1.5519e+02, -1.2053e+02,  1.1194e+03,  9.2466e+01,  2.7197e+01,\n",
       "         1.8872e+02,  1.7456e+02, -2.9397e+02, -6.4179e+02, -9.7123e+01,\n",
       "        -4.9793e+02, -5.2605e+02, -5.0001e+02, -8.3662e+02,  1.1646e+03,\n",
       "        -1.1578e+03, -4.2701e+02,  7.5739e+02, -7.8883e+02,  6.3543e+02,\n",
       "         9.5327e+02, -1.0651e+02, -1.2095e+02, -9.8910e+00, -1.4087e+01,\n",
       "         6.0560e+01, -3.0946e+02,  3.7684e+02, -6.7926e+02, -2.3954e+02,\n",
       "         3.0471e+02, -8.7254e+02, -2.3140e+02, -2.6149e+02, -9.7728e+02,\n",
       "         4.1898e+02, -7.2303e+01,  1.3932e+02,  5.9835e+02, -5.2604e+02,\n",
       "         4.1779e+02,  1.4224e+02, -3.6683e+02, -6.7855e+01, -2.5968e+01,\n",
       "         7.9339e+02,  8.1295e+01,  4.1112e+02,  6.2785e+02, -1.7611e+03,\n",
       "         6.0702e+02, -5.5384e+01,  1.5148e+02, -4.6962e+02, -1.9859e+02,\n",
       "         1.6759e+02, -6.3220e+02, -2.8955e+02,  3.5193e+02,  5.2457e+02,\n",
       "        -7.4151e+02,  8.4464e+02, -4.0614e+02,  1.1507e+03, -1.5909e+02,\n",
       "         8.3210e+02,  8.4458e+01,  7.9895e+02, -2.0564e+02,  2.3784e+02,\n",
       "        -3.4068e+02,  9.5506e+01, -1.7454e+01,  7.5535e+01, -2.0050e+02,\n",
       "         4.9810e+02, -3.6789e+01, -5.8926e+02, -9.4851e+02, -1.5492e+01,\n",
       "         2.0672e+02,  1.6595e+02,  3.8158e+02, -1.2839e+03, -1.8320e+02,\n",
       "         4.0624e+02,  3.8761e+02,  9.5634e+02,  4.6369e+02,  1.6513e+02,\n",
       "         1.5539e+03, -6.0533e+02,  5.0848e+02,  7.3011e+02, -3.4658e+02,\n",
       "        -1.1837e+02,  3.3607e+02,  4.1601e+02, -1.6393e+02, -5.2540e+02,\n",
       "        -4.2323e+02,  3.8239e+02, -9.4679e+02, -1.7646e+02,  3.7193e+01,\n",
       "        -5.8218e+02,  6.4838e+02,  1.6608e+01, -7.9458e+02, -2.2836e+02,\n",
       "        -2.9090e+02,  4.4205e+02, -1.4077e+02, -1.1744e+03,  4.4088e+02,\n",
       "         1.3846e+02,  1.7477e+02, -1.1664e+02,  1.3907e+03, -2.3876e+02,\n",
       "         2.1341e+01, -8.3993e+02,  6.6334e+02,  8.8274e+02,  5.0751e+01,\n",
       "        -8.6873e+02,  6.4095e+02, -3.9365e+02,  9.8285e+01,  8.4197e+01,\n",
       "         2.8220e+02, -9.2532e+02,  3.6835e+01, -1.2645e+03, -1.3260e+02,\n",
       "         4.8777e+02, -5.6409e+02,  7.7319e+02, -8.4211e+01,  2.5600e+02,\n",
       "         1.8746e+02, -1.8075e+02, -1.0722e+03,  2.0221e-01, -3.1626e+02,\n",
       "        -1.4896e+02, -4.8648e+02, -3.3703e+02, -1.8644e+02,  6.1822e+02,\n",
       "        -7.2257e+02,  7.3345e+02,  1.1059e+03,  3.3048e+02,  3.2904e+01,\n",
       "        -7.7318e+02,  2.4174e+02,  4.4749e+02,  4.8421e+02, -4.3766e+02,\n",
       "         5.5284e+02, -4.0563e+02, -1.0979e+02, -8.1884e+02, -5.4731e+02,\n",
       "         2.3520e+02, -1.1894e+03,  7.6184e+02, -2.4574e+02,  9.8572e+01,\n",
       "         2.9169e+01,  6.2880e+02,  1.8430e+02,  6.9437e+01, -9.6566e+02,\n",
       "        -7.6114e+02, -4.5794e+02, -8.8455e+01, -1.3720e+02, -4.8188e+02,\n",
       "         7.4859e+02,  3.1137e+02,  8.9031e+02,  1.4473e+02,  3.5661e+02,\n",
       "         2.4364e+00, -2.2650e+00,  1.0398e+03,  4.9450e+01,  1.5219e+02,\n",
       "        -6.8031e+01,  7.8465e+01,  9.0959e+02,  6.5776e+02, -1.7987e+01,\n",
       "         3.4484e+01,  4.1333e+02,  3.5247e+02,  8.5346e+02, -6.6795e+02,\n",
       "         3.4091e+02, -2.0679e+02, -2.6845e+01, -2.7977e+02,  2.3294e+02,\n",
       "        -1.8259e+02,  3.1481e+02, -4.6463e+02,  1.9876e+02,  9.4669e+02,\n",
       "        -1.6169e+02, -2.2742e+02, -3.1550e+02,  1.9905e+01,  3.8907e+02,\n",
       "         4.4179e+02,  7.8433e+02, -9.6563e+02, -7.1782e+02, -1.9607e+02,\n",
       "        -1.1713e+03,  4.7788e+01, -3.9592e+02,  1.3539e+03, -5.5194e+02,\n",
       "        -3.3254e+02,  1.3317e+02, -4.3306e+01, -5.5744e+01, -1.3875e+03,\n",
       "        -3.5376e+02,  2.6230e+01, -4.6643e+02,  1.4691e+02, -1.6051e+02,\n",
       "        -2.4276e+02, -9.6988e+01, -6.8512e+02, -6.3858e+02, -1.7028e+02,\n",
       "         5.9011e+02, -5.6681e+01, -1.5675e+02, -3.6791e+02, -3.8204e+02,\n",
       "        -4.6955e+02, -1.6940e+02, -1.0049e+01, -3.9361e+02,  1.2804e+02,\n",
       "        -2.0693e+02, -2.9577e+02,  3.4859e+02, -6.9949e+02, -2.6326e+02,\n",
       "        -1.1674e+02, -8.1492e+02, -8.2724e+02, -5.2407e+02, -4.3181e+02,\n",
       "        -3.6749e+02, -7.2764e+02,  7.3440e+02, -3.1612e+02,  4.9516e+02,\n",
       "        -4.5532e+02,  4.9389e+02, -9.5514e+02,  4.3927e+02,  7.1165e+02,\n",
       "        -4.2673e+02,  4.5032e+02, -6.5165e+01,  7.2240e+02,  2.2386e+02,\n",
       "        -9.4661e+02, -7.8182e+01, -4.3151e+02,  4.8898e+02, -4.0709e+02,\n",
       "         3.5088e+02,  1.0228e+03,  5.9694e+01, -1.6259e+02,  7.4507e+02,\n",
       "         7.3404e+02, -1.4166e+01, -2.2558e+01, -1.2184e+03, -4.6935e+02,\n",
       "         2.6364e+02, -4.5576e+02,  1.0912e+03,  3.6147e+02, -9.2562e+02,\n",
       "         9.5438e+02,  3.7337e+02, -3.4379e+00,  2.7113e+02, -1.0968e+03,\n",
       "        -3.9588e+02,  1.0348e+03, -1.2242e+03,  1.3918e+02,  3.2849e+01,\n",
       "        -1.2853e+02,  4.8058e+02,  2.7624e+02, -5.8722e+02, -2.8696e+00,\n",
       "         1.4719e+03,  1.2072e+03, -2.0426e+02,  5.0346e+02,  8.0501e+02,\n",
       "         7.3074e+02,  2.1692e+02, -1.1192e+02,  9.1503e+02, -5.8620e+02,\n",
       "        -4.8757e+02,  5.0549e+02, -3.3545e+01,  9.6023e+02,  1.9529e+02,\n",
       "        -5.1394e+02,  4.0608e+02,  2.2756e+02,  4.3553e+02,  5.4362e+02,\n",
       "        -1.5088e+02, -2.2546e+00,  2.0319e+03, -2.9869e+02, -9.8745e+02,\n",
       "        -1.6999e+02,  5.4451e+01, -1.3593e+02, -5.9124e+02,  2.9941e+01,\n",
       "        -3.8214e+02, -8.4353e+01, -5.1367e+02,  4.0401e+02,  5.6742e+02,\n",
       "        -5.2701e-01,  1.2555e+03,  3.5528e+02, -6.1800e+01,  7.2598e+02,\n",
       "        -7.2096e+02, -6.6002e+02, -3.5112e+02,  4.3062e+02, -5.0626e+02,\n",
       "         3.4175e+02,  1.2346e+02, -6.6606e+02, -2.4696e+02,  1.0149e+03,\n",
       "         1.2985e+01,  1.0901e+03, -1.0574e+03, -4.4979e+02,  4.4994e+02,\n",
       "         1.8675e+02, -5.1523e+02, -1.3514e+02, -3.2326e+02, -1.3027e+02,\n",
       "         2.6055e+02, -6.5246e+02,  3.6671e+02, -5.3908e+02, -1.2225e+03,\n",
       "        -1.1622e+03,  7.4447e+02,  1.2170e+02, -6.3397e+02, -2.0987e+02,\n",
       "         3.9281e+02, -8.8620e+02, -6.1338e+02, -1.2682e+02, -7.6951e+02,\n",
       "        -8.3827e+02,  1.4780e+02,  1.5507e+02,  6.5795e+02, -2.8040e+02,\n",
       "        -1.4231e+01,  3.3966e+02, -1.7620e+02,  7.9282e+02,  3.0507e+02,\n",
       "        -4.6708e+02,  1.0871e+03, -1.3675e+02, -1.2273e+02,  4.5408e+01,\n",
       "        -2.7496e+02, -1.2477e+02,  1.6324e+02,  1.1121e+02, -6.8197e+02,\n",
       "        -4.0436e+02,  8.9820e+02,  2.4434e+01, -3.0475e+02, -9.1015e+02,\n",
       "        -5.0465e+02,  2.4293e+02,  9.6878e+02, -8.4183e+00, -5.7318e+01,\n",
       "        -8.6234e+02,  4.0810e+00,  5.8672e+02, -4.3498e+02, -1.6583e+02,\n",
       "         4.1840e+02, -3.2567e+02,  5.3940e+01,  1.4115e+03,  6.0037e+01,\n",
       "        -1.7412e+03,  7.0390e+02,  8.9386e+01, -8.3089e+02,  1.7725e+02,\n",
       "        -9.3119e+01,  2.5134e+02, -1.0973e+02, -1.8067e+02, -4.2882e+02,\n",
       "        -9.3442e+01, -1.3172e+02, -2.6206e+02,  3.4336e+02, -5.5820e+02,\n",
       "        -7.1831e+02, -6.2523e+02,  7.8551e+01, -5.7452e+01, -3.2032e+02,\n",
       "         1.1122e+03, -5.0772e+02, -1.7009e+01,  2.7438e+02,  9.9868e+02,\n",
       "        -1.3712e+02, -1.4867e+02, -3.8359e+02, -1.3149e+03,  8.9512e+02,\n",
       "        -3.5584e+02,  2.9524e+02, -1.3889e+03,  7.8904e+02,  7.2734e+02,\n",
       "         1.1762e+02, -4.9036e+02, -3.6113e+02,  1.3727e+02, -3.4511e+02,\n",
       "         5.5340e+02, -6.8079e+02,  1.8061e+02, -5.7527e+00,  7.1076e+02,\n",
       "         2.4396e+02,  8.5125e+02, -7.8232e+02,  8.0043e+02, -6.8270e+02,\n",
       "        -3.1713e+02, -6.7672e+02, -4.4521e+02, -2.1111e+02, -9.3720e+01,\n",
       "        -9.5968e+01,  5.4257e+02,  5.9510e+00, -2.0991e+02,  9.5676e+01,\n",
       "        -1.0483e+03,  6.5668e+01,  2.2882e+02,  5.8605e+02, -1.0478e+03,\n",
       "         6.2970e+02, -4.0365e+01,  1.4107e+02,  3.4040e+02,  3.6983e+01,\n",
       "         1.9532e+02, -8.2954e+02, -1.1347e+03, -8.3028e+02,  2.3680e+02,\n",
       "         7.0352e+02, -5.4913e+02,  4.2251e+02, -1.6794e+02,  2.5308e+02,\n",
       "        -8.5740e+02,  6.8648e+02,  1.4648e+03, -2.3738e+02, -1.2226e+03,\n",
       "        -2.9079e+01, -2.1550e+02, -1.0086e+02, -2.9422e+02, -9.8940e+02,\n",
       "        -5.0914e+02,  1.2045e+03,  2.0868e+02, -9.2470e+02, -8.9349e+02,\n",
       "         1.7306e+03,  3.1479e+02, -6.8379e+02,  2.3561e+02,  2.8198e+02,\n",
       "         2.9219e+02, -2.5712e+02,  3.4545e+02,  3.3904e+02,  9.2723e+02,\n",
       "        -1.4791e+03, -1.0711e+03,  1.2872e+01,  8.5136e+02,  2.7952e+02,\n",
       "        -6.9179e+02, -4.3529e+02,  4.1915e+02, -1.0089e+03, -4.9260e+01,\n",
       "         3.4019e+02,  7.4134e+02, -5.1214e+02, -8.5624e+02,  4.1663e+02,\n",
       "        -1.7662e+02,  3.0392e+02, -3.3456e+02,  5.5762e+02,  3.8095e+02,\n",
       "        -1.0197e+03, -5.2929e+02, -1.0816e+03,  1.3512e+02,  2.3900e+02,\n",
       "         3.0028e+02,  1.8554e+02,  3.9866e+02,  3.6996e+02,  1.6315e+01,\n",
       "         6.4985e+02, -6.7905e+02, -2.0867e+00, -7.6933e+02,  2.2049e+02,\n",
       "         6.8753e+01,  6.1215e+02, -2.5228e+02,  4.8405e+02, -6.6142e+02,\n",
       "         3.8345e+02, -2.4517e+02,  1.0590e+02, -3.4707e+02,  1.0960e+02,\n",
       "         6.3501e+02,  3.2960e+02, -8.2496e+02,  6.9624e+02, -8.8297e+02,\n",
       "         2.2057e+02,  5.1882e+01, -7.3417e+02, -4.4183e+02, -1.0541e+02,\n",
       "         5.7712e+02,  2.1132e+01, -1.0797e+00, -1.9773e+02, -4.2033e+02,\n",
       "        -1.8751e+02,  2.0653e+03,  6.3977e+02,  9.1150e+02, -8.1036e+02,\n",
       "        -4.4940e+02,  1.7656e+02,  3.8848e+02, -7.3422e+02, -4.8574e+02,\n",
       "        -3.0015e+02, -3.5011e+02,  5.5921e+02,  5.3346e+02, -3.4855e+02,\n",
       "         4.0264e+02, -2.6584e+02, -1.9901e+02, -6.7336e+02,  1.1544e+02,\n",
       "         4.3355e+01,  1.1903e+03,  2.9936e+02, -7.5486e+02, -1.4832e+02,\n",
       "         1.1743e+03, -6.8767e+02,  2.9678e+02, -3.5511e+02, -5.7490e+02,\n",
       "         6.5755e+02, -6.4418e+02, -8.1210e+02,  8.4984e+02,  3.3872e+02,\n",
       "        -4.3645e+02,  1.9972e+02,  6.4174e+02,  4.5755e+02, -3.4768e+02,\n",
       "        -8.7742e+01,  2.4288e+02, -3.0468e+02, -2.5053e+02, -7.3478e+02,\n",
       "         7.0459e+01, -4.2141e+02, -9.0025e+02,  2.6915e+02,  5.8882e+02,\n",
       "         2.1865e+02, -3.3117e+02, -6.0918e+02, -1.8964e+01, -1.6610e+02,\n",
       "         5.2098e+01, -4.0495e+01,  4.2163e+02,  5.2545e+02, -6.6619e+02,\n",
       "        -2.4631e+02,  1.8649e+02,  1.0545e+02,  2.8063e+02,  1.3329e+02,\n",
       "         2.3283e+02,  4.9870e+02,  9.7214e+02,  9.3558e+02,  1.1499e+03,\n",
       "        -1.0315e+02,  1.1413e+02,  8.7863e+02,  4.7207e+02,  6.3068e+02,\n",
       "        -3.1533e+02,  8.4813e+02,  4.6716e+00, -2.7367e+02, -4.2052e+01,\n",
       "        -3.4037e+02, -3.1580e+02,  2.1900e+02,  5.0809e+02, -5.0834e+02,\n",
       "        -4.0084e+02, -1.2117e+03, -1.6309e+03,  6.5203e+02,  8.6217e+02,\n",
       "         6.8215e+02,  8.1046e+01,  9.3349e+01,  2.0510e+02, -2.2458e+02,\n",
       "         3.1936e+02,  1.5644e+02, -2.0913e+02,  1.8839e+02, -1.2287e+03,\n",
       "        -9.2052e+02,  4.2554e+02, -3.3779e+02,  5.4888e+02, -3.4983e+02,\n",
       "         3.8774e+02,  2.5993e+02, -6.8721e+02, -1.2891e+02,  3.9057e+02,\n",
       "        -3.9832e+01, -3.0839e+02,  1.4265e+03,  6.9035e+02, -6.5330e+02,\n",
       "         5.1841e+02,  7.6608e+02,  5.7097e+01, -6.2184e+02, -1.0165e+03,\n",
       "         4.1310e+02, -3.5507e+02,  8.5988e+01,  7.9911e+01,  3.5392e+02,\n",
       "         7.0007e+02, -9.4470e+02, -1.5296e+01,  1.0382e+02, -1.5905e+02,\n",
       "        -7.5018e+02, -5.8007e+02, -2.4289e+02,  1.2981e+03, -4.9580e+02,\n",
       "        -4.0050e+02, -2.0289e+02, -4.7044e+02, -1.0989e+03,  7.7680e+02,\n",
       "        -5.0913e+02, -7.0313e+01, -8.4318e+02, -2.6662e+02, -1.0338e+03,\n",
       "        -4.2819e+02, -5.7288e+01,  1.3607e+02,  1.2827e+02, -3.3473e+02,\n",
       "         4.1329e+02,  2.0215e+02, -3.3073e+02, -4.8885e+02, -3.4080e+02,\n",
       "         1.3280e+02,  4.9645e+02,  2.3211e+01, -2.6871e+02, -9.0295e+02,\n",
       "         1.1771e+03,  3.6242e+02,  2.1678e+02,  2.1906e+02, -1.7096e+02,\n",
       "         1.1313e+03, -1.0525e+03, -2.5710e+02,  6.9503e+02,  1.3086e+01,\n",
       "        -2.1434e+01, -2.7374e+02,  7.7616e+02,  1.3929e+02,  5.0409e+02,\n",
       "         4.9293e+02, -9.7342e+02,  3.1367e+02, -1.5002e+03,  6.4731e+02,\n",
       "        -4.7866e+02, -4.8963e+02,  5.0989e+02, -6.5292e+02,  4.0472e+02,\n",
       "        -5.3958e+02,  3.4232e+02,  4.0519e+02, -1.9374e+02, -8.9211e+02,\n",
       "         3.7635e+02,  4.3312e+02, -1.1104e+03,  2.5958e+02,  2.6681e+02,\n",
       "         2.9600e+02,  2.1714e+02, -2.0176e+02,  1.9782e+02,  1.2719e+03,\n",
       "         7.3116e+00, -7.1836e+02, -1.0756e+03,  2.3795e+02, -1.2092e+02,\n",
       "        -2.5520e+01, -9.0081e+02,  3.2890e+02,  3.6617e+02, -4.2355e+02,\n",
       "        -1.0135e+03, -1.2089e+02, -3.3253e+01, -2.7015e+02,  4.7690e+01,\n",
       "        -9.3237e+02,  1.4504e+02,  3.0019e+02, -1.9235e+02, -1.0404e+02,\n",
       "        -2.1447e+02,  6.5033e+02,  3.6142e+02, -2.3775e+02, -3.2958e+02,\n",
       "        -1.7580e+02,  1.8336e+03, -6.6630e+02,  5.2500e+02, -1.9551e+02,\n",
       "        -5.6886e+02,  6.6945e+02,  4.9943e+02,  3.9050e+01, -4.7449e+02,\n",
       "        -1.1649e+03,  3.6657e+02,  6.9320e+02,  1.7573e+02, -2.5382e+02,\n",
       "        -4.2253e+02,  3.4988e+01, -1.0928e+03, -4.3747e+02,  1.1660e+03,\n",
       "        -3.8268e+02,  4.1382e+02, -4.0715e+02,  1.0376e+02, -5.6831e+02,\n",
       "         5.1156e+02, -1.9020e+02, -4.3581e+02,  9.1460e+01,  5.2712e+02,\n",
       "         1.4542e+03, -8.0816e+02,  1.4350e+02, -9.6895e+02,  5.8539e+02,\n",
       "        -2.5576e+02,  3.6580e+02,  4.9544e+02,  3.1875e+02,  6.4815e+02,\n",
       "        -3.9333e+02,  3.4324e+02, -3.3374e+02,  2.7119e+02, -2.1259e+02,\n",
       "         4.1951e+02,  5.8165e+01,  2.9256e+02, -3.9518e+02,  2.7812e+02,\n",
       "         7.9529e+02, -1.2406e+03, -1.7968e+02, -1.3035e+03, -1.1811e+03,\n",
       "         7.4074e+02, -8.0961e+02,  8.3143e+02,  2.9495e+02,  9.3706e+02,\n",
       "         3.4130e+02,  3.8884e+02,  3.7747e+02, -1.4013e+03, -2.0394e+02,\n",
       "        -1.7905e+02, -2.0609e+02,  7.4068e+01,  5.9328e+01, -4.8364e+02,\n",
       "        -2.4423e+02,  6.5000e+02,  2.2471e+02, -4.8892e+02,  4.1193e+02,\n",
       "        -1.7326e+02, -1.2244e+03, -6.5062e+01,  8.0615e+02,  6.3632e+02,\n",
       "         1.0452e+02, -5.4789e+02,  1.9832e+01, -1.2186e+02,  4.7331e+02,\n",
       "        -7.5951e+02,  3.8220e+01, -3.8095e+02, -2.3627e+02, -1.0873e+02,\n",
       "        -4.6795e+02,  1.0454e+02,  2.2555e+02,  1.2966e+02, -7.3467e+00,\n",
       "        -1.1406e+02,  1.4522e+02,  4.5259e+02,  8.8948e+02, -4.7931e+02,\n",
       "         4.5991e+02, -3.5754e+02, -4.0136e+01, -3.3883e+02,  1.4593e+03])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e8b5676-2c6c-434d-822b-10874478b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e78c1a6b-e5c9-42c9-a8fa-7ef7170c2a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.pop(2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71f847-a1cb-4a90-bef5-36bc8bd6ce84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
