{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc1ab8f9-2947-44fc-9de6-bd741c27eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")\n",
    "from parser.utils import load_json, dfs_cardinality, estimate_scan_in_mb\n",
    "from models.feature.single_xgboost_feature import find_top_k_operators, featurize_one_plan, get_top_k_table_by_size\n",
    "from utils.load_brad_trace import load_trace, create_concurrency_dataset, load_trace_all_version\n",
    "from models.concurrency.utils import pre_info_train_test_seperation\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from models.single.stage import SingleStage\n",
    "from models.concurrency.complex_models import ConcurrentRNN\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adcb1507-a2fc-4323-a350-9566aee3b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple\n",
    "from utils.load_brad_trace import (\n",
    "    load_trace,\n",
    "    create_concurrency_dataset,\n",
    "    load_trace_all_version,\n",
    ")\n",
    "from models.single.stage import SingleStage\n",
    "from models.concurrency.complex_models import ConcurrentRNN\n",
    "from scheduler.base_scheduler import BaseScheduler\n",
    "\n",
    "\n",
    "class QueryBank:\n",
    "    def __init__(\n",
    "        self, sql_query_file: str, query_runtime_path: str, seed: int = 0\n",
    "    ) -> None:\n",
    "        with open(sql_query_file, \"r\") as f:\n",
    "            sql_queries = f.readlines()\n",
    "        query_runtime = np.load(query_runtime_path)\n",
    "        assert len(sql_queries) == len(query_runtime)\n",
    "        idx = np.argsort(query_runtime)\n",
    "        self.query_runtime = query_runtime[idx]\n",
    "        self.sql_queries = [sql_queries[i] for i in idx]\n",
    "        self.query_len = len(self.query_runtime)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def random_sample(self) -> (str, float):\n",
    "        # make a random sample of the query\n",
    "        idx = np.random.randint(self.query_len)\n",
    "        return self.sql_queries[idx], self.query_runtime[idx]\n",
    "\n",
    "    def sample_by_runtime(self, runtime: float) -> (str, float):\n",
    "        # sample a query that best matches the runtime\n",
    "        idx = np.searchsorted(self.query_runtime, runtime)\n",
    "        idx = max(idx, self.query_len - 1)\n",
    "        return self.sql_queries[idx], self.query_runtime[idx]\n",
    "\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(\n",
    "        self, scheduler: BaseScheduler, query_bank: Optional[QueryBank] = None, pause_wait_s: float = 1.0\n",
    "    ):\n",
    "        self.scheduler = scheduler\n",
    "        self.query_bank = query_bank\n",
    "        self.pause_wait_s = pause_wait_s\n",
    "\n",
    "    def replay_one_query(self, start_time: float, next_query_start_time: Optional[float] = None,\n",
    "                         query_str: Optional[int] = None, query_idx: Optional[int] = None):\n",
    "        # Todo: this logical should go to the scheduler\n",
    "        should_immediate_re_ingest, should_pause_and_re_ingest = self.scheduler.ingest_query_simulation(\n",
    "            start_time, query_str=query_str, query_idx=query_idx\n",
    "        )\n",
    "        print(should_immediate_re_ingest, should_pause_and_re_ingest)\n",
    "        if should_immediate_re_ingest:\n",
    "            # the scheduler schedules one query at a time even if there are multiple queries in the queue, so need to call again\n",
    "            self.replay_one_query(start_time + 0.001)\n",
    "        if should_pause_and_re_ingest:\n",
    "            if next_query_start_time is not None and next_query_start_time <= start_time + self.pause_wait_s:\n",
    "                return\n",
    "            self.replay_one_query(start_time + self.pause_wait_s)\n",
    "\n",
    "    def replay_workload(self, directory: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        all_raw_trace, all_trace = load_trace(directory, 8, concat=True)\n",
    "        concurrency_df = create_concurrency_dataset(all_trace, engine=None, pre_exec_interval=200)\n",
    "        concurrency_df = concurrency_df.sort_values(by=['start_time'], ascending=True)\n",
    "        original_predictions = self.scheduler.make_original_prediction(concurrency_df)\n",
    "        assert len(concurrency_df) == len(original_predictions)\n",
    "        original_runtime = []\n",
    "        all_start_time = concurrency_df[\"start_time\"].values\n",
    "        all_query_idx = concurrency_df[\"query_idx\"].values\n",
    "        for i in range(len(concurrency_df)):\n",
    "            original_runtime.append(original_predictions[i])\n",
    "            # replaying the query one-by-one\n",
    "            if i < len(concurrency_df):\n",
    "                next_query_start_time = all_start_time[i + 1]\n",
    "            else:\n",
    "                next_query_start_time = None\n",
    "            self.replay_one_query(all_start_time[i], next_query_start_time, i, all_query_idx[i])\n",
    "        # finish all queries\n",
    "        self.scheduler.finish_query(np.infty)\n",
    "        new_runtime = []\n",
    "        for i in range(len(concurrency_df)):\n",
    "            new_runtime.append(self.scheduler.all_query_runtime[i])\n",
    "        original_runtime = np.asarray(original_runtime)\n",
    "        new_runtime = np.asarray(new_runtime)\n",
    "        return original_runtime, new_runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ce284a-0421-456f-b645-8acd9cf01d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Optional, Tuple, List, Union, MutableMapping\n",
    "from models.single.stage import SingleStage\n",
    "from models.concurrency.complex_models import ConcurrentRNN\n",
    "\n",
    "\n",
    "def reverse_index_list(lst: List, pop_index: List[int]) -> List:\n",
    "    return [\n",
    "        lst[i] for i in range(len(lst)) if i not in pop_index\n",
    "    ]\n",
    "\n",
    "\n",
    "class BaseScheduler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        stage_model: SingleStage,\n",
    "        predictor: ConcurrentRNN,\n",
    "        max_concurrency_level: int = 5,\n",
    "    ):\n",
    "        self.stage_model = stage_model\n",
    "        self.predictor = predictor\n",
    "        self.max_concurrency_level = max_concurrency_level\n",
    "\n",
    "        self.existing_query_features: List[np.ndarray] = []\n",
    "        self.existing_query_concur_features: List[Optional[torch.Tensor]] = []\n",
    "        self.existing_pre_info_length: List[int] = []\n",
    "        self.existing_start_time: List[float] = []\n",
    "        self.existing_finish_time: List[float] = []\n",
    "        self.existing_runtime_prediction_dict: MutableMapping[Union[str, int], float] = dict()\n",
    "        self.existing_runtime_prediction: List[float] = []\n",
    "        self.queued_query_features: List[np.ndarray] = []\n",
    "        self.current_time = 0\n",
    "        self.running_queries: Union[List[str], List[int]] = []\n",
    "        self.queued_queries: Union[List[str], List[int]] = []\n",
    "        self.existing_enter_time: List[float] = []\n",
    "        self.queued_queries_enter_time: List[float] = []\n",
    "        self.all_query_runtime: MutableMapping[Union[str, int], float] = dict()\n",
    "\n",
    "    def make_original_prediction(self, trace: pd.DataFrame) -> np.ndarray:\n",
    "        all_pred, _ = self.predictor.predict(trace, return_per_query=False)\n",
    "        return all_pred\n",
    "\n",
    "    def ingest_query(self, start_t: float, query_idx: int):\n",
    "        return None\n",
    "\n",
    "    def print_state(self):\n",
    "        print(\"current time: \", self.current_time)\n",
    "        print(\"running_queries: \", list(zip(self.running_queries, self.existing_runtime_prediction)))\n",
    "        print(\"queued_queries: \", self.queued_queries)\n",
    "\n",
    "    def submit_query(\n",
    "        self,\n",
    "        pos_in_queue: int,\n",
    "        query_rep: Union[str, int],\n",
    "        pred_runtime: float,\n",
    "        query_feature: np.ndarray,\n",
    "        submit_time: float,\n",
    "        enter_time: float,\n",
    "        finish_t: float,\n",
    "        query_concur_features: Optional[torch.Tensor],\n",
    "        pre_info_length: int,\n",
    "        new_existing_finish_time: Optional[List[float]] = None,\n",
    "        new_existing_runtime_prediction: Optional[List[float]] = None,\n",
    "        new_existing_query_concur_features: Optional[List[Optional[torch.Tensor]]] = None\n",
    "    ):\n",
    "        # first upload the prediction on existing runtime when a new query is submitted\n",
    "        if new_existing_finish_time is not None:\n",
    "            self.existing_finish_time = new_existing_finish_time\n",
    "        if new_existing_runtime_prediction is not None:\n",
    "            self.existing_runtime_prediction = new_existing_runtime_prediction\n",
    "        if new_existing_query_concur_features is not None:\n",
    "            self.existing_query_concur_features = new_existing_query_concur_features\n",
    "        self.running_queries.append(query_rep)\n",
    "        self.existing_query_features.append(query_feature)\n",
    "        self.existing_start_time.append(submit_time)\n",
    "        self.existing_finish_time.append(finish_t)\n",
    "        self.existing_query_concur_features.append(query_concur_features)\n",
    "        self.existing_pre_info_length.append(pre_info_length)\n",
    "        self.existing_enter_time.append(enter_time)\n",
    "        self.existing_runtime_prediction.append(pred_runtime)\n",
    "        self.queued_queries.pop(pos_in_queue)\n",
    "        self.queued_query_features.pop(pos_in_queue)\n",
    "        self.queued_queries_enter_time.pop(pos_in_queue)\n",
    "\n",
    "\n",
    "    def finish_query(self, current_time: float = None) -> None:\n",
    "        if current_time is not None:\n",
    "            self.current_time = current_time\n",
    "        pop_index = []\n",
    "        for i, finish_t in enumerate(self.existing_finish_time):\n",
    "            if finish_t <= self.current_time:\n",
    "                pop_index.append(i)\n",
    "                query_str = self.running_queries[i]\n",
    "                self.all_query_runtime[query_str] = (\n",
    "                    finish_t - self.existing_enter_time[i]\n",
    "                )\n",
    "        if len(pop_index) == 0:\n",
    "            return\n",
    "        length = len(self.existing_finish_time)\n",
    "        self.running_queries = reverse_index_list(self.running_queries, pop_index)\n",
    "        self.existing_enter_time = reverse_index_list(self.existing_enter_time, pop_index)\n",
    "        self.existing_query_features = reverse_index_list(self.existing_query_features, pop_index)\n",
    "        self.existing_runtime_prediction = reverse_index_list(self.existing_runtime_prediction, pop_index)\n",
    "        self.existing_start_time = reverse_index_list(self.existing_start_time, pop_index)\n",
    "        self.existing_finish_time = reverse_index_list(self.existing_finish_time, pop_index)\n",
    "        # Todo: the last two needs change when we remove a query from its pre info,\n",
    "        #  or we train with sufficient squence length\n",
    "        self.existing_query_concur_features = [\n",
    "            self.existing_query_concur_features[i]\n",
    "            for i in range(length)\n",
    "            if i not in pop_index\n",
    "        ]\n",
    "        self.existing_pre_info_length = [\n",
    "            self.existing_pre_info_length[i]\n",
    "            for i in range(length)\n",
    "            if i not in pop_index\n",
    "        ]\n",
    "\n",
    "    def ingest_query_simulation(\n",
    "        self,\n",
    "        start_t: float,\n",
    "        query_str: Optional[Union[str, int]] = None,\n",
    "        query_idx: Optional[int] = None,\n",
    "    ) -> Tuple[bool, bool]:\n",
    "        \"\"\"We work on planning the currently queued queries if quert_str is None (i.e., no query submitted)\"\"\"\n",
    "        self.current_time = start_t\n",
    "        self.finish_query()\n",
    "        should_immediate_re_ingest = False\n",
    "        should_pause_and_re_ingest = False\n",
    "        if query_str is not None:\n",
    "            self.queued_queries.append(query_str)\n",
    "            self.queued_queries_enter_time.append(start_t)\n",
    "            query_feature = self.stage_model.featurize_online(query_idx)\n",
    "            self.queued_query_features.append(query_feature)\n",
    "\n",
    "        if len(self.queued_query_features) == 0:\n",
    "            # nothing to do when there is no query in the queue\n",
    "            return should_immediate_re_ingest, should_pause_and_re_ingest\n",
    "\n",
    "        predictions, global_x, global_pre_info_length = self.predictor.online_inference(\n",
    "            self.existing_query_features,\n",
    "            self.existing_query_concur_features,\n",
    "            self.existing_pre_info_length,\n",
    "            self.queued_query_features,\n",
    "            self.existing_start_time,\n",
    "            start_t,\n",
    "        )\n",
    "\n",
    "        predictions = predictions.reshape(-1).detach().numpy()\n",
    "        # Todo: add algorithms to decide whether to put in queue or directly for execution\n",
    "        if len(self.running_queries) == 0:\n",
    "            # submit up to self.max_concurrency_level number of queries in queue when there is no query running\n",
    "            # Todo: this is not optimal\n",
    "            assert len(predictions) == len(self.queued_queries)\n",
    "            sort_idx = np.argsort(predictions)\n",
    "            if len(sort_idx) >= self.max_concurrency_level:\n",
    "                sort_idx = sort_idx[: self.max_concurrency_level]\n",
    "            submit_query_str = []\n",
    "            submit_query_feature = []\n",
    "            submit_enter_time = []\n",
    "            submit_pred_runtime = []\n",
    "            for i in sort_idx:\n",
    "                submit_query_str.append(self.queued_queries[i])\n",
    "                submit_query_feature.append(self.queued_query_features[i])\n",
    "                submit_enter_time.append(self.queued_queries_enter_time[i])\n",
    "                submit_pred_runtime.append(float(predictions[i]))\n",
    "            for i, idx in enumerate(sort_idx):\n",
    "                finish_t = float(predictions[idx]) + start_t\n",
    "                query_str = submit_query_str[i]\n",
    "                query_feature = submit_query_feature[i]\n",
    "                enter_t = submit_enter_time[i]\n",
    "                pred_runtime = submit_pred_runtime[i]\n",
    "                self.submit_query(\n",
    "                    idx,\n",
    "                    query_str,\n",
    "                    pred_runtime,\n",
    "                    query_feature,\n",
    "                    start_t,\n",
    "                    enter_t,\n",
    "                    finish_t,\n",
    "                    None,\n",
    "                    int(global_pre_info_length[idx]),\n",
    "                )\n",
    "            return should_immediate_re_ingest, should_pause_and_re_ingest\n",
    "        elif len(self.running_queries) >= self.max_concurrency_level:\n",
    "            # when the server is running at its full capacity, should pause and retry\n",
    "            should_pause_and_re_ingest = True\n",
    "            return should_immediate_re_ingest, should_pause_and_re_ingest\n",
    "        else:\n",
    "            # Todo: implement some better algos\n",
    "            # Todo: add another logic: if the currently queued queries are all \"bad\" for the system load, pause and retry\n",
    "            all_new_existing_pred = []\n",
    "            all_curr_pred = []\n",
    "            all_delta_sum = []\n",
    "            all_query_concur_feature = []\n",
    "            all_global_pre_info_length = []\n",
    "            all_existing_query_concur_feature = []\n",
    "            for i in range(len(self.queued_queries)):\n",
    "                pred_idx = i * (1 + len(self.existing_query_concur_features))\n",
    "                all_global_pre_info_length.append(global_pre_info_length[pred_idx])\n",
    "                curr_pred = predictions[pred_idx]\n",
    "                curr_concur_feature = global_x[pred_idx]\n",
    "                all_curr_pred.append(curr_pred)\n",
    "                old_existing_pred = np.asarray(self.existing_runtime_prediction)\n",
    "                new_existing_pred = predictions[(pred_idx + 1): (pred_idx + len(self.existing_query_concur_features) + 1)]\n",
    "                curr_existing_query_concur_feature = []\n",
    "                for j in range(pred_idx + 1, pred_idx + len(self.existing_query_concur_features) + 1):\n",
    "                    curr_existing_query_concur_feature.append(global_x[j])\n",
    "                all_new_existing_pred.append(new_existing_pred)\n",
    "                all_query_concur_feature.append(curr_concur_feature)\n",
    "                all_existing_query_concur_feature.append(curr_existing_query_concur_feature)\n",
    "                # realistically, should be a positive number, the smaller, the better\n",
    "                delta = new_existing_pred - old_existing_pred\n",
    "                all_delta_sum.append(np.sum(delta))\n",
    "            # Heuristic to submit the query that incur minimal delta on the existing queries, then resubmit the next\n",
    "            selected_idx = np.argmin(all_delta_sum)\n",
    "            finish_t = all_curr_pred[selected_idx] + start_t\n",
    "            new_existing_finish_time = []\n",
    "            for i in range(len(self.existing_start_time)):\n",
    "                new_existing_finish_time.append(all_new_existing_pred[selected_idx][i] + self.existing_start_time[i])\n",
    "            self.submit_query(\n",
    "                selected_idx,\n",
    "                self.queued_queries[selected_idx],\n",
    "                all_curr_pred[selected_idx],\n",
    "                self.queued_query_features[selected_idx],\n",
    "                start_t,\n",
    "                self.queued_queries_enter_time[selected_idx],\n",
    "                finish_t,\n",
    "                all_query_concur_feature[selected_idx],\n",
    "                int(global_pre_info_length[selected_idx]),\n",
    "                new_existing_finish_time,\n",
    "                list(all_new_existing_pred[selected_idx]),\n",
    "                all_existing_query_concur_feature[selected_idx]\n",
    "            )\n",
    "            # immediately resubmit the next\n",
    "            should_immediate_re_ingest = True\n",
    "            return should_immediate_re_ingest, should_pause_and_re_ingest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576aea90-0564-437e-9099-146a244551d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28925 25561\n",
      "43967 10907\n"
     ]
    }
   ],
   "source": [
    "parsed_queries_path = \"/Users/ziniuw/Desktop/research/Data/AWS_trace/mixed_aurora/aurora_mixed_parsed_queries.json\"\n",
    "plans = load_json(parsed_queries_path, namespace=False)\n",
    "folder_name = \"mixed_aurora\"\n",
    "directory = f\"/Users/ziniuw/Desktop/research/Data/AWS_trace/{folder_name}/\"\n",
    "all_raw_trace, all_trace = load_trace_all_version(directory, 8, concat=True)\n",
    "all_concurrency_df = []\n",
    "for trace in all_trace:\n",
    "    concurrency_df = create_concurrency_dataset(trace, engine=None, pre_exec_interval=200)\n",
    "    all_concurrency_df.append(concurrency_df)\n",
    "concurrency_df = pd.concat(all_concurrency_df, ignore_index=True)\n",
    "train_trace_df_sep, eval_trace_df_sep = pre_info_train_test_seperation(concurrency_df)\n",
    "print(len(train_trace_df_sep), len(eval_trace_df_sep))\n",
    "np.random.seed(0)\n",
    "train_idx = np.random.choice(len(concurrency_df), size=int(0.8 * len(concurrency_df)), replace=False)\n",
    "test_idx = [i for i in range(len(concurrency_df)) if i not in train_idx]\n",
    "train_trace_df = copy.deepcopy(concurrency_df.iloc[train_idx])\n",
    "eval_trace_df = concurrency_df.iloc[test_idx]\n",
    "eval_trace_df = copy.deepcopy(eval_trace_df[eval_trace_df['num_concurrent_queries'] > 0])\n",
    "print(len(train_trace_df), len(eval_trace_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10927c71-72be-4c2d-a154-939c6d129781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7247"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concurrency_df = create_concurrency_dataset(all_trace[4], engine=None, pre_exec_interval=200)\n",
    "len(concurrency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6a4c039-d2b7-4322-91c8-6fc0b47ad549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 operators contains 0.9650782102582758 total operators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 200/200 [00:01<00:00, 163.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% absolute error is 0.7539181709289551, q-error is 1.6221708059310913\n",
      "90% absolute error is 7.437521934509277, q-error is 4.810779094696045\n",
      "95% absolute error is 17.491859436035156, q-error is 7.3121185302734375\n"
     ]
    }
   ],
   "source": [
    "ss = SingleStage(use_table_features=True, true_card=True)\n",
    "#df = ss.featurize_data(train_trace_df, parsed_queries_path)\n",
    "df = ss.featurize_data(concurrency_df, parsed_queries_path)\n",
    "ss.train(df)\n",
    "rnn = ConcurrentRNN(ss, \n",
    "                    input_size=len(ss.all_feature[0]) * 2 + 7,\n",
    "                    embedding_dim=128,\n",
    "                    hidden_size=256,\n",
    "                    num_layers=2,\n",
    "                    loss_function=\"q_loss\",\n",
    "                    last_output=True,\n",
    "                    use_seperation=False\n",
    "                   )\n",
    "rnn.load_model(\"checkpoints\")\n",
    "preds, labels = rnn.predict(eval_trace_df_sep, use_pre_info_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd91904f-26bd-4185-8c7c-6e696078cec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>query_idx</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>pre_exec_info</th>\n",
       "      <th>concur_info</th>\n",
       "      <th>num_concurrent_queries</th>\n",
       "      <th>concur_info_train</th>\n",
       "      <th>num_concurrent_queries_train</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>5.655529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.655529</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(47, 0.0, 0.7545511722564697)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0.754551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754551</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 12.939171041616367, 1.0, 0.0, 1.0, 3.178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>223</td>\n",
       "      <td>6.149721</td>\n",
       "      <td>7.585598</td>\n",
       "      <td>13.735319</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 5.662960514858168, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>166</td>\n",
       "      <td>52.448667</td>\n",
       "      <td>12.873188</td>\n",
       "      <td>65.321855</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(223, 7.585598000000001, 13.735319145629884),...</td>\n",
       "      <td>10</td>\n",
       "      <td>[(223, 7.585598000000001, 13.735319145629884)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 2.0, 18.40287090199306, 1.0, 6.5279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>15.688915</td>\n",
       "      <td>13.946549</td>\n",
       "      <td>29.635464</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.0, 0.0, 1.0, 19.905940414924405, 1.0, 4.564...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>230</td>\n",
       "      <td>25.264143</td>\n",
       "      <td>14.095773</td>\n",
       "      <td>39.359916</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 4.564348295634497, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>71.312155</td>\n",
       "      <td>14.945813</td>\n",
       "      <td>86.257968</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.0, 0.0, 2.0, 19.450703284645463, 1.0, 3.871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>27.104419</td>\n",
       "      <td>21.507418</td>\n",
       "      <td>48.611837</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[1.0, 19.324584027212996, 1.0, 1.3862968611167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>130</td>\n",
       "      <td>1.505992</td>\n",
       "      <td>35.191467</td>\n",
       "      <td>36.697459</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 1.0, 2.4849074831209865, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>53.068653</td>\n",
       "      <td>35.814352</td>\n",
       "      <td>88.883005</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 5.257495424111114, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>6.581586</td>\n",
       "      <td>50.635466</td>\n",
       "      <td>57.217052</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.0, 0.0, 5.0, 20.084967535837624, 1.0, 3.871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>15.602509</td>\n",
       "      <td>60.663118</td>\n",
       "      <td>76.265627</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.0, 10.34971065343648, 1.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>162</td>\n",
       "      <td>42.714921</td>\n",
       "      <td>62.922722</td>\n",
       "      <td>105.637643</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[(166, 12.873187999999999, 65.3218545725708), ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 5.318120042863823, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>239</td>\n",
       "      <td>9.314334</td>\n",
       "      <td>68.096225</td>\n",
       "      <td>77.410559</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(34, 14.945812999999998, 86.25796824673462), ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[(34, 14.945812999999998, 86.25796824673462), ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 5.662960514858168, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>3.443823</td>\n",
       "      <td>68.567545</td>\n",
       "      <td>72.011368</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(34, 14.945812999999998, 86.25796824673462), ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[(34, 14.945812999999998, 86.25796824673462), ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[8.0, 10.450452354862431, 7.0, 31.499663515406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>3.219293</td>\n",
       "      <td>95.472959</td>\n",
       "      <td>98.692252</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.0, 0.0, 4.0, 27.65695795979097, 1.0, 4.7874...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>109</td>\n",
       "      <td>14.189221</td>\n",
       "      <td>100.729884</td>\n",
       "      <td>114.919105</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382), ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 3.1780542470145257, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>222</td>\n",
       "      <td>50.883419</td>\n",
       "      <td>100.930435</td>\n",
       "      <td>151.813854</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382), ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382), ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 4.564348295634497, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "      <td>1.180558</td>\n",
       "      <td>102.037091</td>\n",
       "      <td>103.217649</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.0, 44.7239645661069, 3.0, 4.564351108131291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>23.693690</td>\n",
       "      <td>104.812951</td>\n",
       "      <td>128.506641</td>\n",
       "      <td>[(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382), ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[(162, 62.92272199999999, 105.6376432360382), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.0, 19.410506292762488, 6.0, 26.540273810465...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  query_idx    runtime  start_time    end_time  \\\n",
       "0       0        163   5.655529    0.000000    5.655529   \n",
       "1       1         47   0.754551    0.000000    0.754551   \n",
       "2       2        223   6.149721    7.585598   13.735319   \n",
       "3       3        166  52.448667   12.873188   65.321855   \n",
       "4       4         10  15.688915   13.946549   29.635464   \n",
       "5       5        230  25.264143   14.095773   39.359916   \n",
       "6       6         34  71.312155   14.945813   86.257968   \n",
       "7       7        194  27.104419   21.507418   48.611837   \n",
       "8       8        130   1.505992   35.191467   36.697459   \n",
       "9       9        216  53.068653   35.814352   88.883005   \n",
       "10     10         46   6.581586   50.635466   57.217052   \n",
       "11     11        150  15.602509   60.663118   76.265627   \n",
       "12     12        162  42.714921   62.922722  105.637643   \n",
       "13     13        239   9.314334   68.096225   77.410559   \n",
       "14     14         52   3.443823   68.567545   72.011368   \n",
       "15     15         25   3.219293   95.472959   98.692252   \n",
       "16     16        109  14.189221  100.729884  114.919105   \n",
       "17     17        222  50.883419  100.930435  151.813854   \n",
       "18     18         57   1.180558  102.037091  103.217649   \n",
       "19     19         49  23.693690  104.812951  128.506641   \n",
       "\n",
       "                                        pre_exec_info  \\\n",
       "0                                                  []   \n",
       "1                                                  []   \n",
       "2   [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "3   [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "4   [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "5   [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "6   [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "7   [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "8   [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "9   [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "10  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "11  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "12  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "13  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "14  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "15  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "16  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "17  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "18  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "19  [(163, 0.0, 5.655529022216797), (47, 0.0, 0.75...   \n",
       "\n",
       "                                          concur_info  num_concurrent_queries  \\\n",
       "0                     [(47, 0.0, 0.7545511722564697)]                       1   \n",
       "1                     [(163, 0.0, 5.655529022216797)]                       1   \n",
       "2       [(166, 12.873187999999999, 65.3218545725708)]                       1   \n",
       "3   [(223, 7.585598000000001, 13.735319145629884),...                      10   \n",
       "4   [(166, 12.873187999999999, 65.3218545725708), ...                       4   \n",
       "5   [(166, 12.873187999999999, 65.3218545725708), ...                       6   \n",
       "6   [(166, 12.873187999999999, 65.3218545725708), ...                      11   \n",
       "7   [(166, 12.873187999999999, 65.3218545725708), ...                       6   \n",
       "8   [(166, 12.873187999999999, 65.3218545725708), ...                       5   \n",
       "9   [(166, 12.873187999999999, 65.3218545725708), ...                      10   \n",
       "10  [(166, 12.873187999999999, 65.3218545725708), ...                       3   \n",
       "11  [(166, 12.873187999999999, 65.3218545725708), ...                       6   \n",
       "12  [(166, 12.873187999999999, 65.3218545725708), ...                      11   \n",
       "13  [(34, 14.945812999999998, 86.25796824673462), ...                       5   \n",
       "14  [(34, 14.945812999999998, 86.25796824673462), ...                       5   \n",
       "15      [(162, 62.92272199999999, 105.6376432360382)]                       1   \n",
       "16  [(162, 62.92272199999999, 105.6376432360382), ...                       4   \n",
       "17  [(162, 62.92272199999999, 105.6376432360382), ...                      13   \n",
       "18  [(162, 62.92272199999999, 105.6376432360382), ...                       3   \n",
       "19  [(162, 62.92272199999999, 105.6376432360382), ...                       7   \n",
       "\n",
       "                                    concur_info_train  \\\n",
       "0                                                  []   \n",
       "1                     [(163, 0.0, 5.655529022216797)]   \n",
       "2                                                  []   \n",
       "3      [(223, 7.585598000000001, 13.735319145629884)]   \n",
       "4       [(166, 12.873187999999999, 65.3218545725708)]   \n",
       "5   [(166, 12.873187999999999, 65.3218545725708), ...   \n",
       "6   [(166, 12.873187999999999, 65.3218545725708), ...   \n",
       "7   [(166, 12.873187999999999, 65.3218545725708), ...   \n",
       "8   [(166, 12.873187999999999, 65.3218545725708), ...   \n",
       "9   [(166, 12.873187999999999, 65.3218545725708), ...   \n",
       "10  [(166, 12.873187999999999, 65.3218545725708), ...   \n",
       "11  [(166, 12.873187999999999, 65.3218545725708), ...   \n",
       "12  [(166, 12.873187999999999, 65.3218545725708), ...   \n",
       "13  [(34, 14.945812999999998, 86.25796824673462), ...   \n",
       "14  [(34, 14.945812999999998, 86.25796824673462), ...   \n",
       "15      [(162, 62.92272199999999, 105.6376432360382)]   \n",
       "16      [(162, 62.92272199999999, 105.6376432360382)]   \n",
       "17  [(162, 62.92272199999999, 105.6376432360382), ...   \n",
       "18  [(162, 62.92272199999999, 105.6376432360382), ...   \n",
       "19  [(162, 62.92272199999999, 105.6376432360382), ...   \n",
       "\n",
       "    num_concurrent_queries_train  \\\n",
       "0                              0   \n",
       "1                              1   \n",
       "2                              0   \n",
       "3                              1   \n",
       "4                              1   \n",
       "5                              2   \n",
       "6                              3   \n",
       "7                              4   \n",
       "8                              4   \n",
       "9                              5   \n",
       "10                             3   \n",
       "11                             3   \n",
       "12                             4   \n",
       "13                             4   \n",
       "14                             5   \n",
       "15                             1   \n",
       "16                             1   \n",
       "17                             2   \n",
       "18                             3   \n",
       "19                             3   \n",
       "\n",
       "                                             features  \n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1   [1.0, 12.939171041616367, 1.0, 0.0, 1.0, 3.178...  \n",
       "2   [0.0, 0.0, 0.0, 0.0, 1.0, 5.662960514858168, 1...  \n",
       "3   [0.0, 0.0, 2.0, 18.40287090199306, 1.0, 6.5279...  \n",
       "4   [2.0, 0.0, 1.0, 19.905940414924405, 1.0, 4.564...  \n",
       "5   [0.0, 0.0, 0.0, 0.0, 1.0, 4.564348295634497, 1...  \n",
       "6   [1.0, 0.0, 2.0, 19.450703284645463, 1.0, 3.871...  \n",
       "7   [1.0, 19.324584027212996, 1.0, 1.3862968611167...  \n",
       "8   [0.0, 0.0, 1.0, 2.4849074831209865, 0.0, 0.0, ...  \n",
       "9   [0.0, 0.0, 0.0, 0.0, 1.0, 5.257495424111114, 1...  \n",
       "10  [6.0, 0.0, 5.0, 20.084967535837624, 1.0, 3.871...  \n",
       "11  [1.0, 10.34971065343648, 1.0, 0.0, 0.0, 0.0, 0...  \n",
       "12  [0.0, 0.0, 0.0, 0.0, 1.0, 5.318120042863823, 1...  \n",
       "13  [0.0, 0.0, 0.0, 0.0, 1.0, 5.662960514858168, 1...  \n",
       "14  [8.0, 10.450452354862431, 7.0, 31.499663515406...  \n",
       "15  [6.0, 0.0, 4.0, 27.65695795979097, 1.0, 4.7874...  \n",
       "16  [0.0, 0.0, 0.0, 0.0, 1.0, 3.1780542470145257, ...  \n",
       "17  [0.0, 0.0, 0.0, 0.0, 1.0, 4.564348295634497, 1...  \n",
       "18  [6.0, 44.7239645661069, 3.0, 4.564351108131291...  \n",
       "19  [6.0, 19.410506292762488, 6.0, 26.540273810465...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concurrency_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ff7d10-9717-4769-9b25-9c18fd55bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 57/57 [00:00<00:00, 57.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% absolute error is 2.107799530029297, q-error is 1.2512032985687256\n",
      "90% absolute error is 26.147747802734383, q-error is 2.921528482437134\n",
      "95% absolute error is 52.68221130371092, q-error is 4.323071813583374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scheduler = BaseScheduler(ss, rnn)\n",
    "simulator = Simulator(scheduler)\n",
    "concurrency_df = concurrency_df.sort_values(by=['start_time'], ascending=True)\n",
    "original_predictions = scheduler.make_original_prediction(concurrency_df)\n",
    "assert len(concurrency_df) == len(original_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12125423-e7a5-4f02-b102-83afc8980d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "============================== 0\n",
      "current time:  0.0\n",
      "running_queries:  [(0, 5.7421417236328125)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 1\n",
      "current time:  0.001\n",
      "running_queries:  [(0, 4.6010733), (1, 0.38370922)]\n",
      "queued_queries:  []\n",
      "False False\n",
      "============================== 2\n",
      "current time:  7.585598000000001\n",
      "running_queries:  [(2, 6.048593997955322)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 3\n",
      "current time:  12.874187999999998\n",
      "running_queries:  [(3, 8.191048)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 4\n",
      "current time:  13.947549\n",
      "running_queries:  [(3, 11.134987), (4, 3.539361)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 5\n",
      "current time:  14.096772999999997\n",
      "running_queries:  [(3, 16.593626), (4, 9.958356), (5, 7.920059)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 6\n",
      "current time:  14.946812999999997\n",
      "running_queries:  [(3, 16.750362), (4, 11.110214), (5, 16.9694), (6, 28.349092)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 7\n",
      "current time:  21.508418\n",
      "running_queries:  [(3, 17.215351), (4, 12.727586), (5, 14.164575), (6, 16.210505), (7, 14.09422)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 8\n",
      "current time:  35.192467\n",
      "running_queries:  [(8, 0.7508263)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 9\n",
      "current time:  35.815352\n",
      "running_queries:  [(8, 0.86094034), (9, 2.2970505)]\n",
      "queued_queries:  []\n",
      "False False\n",
      "============================== 10\n",
      "current time:  50.635465999999994\n",
      "running_queries:  [(10, 3.4959492683410645)]\n",
      "queued_queries:  []\n",
      "False False\n",
      "============================== 11\n",
      "current time:  60.663118\n",
      "running_queries:  [(11, 5.507226943969727)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 12\n",
      "current time:  62.92372199999999\n",
      "running_queries:  [(11, 6.7043233), (12, 4.8605795)]\n",
      "queued_queries:  []\n",
      "False False\n",
      "============================== 13\n",
      "current time:  68.096225\n",
      "running_queries:  [(13, 5.446142196655273)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 14\n",
      "current time:  68.568545\n",
      "running_queries:  [(13, 6.368451), (14, 0.7597669)]\n",
      "queued_queries:  []\n",
      "False False\n",
      "============================== 15\n",
      "current time:  95.472959\n",
      "running_queries:  [(15, 1.026253581047058)]\n",
      "queued_queries:  []\n",
      "False False\n",
      "============================== 16\n",
      "current time:  100.729884\n",
      "running_queries:  [(16, 10.061284065246582)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 17\n",
      "current time:  100.93143500000001\n",
      "running_queries:  [(16, 5.8924985), (17, 4.8988814)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 18\n",
      "current time:  102.03809100000001\n",
      "running_queries:  [(16, 6.8309364), (17, 4.9311967), (18, 0.052886654)]\n",
      "queued_queries:  []\n",
      "True False\n",
      "False False\n",
      "============================== 19\n",
      "current time:  104.813951\n",
      "running_queries:  [(16, 6.7743154), (17, 4.532351), (19, 2.2180746)]\n",
      "queued_queries:  []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "original_runtime = []\n",
    "all_start_time = concurrency_df[\"start_time\"].values\n",
    "all_query_idx = concurrency_df[\"query_idx\"].values\n",
    "for i in range(len(concurrency_df)):\n",
    "    original_runtime.append(original_predictions[i])\n",
    "    # replaying the query one-by-one\n",
    "    if i < len(concurrency_df):\n",
    "        next_query_start_time = all_start_time[i + 1]\n",
    "    else:\n",
    "        next_query_start_time = None\n",
    "    simulator.replay_one_query(all_start_time[i], next_query_start_time, i, all_query_idx[i])\n",
    "    print(\"==============================\", i)\n",
    "    scheduler.print_state()\n",
    "    if i == 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a581d9-893a-4165-adde-b060047441e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.replay_one_query(1.87, 2.76, 143, 143)\n",
    "scheduler.print_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
