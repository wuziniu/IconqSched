{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c22c477-d91e-4105-8faf-4f47a8305469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.load_brad_trace import load_trace, create_concurrency_dataset, load_trace_all_version\n",
    "from models.concurrency.analytical_models import SimpleFitCurve, ComplexFitCurve\n",
    "from models.concurrency.xgboost import XGBoostPredictor\n",
    "from models.concurrency.linear_regression import SimpleLinearReg\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06226fd1-03ad-4fb5-ba19-11108c4be863",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"mixed_aurora\"\n",
    "directory = f\"/Users/ziniuw/Desktop/research/Data/AWS_trace/{folder_name}/\"\n",
    "all_raw_trace, all_trace = load_trace_all_version(directory, 8, concat=True)\n",
    "all_concurrency_df = []\n",
    "for trace in all_trace:\n",
    "    concurrency_df = create_concurrency_dataset(trace, engine=None, pre_exec_interval=200)\n",
    "    all_concurrency_df.append(concurrency_df)\n",
    "concurrency_df = pd.concat(all_concurrency_df, ignore_index=True)\n",
    "isolated_trace_df = pd.read_csv(f\"/Users/ziniuw/Desktop/research/Data/AWS_trace/{folder_name}/repeating_olap_batch_warmup.csv\")\n",
    "#isolated_trace_df = pd.read_csv(f\"/Users/ziniuw/Desktop/research/Data/AWS_trace/mixed_redshift/repeating_olap_batch_warmup.csv\")\n",
    "isolated_trace_df[\"runtime\"] = isolated_trace_df[\"run_time_s\"]\n",
    "isolated_rt_cache = dict()\n",
    "for i, rows in isolated_trace_df.groupby(\"query_idx\"):\n",
    "    isolated_rt_cache[i] = np.median(rows[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d41f999-2e9a-4545-a17d-2d486cd4e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 23 2.397554874420166 6.9897928134254785 1.7361910343170166 46.89248514175415 9.473017881796181\n",
      "1 21 0.0336682796478271 0.042800471896216954 0.0306851863861084 0.064239501953125 0.008890692266292256\n",
      "2 25 20.54295063018799 77.7485980606079 36.011961460113525 176.65631198883057 32.84361507978263\n",
      "3 21 235.5201551914215 723.5043605055128 514.6219673156738 996.0332036018372 99.72439938805589\n",
      "4 23 75.73165822029114 183.26921186239824 95.24777936935423 322.1603753566742 57.0662497887613\n",
      "5 21 15.107906103134155 72.08878095944722 24.272745609283447 158.4005913734436 29.339563577499423\n",
      "6 22 37.87974190711975 103.16899719021536 31.87341856956482 219.7085883617401 39.49215570636949\n",
      "7 22 0.5295925140380859 0.9977116801521995 0.5253846645355225 3.6383426189422607 0.6118403643045283\n",
      "8 23 0.8444762229919434 5.961048416469408 0.2201185226440429 27.26981830596924 6.273220019590701\n",
      "9 22 0.678797721862793 0.1255583979866721 0.0557055473327636 0.851060152053833 0.1615357087075341\n",
      "10 21 0.0771567821502685 0.2136202653249105 0.0695333480834961 0.7829084396362305 0.15434167068471696\n",
      "11 23 6.227125883102417 16.184140288311504 3.430562973022461 45.53382992744446 11.56589882122229\n",
      "12 22 26.750946521759037 97.93932069431652 32.612547636032104 207.1578130722046 49.2795844012873\n",
      "13 21 1.1020281314849854 3.553691478002639 1.2702009677886963 26.018664360046387 5.163285756368686\n",
      "14 22 41.52834868431091 121.65024861422452 68.60875201225281 355.8027558326721 61.22873364603712\n",
      "15 24 0.3888075351715088 1.1881455580393474 0.3847522735595703 12.994544506072998 2.526401848092305\n",
      "16 22 9.33980107307434 86.16257793253118 33.57595729827881 207.65561723709104 34.170450739128796\n",
      "17 23 83.12843060493469 296.701534602953 150.557382106781 714.7422087192535 124.89011916788225\n",
      "18 21 0.035271406173706 0.05231070518493648 0.0365009307861328 0.1775989532470703 0.030540554844811114\n",
      "19 22 0.4481382369995117 0.771148605780168 0.4534749984741211 2.4920597076416016 0.4255168740559307\n",
      "20 22 26.68255186080933 82.32326952977614 40.248857259750366 177.3127408027649 33.84600055575649\n",
      "21 21 2.380606174468994 5.434237128212338 1.403172731399536 11.4060959815979 3.180699060858816\n",
      "22 21 31.556964874267575 146.55099364689417 50.740750789642334 245.94434309005737 46.78533437570987\n",
      "23 22 0.4093599319458008 1.1405333172191272 0.4207050800323486 8.06845474243164 1.5670959272019922\n",
      "24 23 13.285956859588625 82.94941455384959 20.430005311965942 147.41200256347656 27.945278132747145\n",
      "25 23 0.2962470054626465 5.1514595902484395 0.3191778659820556 30.13551950454712 7.971421426196254\n",
      "26 22 8.5355806350708 13.858905120329423 0.787994384765625 53.67154026031494 14.81072867126052\n",
      "27 23 39.25736117362976 108.32480989331785 51.50614285469055 232.39939308166504 44.21557453017148\n",
      "28 23 24.937642574310303 105.07014341976331 44.7848699092865 243.56090712547305 54.341192304711086\n",
      "29 23 10.210095167160034 78.1181552513786 27.248016119003296 132.98541021347046 29.22822119862054\n",
      "30 21 0.1120607852935791 0.4464929217383975 0.0796630382537841 6.172322511672974 1.2861362321151641\n",
      "31 24 0.9183123111724854 2.179687728484472 1.097135066986084 6.987371921539307 1.4937403667444848\n",
      "32 23 0.8550822734832764 7.327541475710661 0.8934240341186523 37.4722580909729 10.3170675150801\n",
      "33 23 0.3256962299346924 3.3361666098884912 0.3297452926635742 8.775776863098145 2.011919797947492\n",
      "34 24 122.98939394950868 254.37290877103806 87.80307221412659 653.0446753501892 121.0375202246764\n",
      "35 23 23.3917133808136 56.873718956242435 5.8984315395355225 197.13838958740237 35.64635680292319\n",
      "36 23 0.0645346641540527 0.46559014527694037 0.0600912570953369 1.7672019004821775 0.46807378733112637\n",
      "37 21 1.1734464168548584 4.61646200361706 0.1859669685363769 17.68986940383911 6.575947183779314\n",
      "38 23 30.455843925476078 93.31937108869138 35.11863565444946 199.28476572036743 41.844340739453045\n",
      "39 23 1.5877351760864258 16.006294437076736 4.954604148864746 40.002551555633545 9.50746742383308\n",
      "40 22 0.609882116317749 1.3407967198978772 0.3659403324127197 10.767824649810793 2.432932474477646\n",
      "41 22 0.3121485710144043 2.756193085150285 0.46712327003479 9.176797866821287 1.9604538044829078\n",
      "42 22 25.776408910751343 69.006073160605 14.993702411651611 150.88532829284668 34.59215689348754\n",
      "43 22 29.42440128326416 74.99094826524907 27.1892306804657 118.12181568145752 25.45183556578762\n",
      "44 21 0.5263023376464844 5.761021387009394 0.2777009010314941 35.48574471473694 9.126682999367434\n",
      "45 23 61.80804038047791 143.96716685917067 88.77582550048828 308.7940320968628 45.15153771845222\n",
      "46 22 0.4231984615325928 12.712100830945102 0.4721410274505615 44.26828932762146 13.756322364313823\n",
      "47 23 1.388341188430786 12.895637439644855 1.5947036743164062 45.08370780944824 13.550412228952998\n",
      "48 21 1.3969454765319824 11.670005071730841 1.53783917427063 38.86682796478272 11.875015844678163\n",
      "49 22 37.77339816093445 85.19459131630984 32.52388525009155 241.61110949516296 46.15450220267839\n",
      "50 21 2.032728433609009 8.749213888531639 2.314539670944214 47.67878985404968 10.262159335232615\n",
      "51 22 25.20745277404785 79.93191385269165 42.001489877700806 115.36010408401488 19.926647118098153\n",
      "52 23 39.98059368133545 149.9488203836524 85.70980405807495 274.9142861366272 48.04230334529152\n",
      "53 22 1.849722146987915 10.517767223444851 1.8766586780548096 34.3010094165802 9.037321276062059\n",
      "54 24 58.78784680366516 131.7462236781915 47.64624786376953 197.14332509040835 33.22483274067126\n",
      "55 21 7.702667951583862 75.17281503904434 13.731611728668211 176.56220650672913 38.05801342178196\n",
      "56 22 0.4916427135467529 1.948278633030978 0.5308547019958496 11.814286947250366 2.801353015137886\n",
      "57 21 1.139263153076172 3.5593993096124557 1.260359764099121 11.797884225845335 3.4327689443551486\n",
      "58 22 42.81422257423401 101.14834833145142 25.08626627922058 228.03829312324524 47.40871454452425\n",
      "59 21 28.34344244003296 90.91845714478265 23.18736886978149 301.95357966423035 55.54797089592566\n",
      "60 22 45.06873941421509 170.33297748999163 113.48154735565186 486.0422909259796 85.98268616575032\n",
      "61 23 40.38112235069275 109.53442872088888 26.0031418800354 264.3960039615631 47.129961576958216\n",
      "62 24 0.2423465251922607 1.4591027597586315 0.2927072048187256 4.759328365325928 1.0698165131064308\n",
      "63 25 24.04874062538147 78.44325522422791 7.753509759902954 186.36252284049988 38.799703556836725\n",
      "64 22 13.6708984375 70.5683312849565 11.53930640220642 151.28026127815247 32.57779394010435\n",
      "65 22 60.52810192108154 102.23685926740819 22.731439113616943 223.960725069046 58.7710671381136\n",
      "66 23 37.70097303390503 113.40419635565385 58.3717827796936 267.6595344543457 47.558438661404004\n",
      "67 21 0.3839783668518066 2.354116303580148 0.4122610092163086 15.706271886825562 4.368030924219535\n",
      "68 24 0.0308609008789062 0.04784828424453732 0.0309765338897705 0.0847311019897461 0.0157054722034861\n",
      "69 23 0.7467255592346191 13.699009615442026 0.9250617027282716 72.14889335632324 16.53732253351559\n",
      "70 23 2.726883172988892 8.313379888949187 1.2347121238708496 73.87405323982239 15.146908850049575\n",
      "71 21 19.239057540893555 77.46834682282947 21.77384305000305 140.95213079452515 29.023157812647515\n",
      "72 21 1.344194412231445 7.753480173292614 0.4556901454925537 51.065160512924194 11.741405638157978\n",
      "73 22 8.90050482749939 75.57090135054155 39.32475185394287 129.968496799469 27.75609102918256\n",
      "74 22 44.21470499038696 95.36021381074733 58.60454750061035 132.27711987495422 20.047600686983312\n",
      "75 21 9.610396146774292 135.944473584493 17.070606231689453 428.7037394046784 103.8326951628269\n",
      "76 22 0.8353226184844971 4.646890889514577 1.0417201519012451 18.70798134803772 5.055430141947348\n",
      "77 21 41.36648607254028 113.06622427985782 49.70887398719788 198.79279160499573 43.33204285642806\n",
      "78 22 6.559170484542847 21.822530562227424 3.6589317321777344 56.03164839744568 18.028479914131914\n",
      "79 22 12.496122598648071 76.29312864216891 32.812960624694824 124.0277988910675 28.402733928775017\n",
      "80 21 44.54309511184693 176.58923847334725 117.07256269454956 285.1414449214936 44.596977090625785\n",
      "81 22 0.4250683784484863 0.6913110126148571 0.4374122619628906 3.384938240051269 0.5941385237422833\n",
      "82 22 45.24423313140869 141.10768856785515 65.88829970359802 291.6165261268616 55.77865137641481\n",
      "83 23 981.87251496315 84.22061536623085 36.78687596321106 220.6294207572937 40.13655845380976\n",
      "84 22 38.97897529602051 149.64852272380483 96.5650315284729 291.25213742256165 42.03771238770476\n",
      "85 22 58.89505934715271 73.6228896704587 35.713664531707764 106.81664443016052 21.096835261016622\n",
      "86 23 13.007020235061646 6.947554038918537 0.3404839038848877 40.45940613746643 10.271738295312712\n",
      "87 21 3.7628350257873535 2.4319453012375605 0.5967526435852051 12.043309926986694 2.8758970422460033\n",
      "88 23 0.5695405006408691 2.324500913205354 0.286278486251831 4.895215272903442 1.5512542740631992\n",
      "89 23 0.2282626628875732 222.56775829066402 133.6943244934082 305.0563879013061 44.166073637820986\n",
      "90 21 95.88815259933472 3.1881836028326127 0.290177583694458 16.028655767440796 4.975333377706963\n",
      "91 21 468.5002930164337 80.48511927468437 32.20046639442444 124.76345348358154 24.730666294482017\n",
      "92 22 0.2842040061950683 80.79885745048523 16.70511794090271 154.65073800086975 34.64132856341455\n",
      "93 22 23.863335371017456 3.256664893843911 1.0646820068359375 14.19463348388672 3.7840352495223173\n",
      "94 23 28.65204787254333 0.5530317866283915 0.0869719982147216 6.725616931915283 1.4112736283519975\n",
      "95 23 0.9707796573638916 3.7092023310453994 1.24164080619812 12.7912859916687 2.684786142838576\n",
      "96 22 0.0824153423309326 83.97920060157776 43.73636293411255 203.8058249950409 40.45471029038828\n",
      "97 22 0.4933245182037353 5.452858610586687 1.2804481983184814 16.276411771774292 4.471955555436982\n",
      "98 22 22.00653100013733 22.883476885882292 4.518856525421143 67.91768789291382 17.38669667202203\n",
      "99 23 1.0290839672088623 77.47791044608407 31.519620180130005 132.8948802947998 26.17853707959575\n",
      "100 23 3.867759704589844 11.579320295997288 1.5697932243347168 37.58251619338989 10.574327628076261\n",
      "101 22 19.90601110458374 67.29679828340358 19.30060315132141 120.02665877342224 26.62881568182861\n",
      "102 22 1.8290839195251465 1.8975270011208274 1.330045223236084 3.157266139984131 0.5267814717129871\n",
      "103 24 23.411291360855103 2.7545248667399087 1.1737103462219238 17.56958556175232 3.527825417797858\n",
      "104 23 1.1419994831085205 22.232826948165894 4.196043968200684 103.95571899414062 22.183755251424635\n",
      "105 21 1.16880464553833 9.656908092044649 1.1033194065093994 29.699135303497314 6.563041840811933\n",
      "106 22 4.371509790420532 2.328883864662864 1.003007173538208 17.181044101715088 3.2737854053464317\n",
      "107 22 1.8667912483215328 5.7009205709804185 2.4195821285247803 22.38631629943848 5.190346379989339\n",
      "108 23 1.0081393718719482 1.2927281960197117 0.6930716037750244 8.075559139251709 1.4707821392805593\n",
      "109 21 2.1964070796966557 27.44436885061718 4.572751998901367 61.06359529495239 15.56694194509429\n",
      "110 23 0.6800353527069092 12.909786369489586 2.5046629905700684 60.078739404678345 12.841040710888068\n",
      "111 21 2.5733885765075684 11.61001341683524 6.215322732925415 33.397823095321655 5.55236954963328\n",
      "112 21 2.1411075592041016 4.829705272402082 1.2133421897888184 38.55197834968567 8.379655975190108\n",
      "113 22 5.171602010726929 78.0311341827566 30.808438062667847 194.97879123687744 45.88233484072781\n",
      "114 23 1.2303364276885986 65.45244091490041 11.744507551193236 147.36590051651 32.17840406424458\n",
      "115 22 16.711405754089355 1.8201952955939553 1.2246253490447998 3.3149421215057373 0.6376000607279703\n",
      "116 23 24.473872900009155 12.619767375614332 7.380224704742432 20.971259355545044 3.9862642974424944\n",
      "117 23 1.2199440002441406 1.2430855191272239 0.3335855007171631 13.451581239700316 2.7149982627557425\n",
      "118 21 6.079718112945557 20.293491738183157 4.087346792221069 46.14321994781494 10.913101306604373\n",
      "119 23 0.3291952610015869 1.7890461216802183 0.5712568759918213 6.370089769363403 1.4833425923382053\n",
      "120 23 3.2935023307800293 9.46748461930648 4.60681676864624 16.42377281188965 3.427229588033325\n",
      "121 22 0.5107026100158691 14.618619973009283 3.4381837844848637 59.53220510482788 14.65250458807275\n",
      "122 23 4.806821823120117 18.384831459625907 2.7014896869659424 55.40261197090149 14.216060863100948\n",
      "123 22 3.11295747756958 1.2595521970228716 0.2808420658111572 2.905582427978516 0.8757733821192429\n",
      "124 22 2.409074306488037 7.684159376404502 2.331825256347656 31.01224255561829 8.80539057898524\n",
      "125 22 0.3088698387145996 2.1288703138178047 0.5419504642486572 12.097370386123655 3.0785258655880368\n",
      "126 22 2.0571112632751465 3.207423513585871 0.5687918663024902 51.795021295547485 10.604620315385041\n",
      "127 21 0.5210597515106201 37.711857296171644 4.24920392036438 102.75732731819151 20.570393015731273\n",
      "128 23 0.5751469135284424 11.448117028111996 1.941819667816162 44.096232414245605 10.738539598469442\n",
      "129 22 7.098636388778687 83.85551928390156 27.150004625320435 189.17943167686465 34.033262538523985\n",
      "130 21 2.0346944332122803 84.44872096606663 31.84046244621277 134.62761306762695 25.716983760164005\n",
      "131 21 25.644712209701535 14.687898556391398 2.466801404953003 49.92515110969544 13.071565722114748\n",
      "132 22 21.0562846660614 2.8233367746526543 0.2618594169616699 16.478155851364136 3.256633268835343\n",
      "133 22 3.645643949508667 3.110214190049605 0.9921903610229492 32.48973608016968 6.45899473883162\n",
      "134 22 0.2979004383087158 2.5663458542390303 0.9920444488525392 15.601428270339966 3.1331175658409784\n",
      "135 23 0.8806166648864746 1.0865437362505042 0.6856386661529541 4.890574216842651 0.8236451259782509\n",
      "136 23 0.982201337814331 4.610276284425155 1.2069716453552246 29.66314196586609 6.177505194958249\n",
      "137 23 0.6869444847106934 4.789511991583782 1.008424997329712 30.54637026786804 6.024743409486969\n",
      "138 22 0.999781608581543 8.943389957601374 5.288976669311523 26.94955277442932 4.933215903631969\n",
      "139 22 0.8672997951507568 46.29782126166604 16.72199773788452 105.11087536811829 23.405388165504018\n",
      "140 25 4.771123170852661 1.2910929107666016 0.8654930591583252 3.276896476745605 0.49578979486321423\n",
      "141 22 15.345102787017822 68.07453658364035 17.479447841644287 130.52339124679563 29.442226002619808\n",
      "142 22 0.8703880310058594 7.9041785110126845 2.526639699935913 34.093987464904785 8.742918710338458\n",
      "143 23 14.8991539478302 1.121874933657439 0.3190207481384277 8.235247611999512 2.018489424505436\n",
      "144 24 2.511554002761841 3.1659750640392303 0.9391560554504396 21.347491025924683 4.858840603866207\n",
      "145 22 0.2933714389801025 7.933146249164235 2.9898946285247803 26.26517081260681 7.013369116673425\n",
      "146 21 0.9329400062561036 6.2512941133408315 3.0481278896331787 27.33660864830017 6.134351176288122\n",
      "147 21 2.8047914505004883 15.747480051858085 2.7090420722961426 52.08040452003479 13.489203109908642\n",
      "148 22 2.7878215312957764 20.49346842549064 2.30593204498291 85.8226969242096 21.730958135519536\n",
      "149 22 3.1228485107421875 3.1129196882247925 0.2951583862304687 13.928056240081789 3.1639649520974222\n",
      "150 22 2.0293333530426025 3.0276954499157993 0.4562215805053711 10.519112586975098 3.2044902300031786\n",
      "151 21 0.6858911514282227 4.380622909182594 2.025691509246826 16.45615530014038 3.365126159628521\n",
      "152 23 0.755352258682251 4.730573249899822 0.893061637878418 30.65226984024048 7.984516628804794\n",
      "153 22 1.8165926933288572 6.850707465952093 1.7476646900177002 53.51321792602539 11.624101920146275\n",
      "154 24 0.8053956031799316 2.9001413583755493 0.7342977523803711 17.13459277153015 3.7078803664451425\n",
      "155 21 1.5254631042480469 2.333273785454886 0.8108980655670166 17.115768432617188 3.5093848750003356\n",
      "156 23 0.6836025714874268 7.882217718207317 0.8241941928863525 36.855406045913696 9.454435073438807\n",
      "157 23 0.7958602905273438 42.10974233046822 3.297377109527588 89.77678418159485 23.51104262866245\n",
      "158 22 0.8037869930267334 15.102368029681118 4.302280902862549 41.659311294555664 10.400000726915014\n",
      "159 24 8.512287855148315 33.84521226088206 11.266900777816772 79.94401693344116 17.28449427154097\n",
      "160 22 3.692734718322754 11.57721152088859 6.631659984588623 39.33760976791382 7.269350108530884\n",
      "161 21 10.16050910949707 12.328590654191517 0.6996066570281982 46.13150835037232 13.48574865098746\n",
      "162 22 5.946537733078003 2.788287325338884 1.2499165534973145 5.693975210189819 1.0538300913422884\n",
      "163 22 2.499530792236328 2.1872355937957764 1.6517786979675293 3.6145739555358887 0.4665915929201005\n",
      "164 22 1.1602230072021484 76.43051666563207 33.08474898338318 175.02177357673645 33.712013952976896\n",
      "165 22 1.609571933746338 7.145354856144298 2.3616297245025635 17.331918239593506 3.850639934228613\n",
      "166 22 31.27477765083313 2.5641808943314985 0.4203650951385498 5.18537187576294 1.3252315402942698\n",
      "167 22 1.606152057647705 10.175597689368509 1.4109277725219729 32.88277006149292 9.125939987940926\n",
      "168 23 0.4374182224273681 19.898294842761494 2.664159774780273 66.52572631835938 19.917767688393518\n",
      "169 21 7.152820587158203 11.027541444415139 1.6414763927459717 46.60490393638611 14.273584924961984\n",
      "170 23 2.12162446975708 64.78216194069904 29.03904509544373 112.90327072143556 21.91745573689826\n",
      "171 23 1.259871482849121 100.08946014487225 33.899468660354614 224.8640305995941 45.9875369416068\n",
      "172 24 30.21223545074463 4.322989990313848 1.0523478984832764 14.020894289016724 2.7189431737998557\n",
      "173 22 17.812341451644897 12.849268447269093 1.7162604331970217 46.43105959892273 11.937108666170674\n",
      "174 22 0.8436546325683594 9.297147111459212 3.0626087188720703 40.07661724090576 10.13529082041521\n",
      "175 22 3.4518463611602783 13.685023470358415 0.8530962467193604 70.06083655357361 15.611460090562437\n",
      "176 23 2.694579601287842 1.864891995554385 0.2644200325012207 4.755562782287598 1.0364479591072253\n",
      "177 22 1.2450754642486572 8.595370986244895 2.5905799865722656 34.51447916030884 7.661410791883313\n",
      "178 21 0.2616326808929443 5.032455614634922 1.937152862548828 9.70620822906494 2.1571839414662923\n",
      "179 22 2.4262523651123047 8.849479469386013 1.3849363327026367 21.721774101257324 5.17031307876472\n",
      "180 22 1.900059938430786 8.160470886663957 2.8793275356292725 42.35310816764832 9.376339263615016\n",
      "181 22 1.243912935256958 85.45789888772097 43.23809313774109 178.899484872818 37.31192465213068\n",
      "182 21 2.3678290843963623 7.36290777297247 2.92673134803772 33.42267203330994 7.935166446290364\n",
      "183 22 23.26820039749145 2.249464349313216 0.9468071460723876 11.298260927200316 2.1888924799661145\n",
      "184 22 2.5252022743225098 1.19573251767592 0.320974588394165 3.110873222351074 0.8168358612102534\n",
      "185 22 0.8408138751983643 149.34691302342847 93.7652678489685 312.9784755706787 46.81871656040441\n",
      "186 23 0.2815275192260742 31.259340711261917 6.909365177154541 63.96453857421875 13.32033044952546\n",
      "187 21 46.379104137420654 117.96392015048436 33.771538496017456 311.5895755290985 61.66256427002115\n",
      "188 21 8.869046926498413 6.763978549412319 3.0512139797210693 14.117905855178831 3.2113553146260223\n",
      "189 22 21.76157641410828 77.89482564275914 8.278306245803833 141.15684366226196 31.13421402813448\n",
      "190 21 2.791912794113159 22.058679512568883 3.0406899452209477 57.95078039169312 16.726401245233905\n",
      "191 22 27.728280067443848 8.201946724544872 2.1143031120300293 57.00207257270813 13.393039129708507\n",
      "192 24 4.888513803482056 8.486270795265833 1.576545476913452 24.660470724105835 7.780420750520243\n",
      "193 23 1.9896841049194336 1.4468092503754988 0.7624084949493408 3.779869079589844 0.7699500074186115\n",
      "194 21 1.8841726779937744 6.289422057923817 0.5343422889709473 30.837279558181763 7.803235895351248\n",
      "195 21 0.7510271072387695 3.1241930552891324 1.4059646129608154 19.46186351776123 3.723672360251556\n",
      "196 21 0.5192720890045166 10.27056360244751 1.546576976776123 33.26722073554993 8.353118981372587\n",
      "197 23 1.404429912567139 16.753890586935956 3.881973028182984 44.940425395965576 11.323055400793839\n",
      "198 21 1.2696046829223633 11.049244426545643 1.2445194721221924 22.77516293525696 6.526211503667827\n",
      "199 23 3.1951797008514404 5.402899918348893 0.2515103816986084 20.601592302322388 6.276732404322158\n",
      "200 21 1.9799160957336424 1.3782379854293096 0.8298585414886475 4.394127130508423 0.8508976471131264\n",
      "201 21 0.7229652404785156 26.6461923463004 7.903535604476929 59.451338052749634 12.593690265951384\n",
      "202 22 0.7359452247619629 4.475379781289534 1.253969669342041 17.879129886627197 4.974236088009141\n",
      "203 23 4.579397201538086 40.694656092187635 8.31274700164795 74.59437036514282 16.969947189030414\n",
      "204 23 3.126350164413452 30.75874907037486 1.0233378410339355 61.073673248291016 18.078341304873508\n",
      "205 23 9.998357057571411 8.254718645759251 0.9241514205932616 30.119948387146 9.702713048820312\n",
      "206 21 1.1823289394378662 25.673311210813978 7.045467853546143 55.03525924682617 10.754892326316245\n",
      "207 23 1.1905736923217771 4.416593188824861 0.2831106185913086 28.64644503593445 6.514704294644784\n",
      "208 22 3.453319311141968 1.0514701821587302 0.8068385124206543 2.2281007766723637 0.30304960318228197\n",
      "209 22 1.196462869644165 69.90013940767808 16.92854142189026 142.28639459609985 28.071410863802566\n",
      "210 22 0.7399506568908691 4.416621750051325 1.4406123161315918 20.04443049430847 5.230914445113469\n",
      "211 21 21.074706077575684 34.79291226750328 16.681540966033936 74.12308144569397 15.158877337138032\n",
      "212 21 3.934786796569824 42.75169053531828 1.3540349006652832 109.68615293502808 23.525600531397068\n",
      "213 21 10.046723127365112 10.432622035344442 1.0074577331542969 33.745914697647095 10.28230214240583\n",
      "214 21 1.2089297771453855 20.495909713563464 2.092978477478028 55.31604599952698 12.231763982131712\n",
      "215 22 1.329408884048462 4.3642532933842055 0.2688074111938476 21.171883583068848 6.045250378903435\n",
      "216 23 2.350749492645264 1.4949048602062722 0.7412440776824951 7.04738712310791 1.2910629633104191\n",
      "217 22 0.2431106567382812 53.664253971793435 11.63814926147461 135.71746301651 30.61670681208299\n",
      "218 23 1.481129169464111 6.298652514167454 1.1327030658721924 28.302945613861084 8.157074691447537\n",
      "219 24 20.44100069999695 38.35017208258311 7.370096445083618 88.79821443557739 20.746413970965165\n",
      "220 22 1.4564673900604248 38.91587959636342 1.316429615020752 88.72879838943481 22.81557887860686\n",
      "221 22 8.174384832382202 10.31762222810225 0.8606002330780029 71.89394974708557 14.855879586640068\n",
      "222 23 1.1080007553100586 21.260715629743494 1.991410732269287 53.1753089427948 14.251583401078022\n",
      "223 22 1.6218647956848145 3.4127743569287388 0.2600812911987304 19.34111976623535 5.782953617582383\n",
      "224 23 1.496246099472046 3.016734911047894 0.7406561374664307 25.557674407958984 5.962266237570054\n",
      "225 23 0.2420911788940429 67.08286866934404 26.55039358139038 163.36516547203064 28.107484947799605\n",
      "226 21 0.7574784755706787 4.708903131030855 1.4419441223144531 23.94285821914673 6.498686299765802\n",
      "227 23 18.59429621696472 39.74737929261249 12.68664288520813 97.86278200149536 19.597563349410397\n",
      "228 23 1.2225255966186523 31.43480763228043 2.9766883850097656 66.7907919883728 16.378024544667518\n",
      "229 24 4.659992456436157 9.244151363770166 1.0800631046295166 31.72947645187378 8.851340451645562\n",
      "230 22 7.907375574111938 32.15473556518555 6.256954193115234 95.9319143295288 20.047355283686183\n",
      "231 22 2.5898468494415283 5.648239244114269 0.2666065692901611 20.82340693473816 6.937012961374777\n",
      "232 22 4.505531549453735 1.183630802414634 0.7382781505584717 4.55221152305603 0.7800157187480268\n",
      "233 22 0.7773704528808594 54.14423330263658 5.170088529586792 136.9858582019806 28.261302036073467\n",
      "234 21 1.275571346282959 7.978255760102045 1.229769945144653 28.60218620300293 9.636172521855322\n",
      "235 22 14.71896243095398 33.85423584417863 1.6529569625854492 74.15129446983337 17.347147153740092\n",
      "236 22 4.048619508743286 32.882757512005895 1.0168726444244385 69.82897281646729 21.98947186750301\n",
      "237 23 1.3037900924682615 12.358581035033517 1.019498586654663 37.041926860809326 12.023784175165979\n"
     ]
    }
   ],
   "source": [
    "for i, rows in concurrency_df.groupby(\"query_idx\"):\n",
    "    runtime = rows[\"runtime\"].values\n",
    "    print(i, len(rows), isolated_rt_cache[i], np.mean(runtime), np.min(runtime), np.max(runtime), np.std(runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baed6340-0010-4701-ab3a-fe7dbd0f05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train_idx = np.random.choice(len(concurrency_df), size=int(0.8 * len(concurrency_df)), replace=False)\n",
    "test_idx = [i for i in range(len(concurrency_df)) if i not in train_idx]\n",
    "eval_trace_df = concurrency_df.iloc[test_idx]\n",
    "eval_trace_df = eval_trace_df[eval_trace_df['num_concurrent_queries'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c83529b-a7d2-4f17-a7cf-25749e882269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import l1_loss\n",
    "import scipy.optimize as optimization\n",
    "from torch.utils.data import DataLoader\n",
    "from models.concurrency.base_model import ConcurPredictor\n",
    "from models.concurrency.utils import QueryFeatureDataset, SimpleNet\n",
    "from models.concurrency.analytical_functions import simple_queueing_func, interaction_func_torch, interaction_func_scipy\n",
    "from parser.utils import load_json, dfs_cardinality, estimate_scan_in_mb\n",
    "\n",
    "\n",
    "class SimpleFitCurve(ConcurPredictor):\n",
    "    \"\"\"\n",
    "    Simple fit curve model for runtime prediction with concurrency\n",
    "    runtime = queue_time(num_concurrency) + alpha(num_concurrency) * isolated_runtime\n",
    "            = (a1 * max(num_concurrency-b1, 0)) + (1 + a2*min(num_concurrency, b1)) * isolated_runtime\n",
    "    optimize a1, b1, b2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.isolated_rt_cache = dict()\n",
    "        self.use_train = True\n",
    "        self.a1_global = 0\n",
    "        self.a1 = dict()\n",
    "        self.b1_global = 0\n",
    "        self.b1 = dict()\n",
    "        self.a2_global = 0\n",
    "        self.a2 = dict()\n",
    "\n",
    "    def train(self, trace_df, use_train=True, isolated_trace_df=None):\n",
    "        self.use_train = use_train\n",
    "        self.get_isolated_runtime_cache(trace_df, isolated_trace_df)\n",
    "        concurrent_df = trace_df[trace_df[\"num_concurrent_queries\"] > 0]\n",
    "\n",
    "        global_y = []\n",
    "        global_x = []\n",
    "        global_ir = []\n",
    "        for i, rows in concurrent_df.groupby(\"query_idx\"):\n",
    "            if i not in self.isolated_rt_cache:\n",
    "                continue\n",
    "            isolated_rt = self.isolated_rt_cache[i]\n",
    "            concurrent_rt = rows[\"runtime\"].values\n",
    "            if use_train:\n",
    "                num_concurrency = rows[\"num_concurrent_queries_train\"].values\n",
    "            else:\n",
    "                num_concurrency = rows[\"num_concurrent_queries\"].values\n",
    "            if len(num_concurrency) < 10:\n",
    "                continue\n",
    "            global_y.append(concurrent_rt)\n",
    "            global_x.append(num_concurrency)\n",
    "            global_ir.append(np.ones(len(num_concurrency)) * isolated_rt)\n",
    "            fit, _ = optimization.curve_fit(\n",
    "                simple_queueing_func,\n",
    "                (num_concurrency, np.ones(len(num_concurrency)) * isolated_rt),\n",
    "                concurrent_rt,\n",
    "                np.array([5, 0.1, 20]),\n",
    "            )\n",
    "            self.a1[i] = fit[0]\n",
    "            self.a2[i] = fit[1]\n",
    "            self.b1[i] = fit[2]\n",
    "        global_y = np.concatenate(global_y)\n",
    "        global_x = np.concatenate(global_x)\n",
    "        global_ir = np.concatenate(global_ir)\n",
    "        fit, _ = optimization.curve_fit(\n",
    "            simple_queueing_func,\n",
    "            (global_x, global_ir),\n",
    "            global_y,\n",
    "            np.array([5, 0.1, 20]),\n",
    "        )\n",
    "        self.a1_global = fit[0]\n",
    "        self.a2_global = fit[1]\n",
    "        self.b1_global = fit[2]\n",
    "\n",
    "    def predict(self, eval_trace_df, use_global=False):\n",
    "        predictions = dict()\n",
    "        labels = dict()\n",
    "        for i, rows in eval_trace_df.groupby(\"query_idx\"):\n",
    "            if i not in self.isolated_rt_cache or i not in self.a1:\n",
    "                continue\n",
    "            isolated_rt = self.isolated_rt_cache[i]\n",
    "            label = rows[\"runtime\"].values\n",
    "            labels[i] = label\n",
    "            if self.use_train:\n",
    "                num_concurrency = rows[\"num_concurrent_queries_train\"].values\n",
    "            else:\n",
    "                num_concurrency = rows[\"num_concurrent_queries\"].values\n",
    "            x = (num_concurrency, np.ones(len(num_concurrency)) * isolated_rt)\n",
    "            if use_global:\n",
    "                pred = simple_queueing_func(\n",
    "                    x, self.a1_global, self.a2_global, self.b1_global\n",
    "                )\n",
    "            else:\n",
    "                pred = simple_queueing_func(x, self.a1[i], self.a2[i], self.b1[i])\n",
    "            pred = np.maximum(pred, 0.001)\n",
    "            predictions[i] = pred\n",
    "        return predictions, labels\n",
    "\n",
    "\n",
    "def fit_curve_loss_torch(x, y, params, constrain, loss_func=\"soft_l1\", penalties=None):\n",
    "    pred = interaction_func_torch(x, *params)\n",
    "    lb = constrain.lb\n",
    "    ub = constrain.ub\n",
    "    if loss_func == \"mae\":\n",
    "        loss = torch.abs(pred - y)\n",
    "    elif loss_func == \"mse\":\n",
    "        loss = (pred - y) ** 2\n",
    "    elif loss_func == \"soft_l1\":\n",
    "        loss = torch.sqrt(1 + (pred - y) ** 2) - 1\n",
    "    else:\n",
    "        assert False, f\"loss func {loss_func} not implemented\"\n",
    "    loss = torch.mean(loss)\n",
    "    for i, p in enumerate(params):\n",
    "        if penalties is not None:\n",
    "            penalty = penalties[i]\n",
    "        else:\n",
    "            penalty = 1\n",
    "        pen = torch.exp(penalty * (p - ub[i])) + torch.exp(-1 * penalty * (p - lb[i]))\n",
    "        loss += pen\n",
    "    return loss\n",
    "\n",
    "\n",
    "class ComplexFitCurve(ConcurPredictor):\n",
    "    \"\"\"\n",
    "    Complex fit curve model for runtime prediction with concurrency\n",
    "    See interaction_func_scipy for detailed analytical functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, is_column_store=False, opt_method='scipy'):\n",
    "        \"\"\"\n",
    "\n",
    "        :param is_column_store:\n",
    "        :param opt_method:\n",
    "        \"\"\"\n",
    "        # indicate whether the DBMS is a column_store\n",
    "        #\n",
    "        super().__init__()\n",
    "        self.isolated_rt_cache = dict()\n",
    "        self.average_rt_cache = dict()\n",
    "        self.query_info = dict()\n",
    "        self.db_stats = None\n",
    "        self.table_sizes = dict()\n",
    "        self.table_sizes_by_index = dict()\n",
    "        self.table_nrows_by_index = dict()\n",
    "        self.table_column_map = dict()\n",
    "        self.use_pre_info = False\n",
    "        self.use_post_info = False\n",
    "        self.is_column_store = is_column_store\n",
    "        self.opt_method = opt_method\n",
    "        self.batch_size = 1024\n",
    "        self.analytic_params = [0.5, 20, 2, 0.2, 0.5, 0.5, 0.1, 0.2, 0.8, 0.2, 10, 200, 16000]\n",
    "        self.bound = optimization.Bounds(\n",
    "            [0.1, 10, 0.01, 0.001, 0.001, 0.001, 0.001, 0.001, 0.5, 0.05, 2, 20, 10000],\n",
    "            [1, 200, 2, 1, 0.9, 0.9, 0.5, 0.5, 0.95, 0.4, 20, 2000, 50000],\n",
    "        )\n",
    "        self.constrain = optimization.Bounds(\n",
    "            [0.1, 10, 0.1, 0.01, 0.01, 0.01, 0.01, 0.1, 0.5, 0.05, 2, 20, 10000],\n",
    "            [1, 200, 2, 1, 0.9, 0.9, 0.5, 0.5, 0.95, 0.4, 20, 2000, 50000],\n",
    "        )\n",
    "        self.penalty = [100, 0.1, 100, 100, 100, 100, 100, 100, 100, 100, 1, 0.1, 0.01]\n",
    "        self.loss_func = \"soft_l1\"\n",
    "        self.model = None\n",
    "        self.analytic_func = None\n",
    "\n",
    "    def _compute_table_size(self):\n",
    "        for col in self.db_stats[\"column_stats\"]:\n",
    "            table = col[\"tablename\"]\n",
    "            if table not in self.table_column_map:\n",
    "                self.table_sizes[table] = 0\n",
    "                self.table_column_map[table] = []\n",
    "            self.table_column_map[table].append(col[\"attname\"])\n",
    "            if col[\"avg_width\"] is not None and col[\"avg_width\"] > 0:\n",
    "                self.table_sizes[table] += col[\"avg_width\"]\n",
    "        all_table_names = [t[\"relname\"] for t in self.db_stats[\"table_stats\"]]\n",
    "        for table in self.table_sizes:\n",
    "            if table in all_table_names:\n",
    "                idx = all_table_names.index(table)\n",
    "                num_tuples = self.db_stats[\"table_stats\"][idx][\"reltuples\"]\n",
    "                self.table_nrows_by_index[idx] = num_tuples\n",
    "                size_in_mb = (num_tuples * self.table_sizes[table]) / (1024 * 1024)\n",
    "                self.table_sizes[table] = size_in_mb\n",
    "                self.table_sizes_by_index[idx] = size_in_mb\n",
    "\n",
    "    def pre_process_queries(\n",
    "        self, parsed_queries_path, with_width=True, use_true_card=False\n",
    "    ):\n",
    "        plans = load_json(parsed_queries_path, namespace=False)\n",
    "        self.db_stats = plans[\"database_stats\"]\n",
    "        self._compute_table_size()\n",
    "        self.query_info = dict()\n",
    "        for i in range(len(plans[\"sql_queries\"])):\n",
    "            curr_query_info = dict()\n",
    "            curr_query_info[\"sql\"] = plans[\"sql_queries\"][i]\n",
    "            all_cardinality = []\n",
    "            dfs_cardinality(\n",
    "                plans[\"parsed_plans\"][i], all_cardinality, with_width, use_true_card\n",
    "            )\n",
    "            curr_query_info[\"all_cardinality\"] = all_cardinality\n",
    "            est_scan, est_scan_per_table = estimate_scan_in_mb(\n",
    "                self.db_stats,\n",
    "                plans[\"parsed_queries\"][i],\n",
    "                use_true_card,\n",
    "                self.is_column_store,\n",
    "            )\n",
    "            curr_query_info[\"est_scan\"] = est_scan\n",
    "            curr_query_info[\"est_scan_per_table\"] = est_scan_per_table\n",
    "            self.query_info[i] = curr_query_info\n",
    "\n",
    "    def estimate_data_share_percentage(self, idx, concur_info, pre_exec_info=None):\n",
    "        # TODO: make it smarter by considering buffer pool behavior\n",
    "        curr_scan = self.query_info[idx][\"est_scan_per_table\"]\n",
    "        curr_total_scan = self.query_info[idx][\"est_scan\"]\n",
    "        if pre_exec_info is not None:\n",
    "            concur_info = concur_info + pre_exec_info\n",
    "        all_shared_scan = 0\n",
    "        for table in curr_scan:\n",
    "            table_size = self.table_sizes_by_index[table]\n",
    "            table_shared_scan = 0\n",
    "            for c in concur_info:\n",
    "                concur_scan = self.query_info[c[0]][\"est_scan_per_table\"]\n",
    "                if table in concur_scan:\n",
    "                    concur_scan_perc = concur_scan[table] / table_size\n",
    "                    overlap_scan = concur_scan_perc * curr_scan[table]\n",
    "                    table_shared_scan += overlap_scan\n",
    "            table_shared_scan = min(table_shared_scan, curr_scan[table])\n",
    "            all_shared_scan += table_shared_scan\n",
    "        return min(all_shared_scan / curr_total_scan, 1.0)\n",
    "\n",
    "    def featurize_data(self, concurrent_df):\n",
    "        global_y = []\n",
    "        global_isolated_runtime = []\n",
    "        global_avg_runtime = []\n",
    "        global_num_concurrency = []\n",
    "        global_sum_concurrent_runtime = []\n",
    "        global_est_scan = []\n",
    "        global_est_concurrent_scan = []\n",
    "        global_scan_sharing_percentage = []\n",
    "        global_max_est_card = []\n",
    "        global_avg_est_card = []\n",
    "        global_max_concurrent_card = []\n",
    "        global_avg_concurrent_card = []\n",
    "        global_query_idx = dict()\n",
    "        start = 0\n",
    "        for i, rows in concurrent_df.groupby(\"query_idx\"):\n",
    "            if (\n",
    "                i not in self.isolated_rt_cache\n",
    "                or i not in self.query_info\n",
    "                or i not in self.average_rt_cache\n",
    "            ):\n",
    "                continue\n",
    "            concurrent_rt = rows[\"runtime\"].values\n",
    "            query_info = self.query_info[i]\n",
    "            n_rows = len(rows)\n",
    "            if self.use_pre_info:\n",
    "                num_concurrency = rows[\"num_concurrent_queries_train\"].values\n",
    "                concur_info = rows[\"concur_info_train\"].values\n",
    "            else:\n",
    "                num_concurrency = rows[\"num_concurrent_queries\"].values\n",
    "                concur_info = rows[\"concur_info\"].values\n",
    "            pre_exec_info = rows[\"pre_exec_info\"].values\n",
    "\n",
    "            global_query_idx[i] = (start, start + n_rows)\n",
    "            start += n_rows\n",
    "            global_y.append(concurrent_rt)\n",
    "            global_isolated_runtime.append(np.ones(n_rows) * self.isolated_rt_cache[i])\n",
    "            global_avg_runtime.append(np.ones(n_rows) * self.average_rt_cache[i])\n",
    "            global_num_concurrency.append(num_concurrency)\n",
    "            global_est_scan.append(np.ones(n_rows) * query_info[\"est_scan\"])\n",
    "            global_max_est_card.append(\n",
    "                np.ones(n_rows) * np.max(query_info[\"all_cardinality\"]) / (1024 * 1024)\n",
    "            )\n",
    "            global_avg_est_card.append(\n",
    "                np.ones(n_rows)\n",
    "                * np.average(query_info[\"all_cardinality\"])\n",
    "                / (1024 * 1024)\n",
    "            )\n",
    "            for j in range(n_rows):\n",
    "                sum_concurrent_runtime = 0\n",
    "                sum_concurrent_scan = 0\n",
    "                concurrent_card = []\n",
    "                for c in concur_info[j]:\n",
    "                    if c[0] in self.average_rt_cache:\n",
    "                        sum_concurrent_runtime += self.average_rt_cache[c[0]]\n",
    "                    else:\n",
    "                        print(c[0])\n",
    "                    if c[0] in self.query_info:\n",
    "                        sum_concurrent_scan += self.query_info[c[0]][\"est_scan\"]\n",
    "                        concurrent_card.extend(self.query_info[c[0]][\"all_cardinality\"])\n",
    "                    else:\n",
    "                        print(c[0])\n",
    "\n",
    "                global_sum_concurrent_runtime.append(sum_concurrent_runtime)\n",
    "                global_est_concurrent_scan.append(sum_concurrent_scan)\n",
    "                if len(concurrent_card) == 0:\n",
    "                    global_max_concurrent_card.append(0)\n",
    "                    global_avg_concurrent_card.append(0)\n",
    "                else:\n",
    "                    global_max_concurrent_card.append(\n",
    "                        np.max(concurrent_card) / (1024 * 1024)\n",
    "                    )\n",
    "                    global_avg_concurrent_card.append(\n",
    "                        np.average(concurrent_card) / (1024 * 1024)\n",
    "                    )\n",
    "                global_scan_sharing_percentage.append(\n",
    "                    self.estimate_data_share_percentage(\n",
    "                        i, concur_info[j], pre_exec_info[j]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        global_y = np.concatenate(global_y)\n",
    "        global_isolated_runtime = np.concatenate(global_isolated_runtime)\n",
    "        global_avg_runtime = np.concatenate(global_avg_runtime)\n",
    "        global_num_concurrency = np.concatenate(global_num_concurrency)\n",
    "        global_est_scan = np.concatenate(global_est_scan)\n",
    "        global_max_est_card = np.concatenate(global_max_est_card)\n",
    "        global_avg_est_card = np.concatenate(global_avg_est_card)\n",
    "        global_sum_concurrent_runtime = np.asarray(global_sum_concurrent_runtime)\n",
    "        global_est_concurrent_scan = np.asarray(global_est_concurrent_scan)\n",
    "        global_max_concurrent_card = np.asarray(global_max_concurrent_card)\n",
    "        global_avg_concurrent_card = np.asarray(global_avg_concurrent_card)\n",
    "        global_scan_sharing_percentage = np.asarray(global_scan_sharing_percentage)\n",
    "        feature = (\n",
    "            global_isolated_runtime,\n",
    "            global_avg_runtime,\n",
    "            global_num_concurrency,\n",
    "            global_sum_concurrent_runtime,\n",
    "            global_est_scan,\n",
    "            global_est_concurrent_scan,\n",
    "            global_scan_sharing_percentage,\n",
    "            global_max_est_card,\n",
    "            global_avg_est_card,\n",
    "            global_max_concurrent_card,\n",
    "            global_avg_concurrent_card,\n",
    "        )\n",
    "        if self.opt_method == \"torch\" or self.opt_method == \"nn\":\n",
    "            feature = list(feature)\n",
    "            for i in range(len(feature)):\n",
    "                feature[i] = torch.from_numpy(feature[i])\n",
    "            feature = tuple(feature)\n",
    "            global_y = torch.from_numpy(global_y)\n",
    "        return feature, global_y, global_query_idx\n",
    "\n",
    "    def train(self, trace_df, use_train=True, isolated_trace_df=None, analytic_func=None):\n",
    "        if analytic_func is None:\n",
    "            analytic_func = interaction_func_scipy\n",
    "        self.analytic_func = analytic_func\n",
    "        self.use_pre_info = use_train\n",
    "        self.get_isolated_runtime_cache(\n",
    "            trace_df, isolated_trace_df, get_avg_runtime=True\n",
    "        )\n",
    "        concurrent_df = trace_df[trace_df[\"num_concurrent_queries\"] > 0]\n",
    "        feature, label, _ = self.featurize_data(concurrent_df)\n",
    "\n",
    "        initial_param_value = np.asarray(self.analytic_params)\n",
    "        if self.opt_method == \"scipy\":\n",
    "            fit, _ = optimization.curve_fit(\n",
    "                self.analytic_func,\n",
    "                feature,\n",
    "                label,\n",
    "                initial_param_value,\n",
    "                bounds=self.bound,\n",
    "                jac=\"3-point\",\n",
    "                method=\"trf\",\n",
    "                loss=\"soft_l1\",\n",
    "                verbose=1\n",
    "            )\n",
    "            self.analytic_params = list(fit)\n",
    "        elif self.opt_method == \"torch\":\n",
    "            torch_analytic_params = []\n",
    "            torch_analytic_params_lr = []\n",
    "            for p in self.analytic_params:\n",
    "                if p == 10:\n",
    "                    t_p = torch.tensor(float(p), requires_grad=False)\n",
    "                else:\n",
    "                    t_p = torch.tensor(float(p), requires_grad=True)\n",
    "                torch_analytic_params.append(t_p)\n",
    "                torch_analytic_params_lr.append({'params': t_p, 'lr': 0.01 * p ** 0.3})\n",
    "            optimizer = optim.Adam(torch_analytic_params_lr, weight_decay=2e-5)\n",
    "            dataset = QueryFeatureDataset(feature, label)\n",
    "            train_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            for epoch in range(200):\n",
    "                for X, y in train_dataloader:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = fit_curve_loss_torch(X, y, torch_analytic_params,\n",
    "                                                self.constrain, loss_func=self.loss_func, penalties=self.penalty)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                if epoch % 10 == 0:\n",
    "                    print(epoch, loss.item())\n",
    "                    print(torch_analytic_params)\n",
    "            for i in range(len(self.analytic_params)):\n",
    "                self.analytic_params[i] = torch_analytic_params[i].detach()\n",
    "        elif self.opt_method == \"nn\":\n",
    "            dataset = QueryFeatureDataset(feature, label)\n",
    "            train_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            self.model = SimpleNet(len(feature))\n",
    "            optimizer = optim.Adam(self.model.parameters(), lr=0.01, weight_decay=2e-5)\n",
    "            for epoch in range(200):\n",
    "                for X, y in train_dataloader:\n",
    "                    X = torch.stack(X).float()\n",
    "                    X = torch.transpose(X, 0, 1)\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = self.model(X)\n",
    "                    pred = pred.reshape(-1)\n",
    "                    loss = l1_loss(pred, y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                if epoch % 10 == 0:\n",
    "                    print(epoch, loss.item())\n",
    "        elif self.opt_method == \"xgboost\":\n",
    "            feature = np.stack(feature).T\n",
    "            model = XGBRegressor(\n",
    "                n_estimators=1000,\n",
    "                max_depth=8,\n",
    "                eta=0.2,\n",
    "                subsample=1.0,\n",
    "                eval_metric=\"mae\",\n",
    "                early_stopping_rounds=100,\n",
    "            )\n",
    "            train_idx = np.random.choice(\n",
    "                len(feature), size=int(0.8 * len(feature)), replace=False\n",
    "            )\n",
    "            val_idx = [i for i in range(len(feature)) if i not in train_idx]\n",
    "            model.fit(\n",
    "                feature[train_idx],\n",
    "                label[train_idx],\n",
    "                eval_set=[(feature[val_idx], label[val_idx])],\n",
    "                verbose=False,\n",
    "            )\n",
    "            self.model = model\n",
    "        else:\n",
    "            assert False, f\"unrecognized optimization method {self.opt_method}\"\n",
    "\n",
    "    def predict(self, eval_trace_df, use_global=False, return_per_query=True):\n",
    "        if self.analytic_func is None:\n",
    "            self.analytic_func = interaction_func_scipy\n",
    "        feature, labels, query_idx = self.featurize_data(eval_trace_df)\n",
    "        if self.opt_method == \"scipy\":\n",
    "            preds = self.analytic_func(\n",
    "                feature,\n",
    "                *self.analytic_params\n",
    "            )\n",
    "        elif self.opt_method == \"torch\":\n",
    "            preds = interaction_func_torch(\n",
    "                feature,\n",
    "                *self.analytic_params\n",
    "            )\n",
    "            preds = preds.numpy()\n",
    "            labels = labels.numpy()\n",
    "        elif self.opt_method == \"nn\":\n",
    "            feature = torch.stack(feature).float()\n",
    "            feature = torch.transpose(feature, 0, 1)\n",
    "            preds = self.model(feature)\n",
    "            preds = preds.reshape(-1)\n",
    "            preds = preds.detach().numpy()\n",
    "            labels = labels.numpy()\n",
    "        elif self.opt_method == \"xgboost\":\n",
    "            feature = np.stack(feature).T\n",
    "            preds = self.model.predict(feature)\n",
    "            preds = np.maximum(preds, 0.001)\n",
    "        else:\n",
    "            assert False, f\"unrecognized optimization method {self.opt_method}\"\n",
    "        if return_per_query:\n",
    "            preds_per_query = dict()\n",
    "            labels_per_query = dict()\n",
    "            for i in query_idx:\n",
    "                start, end = query_idx[i]\n",
    "                preds_per_query[i] = preds[start:end]\n",
    "                labels_per_query[i] = labels[start:end]\n",
    "            return preds_per_query, labels_per_query\n",
    "        else:\n",
    "            return preds, labels\n",
    "\n",
    "\n",
    "class ComplexFitCurveSeparation(ComplexFitCurve):\n",
    "    \"\"\"\n",
    "    Complex fit curve model for runtime prediction with concurrency\n",
    "    See interaction_func_scipy for detailed analytical functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, is_column_store=False, opt_method='scipy'):\n",
    "        super().__init__(is_column_store, opt_method)\n",
    "        self.analytic_params = [0.3, 0.5, 20, 2, 0.2, 0.1, 0.3, 0.3, 0.3, 0.3, 0.1, 0.2, 0.8, 0.2, 10, 200, 16000]\n",
    "        self.bound = optimization.Bounds(\n",
    "            [0.1, 0.1, 10, 0.01, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.5, 0.05, 2, 20, 10000],\n",
    "            [1, 1, 200, 2, 1, 0.9, 0.9, 0.9, 0.5, 0.5, 0.5, 0.5, 0.95, 0.4, 20, 2000, 50000],\n",
    "        )\n",
    "        self.constrain = optimization.Bounds(\n",
    "            [0.1, 0.1, 10, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.5, 0.05, 2, 20, 10000],\n",
    "            [1, 1, 200, 2, 1, 0.9, 0.9, 0.9, 0.5, 0.5, 0.5, 0.5, 0.95, 0.4, 20, 2000, 50000],\n",
    "        )\n",
    "        self.penalty = [100, 100, 0.1, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1, 0.1, 0.01]\n",
    "\n",
    "    def featurize_data(self, concurrent_df):\n",
    "        global_y = []\n",
    "        global_isolated_runtime = []\n",
    "        global_avg_runtime = []\n",
    "        global_num_concurrency_pre = []\n",
    "        global_num_concurrency_post = []\n",
    "        global_sum_concurrent_runtime_pre = []\n",
    "        global_sum_concurrent_runtime_post = []\n",
    "        global_avg_time_elapsed_pre = []\n",
    "        global_sum_time_overlap_post = []\n",
    "        global_est_scan = []\n",
    "        global_est_concurrent_scan_pre = []\n",
    "        global_est_concurrent_scan_post = []\n",
    "        global_scan_sharing_percentage = []\n",
    "        global_max_est_card = []\n",
    "        global_avg_est_card = []\n",
    "        global_max_concurrent_card_pre = []\n",
    "        global_max_concurrent_card_post = []\n",
    "        global_avg_concurrent_card_pre = []\n",
    "        global_avg_concurrent_card_post = []\n",
    "        global_query_idx = dict()\n",
    "        start = 0\n",
    "        for i, rows in concurrent_df.groupby(\"query_idx\"):\n",
    "            if (\n",
    "                    i not in self.isolated_rt_cache\n",
    "                    or i not in self.query_info\n",
    "                    or i not in self.average_rt_cache\n",
    "            ):\n",
    "                continue\n",
    "            concurrent_rt = rows[\"runtime\"].values\n",
    "            start_time = rows[\"start_time\"].values\n",
    "            end_time = rows[\"end_time\"].values\n",
    "            query_info = self.query_info[i]\n",
    "            n_rows = len(rows)\n",
    "            num_concurrency_pre = rows[\"num_concurrent_queries_train\"].values\n",
    "            global_num_concurrency_pre.append(num_concurrency_pre)\n",
    "            concur_info_prev = rows[\"concur_info_train\"].values\n",
    "            full_concur_info = rows[\"concur_info\"].values\n",
    "            concur_info_post = []\n",
    "            for j in range(len(full_concur_info)):\n",
    "                new_info = [c for c in full_concur_info[j] if c not in full_concur_info[j]]\n",
    "                concur_info_post.append(new_info)\n",
    "            pre_exec_info = rows[\"pre_exec_info\"].values\n",
    "\n",
    "            global_query_idx[i] = (start, start + n_rows)\n",
    "            start += n_rows\n",
    "            global_y.append(concurrent_rt)\n",
    "            global_isolated_runtime.append(np.ones(n_rows) * self.isolated_rt_cache[i])\n",
    "            global_avg_runtime.append(np.ones(n_rows) * self.average_rt_cache[i])\n",
    "            global_est_scan.append(np.ones(n_rows) * query_info[\"est_scan\"])\n",
    "            global_max_est_card.append(\n",
    "                np.ones(n_rows) * np.max(query_info[\"all_cardinality\"]) / (1024 * 1024)\n",
    "            )\n",
    "            global_avg_est_card.append(\n",
    "                np.ones(n_rows)\n",
    "                * np.average(query_info[\"all_cardinality\"])\n",
    "                / (1024 * 1024)\n",
    "            )\n",
    "            for j in range(n_rows):\n",
    "                sum_concurrent_runtime_pre = 0\n",
    "                sum_concurrent_runtime_post = 0\n",
    "                sum_concurrent_scan_pre = 0\n",
    "                sum_concurrent_scan_post = 0\n",
    "                avg_time_elapsed_pre = 0\n",
    "                sum_time_overlap_post = 0\n",
    "                concurrent_card_pre = []\n",
    "                concurrent_card_post = []\n",
    "                for c in full_concur_info[j]:\n",
    "                    if c[0] in self.average_rt_cache:\n",
    "                        if c in concur_info_prev[j]:\n",
    "                            sum_concurrent_runtime_pre += self.average_rt_cache[c[0]]\n",
    "                            avg_time_elapsed_pre += (start_time[j] - c[1])\n",
    "                        else:\n",
    "                            sum_concurrent_runtime_post += self.average_rt_cache[c[0]]\n",
    "                            # TODO: this is not practical, make it an estimation\n",
    "                            sum_time_overlap_post += (end_time[j] - c[1])\n",
    "                    else:\n",
    "                        print(c[0])\n",
    "                    if c[0] in self.query_info:\n",
    "                        if c in concur_info_prev[j]:\n",
    "                            sum_concurrent_scan_pre += self.query_info[c[0]][\"est_scan\"]\n",
    "                            concurrent_card_pre.extend(self.query_info[c[0]][\"all_cardinality\"])\n",
    "                        else:\n",
    "                            sum_concurrent_scan_post += self.query_info[c[0]][\"est_scan\"]\n",
    "                            concurrent_card_post.extend(self.query_info[c[0]][\"all_cardinality\"])\n",
    "                    else:\n",
    "                        print(c[0])\n",
    "\n",
    "                global_sum_concurrent_runtime_pre.append(sum_concurrent_runtime_pre)\n",
    "                global_avg_time_elapsed_pre.append(avg_time_elapsed_pre / len(concur_info_prev[j]))\n",
    "                global_est_concurrent_scan_pre.append(sum_concurrent_scan_pre)\n",
    "                if len(concurrent_card_pre) == 0:\n",
    "                    global_max_concurrent_card_pre.append(0)\n",
    "                    global_avg_concurrent_card_pre.append(0)\n",
    "                else:\n",
    "                    global_max_concurrent_card_pre.append(\n",
    "                        np.max(concurrent_card_pre) / (1024 * 1024)\n",
    "                    )\n",
    "                    global_avg_concurrent_card_pre.append(\n",
    "                        np.average(concurrent_card_pre) / (1024 * 1024)\n",
    "                    )\n",
    "                # TODO: may be able to change concur_info_prev to full_concur_info?\n",
    "                global_scan_sharing_percentage.append(\n",
    "                    self.estimate_data_share_percentage(\n",
    "                        i, concur_info_prev[j], pre_exec_info[j]\n",
    "                    )\n",
    "                )\n",
    "                if self.use_pre_info:\n",
    "                    global_sum_concurrent_runtime_post.append(0)\n",
    "                    global_est_concurrent_scan_post.append(0)\n",
    "                    global_sum_time_overlap_post.append(0)\n",
    "                    global_max_concurrent_card_post.append(0)\n",
    "                    global_avg_concurrent_card_post.append(0)\n",
    "                else:\n",
    "                    global_sum_concurrent_runtime_post.append(sum_concurrent_runtime_post)\n",
    "                    global_est_concurrent_scan_post.append(sum_concurrent_scan_post)\n",
    "                    global_sum_time_overlap_post.append(sum_time_overlap_post)\n",
    "                    if len(concurrent_card_post) == 0:\n",
    "                        global_max_concurrent_card_post.append(0)\n",
    "                        global_avg_concurrent_card_post.append(0)\n",
    "                    else:\n",
    "                        global_max_concurrent_card_post.append(\n",
    "                            np.max(concurrent_card_post) / (1024 * 1024)\n",
    "                        )\n",
    "                        global_avg_concurrent_card_post.append(\n",
    "                            np.average(concurrent_card_post) / (1024 * 1024)\n",
    "                        )\n",
    "\n",
    "            if self.use_pre_info:\n",
    "                num_concurrency_post = np.zeros(n_rows)\n",
    "            else:\n",
    "                num_concurrency_post = rows[\"num_concurrent_queries\"].values - rows[\"num_concurrent_queries_train\"].values\n",
    "            global_num_concurrency_post.append(num_concurrency_post)\n",
    "\n",
    "        global_y = np.concatenate(global_y)\n",
    "        global_isolated_runtime = np.concatenate(global_isolated_runtime)\n",
    "        global_avg_runtime = np.concatenate(global_avg_runtime)\n",
    "        global_num_concurrency_pre = np.concatenate(global_num_concurrency_pre)\n",
    "        global_num_concurrency_post = np.concatenate(global_num_concurrency_post)\n",
    "\n",
    "        global_est_scan = np.concatenate(global_est_scan)\n",
    "        global_max_est_card = np.concatenate(global_max_est_card)\n",
    "        global_avg_est_card = np.concatenate(global_avg_est_card)\n",
    "        global_avg_time_elapsed_pre = np.asarray(global_avg_time_elapsed_pre)\n",
    "        global_sum_time_overlap_post = np.asarray(global_sum_time_overlap_post)\n",
    "        global_sum_concurrent_runtime_pre = np.asarray(global_sum_concurrent_runtime_pre)\n",
    "        global_sum_concurrent_runtime_post = np.asarray(global_sum_concurrent_runtime_post)\n",
    "        global_est_concurrent_scan_pre = np.asarray(global_est_concurrent_scan_pre)\n",
    "        global_est_concurrent_scan_post = np.asarray(global_est_concurrent_scan_post)\n",
    "        global_max_concurrent_card_pre = np.asarray(global_max_concurrent_card_pre)\n",
    "        global_max_concurrent_card_post = np.asarray(global_max_concurrent_card_post)\n",
    "        global_avg_concurrent_card_pre = np.asarray(global_avg_concurrent_card_pre)\n",
    "        global_avg_concurrent_card_post = np.asarray(global_avg_concurrent_card_post)\n",
    "        global_scan_sharing_percentage = np.asarray(global_scan_sharing_percentage)\n",
    "        feature = (\n",
    "            global_isolated_runtime,\n",
    "            global_avg_runtime,\n",
    "            global_num_concurrency_pre,\n",
    "            global_num_concurrency_post,\n",
    "            global_sum_concurrent_runtime_pre,\n",
    "            global_sum_concurrent_runtime_post,\n",
    "            global_avg_time_elapsed_pre,\n",
    "            global_sum_time_overlap_post,\n",
    "            global_est_scan,\n",
    "            global_est_concurrent_scan_pre,\n",
    "            global_est_concurrent_scan_post,\n",
    "            global_scan_sharing_percentage,\n",
    "            global_max_est_card,\n",
    "            global_avg_est_card,\n",
    "            global_max_concurrent_card_pre,\n",
    "            global_max_concurrent_card_post,\n",
    "            global_avg_concurrent_card_pre,\n",
    "            global_avg_concurrent_card_post\n",
    "        )\n",
    "        if self.opt_method == \"torch\" or self.opt_method == \"nn\":\n",
    "            feature = list(feature)\n",
    "            for i in range(len(feature)):\n",
    "                feature[i] = torch.from_numpy(feature[i])\n",
    "            feature = tuple(feature)\n",
    "            global_y = torch.from_numpy(global_y)\n",
    "        return feature, global_y, global_query_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4d03f0-e4fd-492c-ba0c-38dcade0d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction_separation_func_scipy(\n",
    "    x,\n",
    "    n1,\n",
    "    q1,\n",
    "    i1,\n",
    "    i2,\n",
    "    c1,\n",
    "    c2,\n",
    "    m1,\n",
    "    m2,\n",
    "    m3,\n",
    "    m4,\n",
    "    m5,\n",
    "    cm1,\n",
    "    r1,\n",
    "    r2,\n",
    "    max_concurrency,\n",
    "    avg_io_speed,\n",
    "    memory_size,\n",
    "    debug=False\n",
    "):\n",
    "    \"\"\"\n",
    "    An analytical function that can consider 3 types of resource sharing/contention: IO, memory, CPU\n",
    "    x:: input tuple containing:\n",
    "        isolated_runtime: the isolated runtime without concurrency of a query\n",
    "        avg_runtime: average or median observed runtime of a query under any concurrency\n",
    "        num_concurrency: number of concurrent queries running with this query\n",
    "        sum_concurrent_runtime: sum of the estimated runtime of all queries concurrently running with this query (CPU)\n",
    "        est_scan: estimated MB of data that this query will need to scan (IO)\n",
    "        est_concurrent_scan: estimated MB of data that the concurrently running queries will need to scan (IO)\n",
    "        scan_sharing_percentage: estimated percentage of data in cache (sharing) according to concurrent queries\n",
    "        max_est_card: maximum estimated cardinality in the query plan of this query (reflect peak memory usage)\n",
    "        avg_est_card: average estimated cardinality in the query plan of this query (reflect average memory usage)\n",
    "        max_concurrent_card: maximum estimated cardinality for all concurrent queries\n",
    "        avg_concurrent_card: average estimated cardinality for all concurrent queries\n",
    "    TODO: adding memory, vCPU, and bandwidth information\n",
    "    \"\"\"\n",
    "    (\n",
    "        isolated_runtime,\n",
    "        avg_runtime,\n",
    "        num_concurrency_pre,\n",
    "        num_concurrency_post,\n",
    "        sum_concurrent_runtime_pre,\n",
    "        sum_concurrent_runtime_post,\n",
    "        avg_time_elapsed_pre,\n",
    "        sum_time_overlap_post,\n",
    "        est_scan,\n",
    "        est_concurrent_scan_pre,\n",
    "        est_concurrent_scan_post,\n",
    "        scan_sharing_percentage,\n",
    "        max_est_card,\n",
    "        avg_est_card,\n",
    "        max_concurrent_card_pre,\n",
    "        max_concurrent_card_post,\n",
    "        avg_concurrent_card_pre,\n",
    "        avg_concurrent_card_post\n",
    "    ) = x\n",
    "    # fraction of running queries (as opposed to queueing queries)\n",
    "    running_frac = np.minimum(num_concurrency_pre + num_concurrency_post, max_concurrency) / np.maximum(\n",
    "        num_concurrency_pre + num_concurrency_post, 1\n",
    "    )\n",
    "    # estimate queueing time of a query based on the sum of concurrent queries' run time\n",
    "    queueing_time = (\n",
    "        q1\n",
    "        * (\n",
    "            np.maximum(num_concurrency_pre + n1 * num_concurrency_post - max_concurrency, 0)\n",
    "            / np.maximum(num_concurrency_pre + n1 * num_concurrency_post, 1)\n",
    "        )\n",
    "        *\n",
    "        (sum_concurrent_runtime_pre + n1 * sum_concurrent_runtime_post - avg_time_elapsed_pre * num_concurrency_pre)\n",
    "    )\n",
    "    queueing_time = np.maximum(queueing_time, 0)\n",
    "    if debug:\n",
    "        print(\"queueing_time\", queueing_time)\n",
    "    discount_pre = (sum_concurrent_runtime_pre - avg_time_elapsed_pre * num_concurrency_pre) * running_frac / np.maximum(sum_concurrent_runtime_pre, 0.1)\n",
    "    discount_pre = np.maximum(discount_pre, 0.1)\n",
    "    print(\"discount_pre\", discount_pre)\n",
    "    discount_post = sum_time_overlap_post / np.maximum(sum_concurrent_runtime_post, 0.1)\n",
    "    # estimate io_speed of a query assuming each query has a base io_speed of i1 + the io speed due to contention\n",
    "    io_speed = i1 + avg_io_speed / np.minimum(\n",
    "        np.maximum(num_concurrency_pre * discount_pre + n1 * num_concurrency_post * discount_post, 1), max_concurrency\n",
    "    )\n",
    "    if debug:\n",
    "        print(\"io_speed\", io_speed)\n",
    "    # estimate time speed on IO as the (estimated scan - data in cache) / estimated io_speed\n",
    "    # use i2 to adjust the estimation error in est_scan and scan_sharing_percentage\n",
    "    io_time = i2 * est_scan * np.maximum((1 - scan_sharing_percentage * running_frac), 0) / io_speed\n",
    "    if debug:\n",
    "        print(\"io_time\", io_time)\n",
    "    io_time_old = i2 * est_scan / io_speed\n",
    "    if debug:\n",
    "        print(\"io_time_old\", io_time_old)\n",
    "    # estimate the amount of CPU work/time as the weighted average of isolated_runtime and avg_runtime - io_time\n",
    "    cpu_time_isolated = np.maximum((r1 * isolated_runtime + (1 - r1) * avg_runtime) - io_time_old, 0.1)\n",
    "    if debug:\n",
    "        print(\"cpu_time_isolated\", cpu_time_isolated)\n",
    "    # estimate the amount of CPU work imposed by the concurrent queries (approximated by their estimate runtime)\n",
    "    cpu_concurrent_pre = (sum_concurrent_runtime_pre * discount_pre) / np.maximum(avg_runtime, 2)\n",
    "    cpu_concurrent_post = sum_time_overlap_post / np.maximum(avg_runtime, 2)\n",
    "    #cpu_concurrent_pre = np.sqrt((sum_concurrent_runtime_pre * discount_pre) / np.maximum(avg_runtime, 2))\n",
    "    #cpu_concurrent_post = np.sqrt(sum_time_overlap_post / np.maximum(avg_runtime, 2))\n",
    "    \n",
    "    # estimate the amount of memory load imposed by the concurrent queries\n",
    "    max_mem_usage_perc_pre = max_est_card / (max_concurrent_card_pre + max_est_card)\n",
    "    avg_mem_usage_perc_pre = avg_est_card / (avg_concurrent_card_pre + avg_est_card)\n",
    "    max_mem_usage_perc_post = max_est_card / (max_concurrent_card_post + max_est_card)\n",
    "    avg_mem_usage_perc_post = avg_est_card / (avg_concurrent_card_post + avg_est_card)\n",
    "    peak_mem_usage = (np.maximum(m1 * (max_concurrent_card_pre + max_est_card) - memory_size, 0) * max_mem_usage_perc_pre + \n",
    "        np.maximum(m1 * (max_concurrent_card_post + max_est_card) - memory_size, 0)\n",
    "        * max_mem_usage_perc_post\n",
    "        ) / memory_size\n",
    "    avg_mem_usage = (np.maximum(m2 * (avg_concurrent_card_pre + avg_est_card) - memory_size, 0)\n",
    "        * avg_mem_usage_perc_pre + np.maximum(m2 * (avg_concurrent_card_post + avg_est_card) - memory_size, 0)\n",
    "        * avg_mem_usage_perc_post\n",
    "        ) / memory_size\n",
    "    mem_usage = m3 * np.sqrt(peak_mem_usage) + m4 * np.sqrt(avg_mem_usage)\n",
    "    if debug:\n",
    "        print(\"mem_usage\", mem_usage)\n",
    "    # estimate the CPU time of a query by considering the contention of CPU and memory of other queries\n",
    "\n",
    "    cpu_time_scale_factor = (\n",
    "        c1 * (cpu_concurrent_pre + c2 * cpu_concurrent_post)\n",
    "    ) * (1 + mem_usage + cm1 * np.sqrt((cpu_concurrent_pre + cpu_concurrent_post) * mem_usage)) \n",
    "    cpu_time = (1 + cpu_time_scale_factor) * cpu_time_isolated\n",
    "    if debug:\n",
    "        print(\"cpu_scale\", c1 * (cpu_concurrent_pre + c2 * cpu_concurrent_post))\n",
    "        print(\"mem_scale\", 1 + mem_usage + cm1 * np.sqrt((cpu_concurrent_pre + cpu_concurrent_post) * mem_usage))\n",
    "    if debug:\n",
    "        print(\"cpu_time_isolated\", cpu_time_isolated)\n",
    "    if debug:\n",
    "        print(\"cpu_time\", cpu_time)\n",
    "    \"\"\"\n",
    "    print(\"==============================================================================\")\n",
    "    print(\"est_scan:\", np.min(est_scan), np.mean(est_scan), np.max(est_scan))\n",
    "    print(\"cpu_concurrent_pre:\", np.min(cpu_concurrent_pre), np.mean(cpu_concurrent_pre), np.max(cpu_concurrent_pre))\n",
    "    print(\"cpu_concurrent_post:\", np.min(cpu_concurrent_post), np.mean(cpu_concurrent_post), np.max(cpu_concurrent_post))\n",
    "    print(\"max_est_card:\", np.min(max_est_card), np.mean(max_est_card), np.max(max_est_card))\n",
    "    #print(\"max_concurrent_card_pre:\", np.min(max_concurrent_card_pre), np.mean(max_concurrent_card_pre), np.max(max_concurrent_card_pre))\n",
    "    #print(\"max_concurrent_card_post:\", np.min(max_concurrent_card_post), np.mean(max_concurrent_card_post), np.max(max_concurrent_card_post))\n",
    "    print(\"avg_est_card:\", np.min(avg_est_card), np.mean(avg_est_card), np.max(avg_est_card))\n",
    "    #print(\"avg_concurrent_card_pre:\", np.min(avg_concurrent_card_pre), np.mean(avg_concurrent_card_pre), np.max(avg_concurrent_card_pre))\n",
    "    #print(\"avg_concurrent_card_post:\", np.min(avg_concurrent_card_post), np.mean(avg_concurrent_card_post), np.max(avg_concurrent_card_post))\n",
    "    print(\"peak_mem_usage:\", np.min(peak_mem_usage), np.mean(peak_mem_usage), np.max(peak_mem_usage))\n",
    "    print(\"avg_mem_usage:\", np.min(avg_mem_usage), np.mean(avg_mem_usage), np.max(avg_mem_usage))\n",
    "    print(\"mem_usage:\", np.min(mem_usage), np.mean(mem_usage), np.max(mem_usage))\n",
    "    print(\"cpu_time_isolated\", np.min(cpu_time_isolated), np.mean(cpu_time_isolated),  np.max(cpu_time_isolated))\n",
    "    print(\"queueing time:\", np.min(queueing_time), np.mean(queueing_time), np.max(queueing_time))\n",
    "    print(\"io time:\", np.min(io_time), np.mean(io_time), np.max(io_time))\n",
    "    print(\"CPU time:\", np.min(cpu_time), np.mean(cpu_time), np.max(cpu_time))\n",
    "    # final runtime of a query is estimated to be the queueing time + io_time + cpu_time\n",
    "    \"\"\"\n",
    "    return np.maximum(queueing_time + io_time + cpu_time, 0.01)\n",
    "\n",
    "\n",
    "def interaction_separation_func_scipy_archive(\n",
    "    x,\n",
    "    n1,\n",
    "    q1,\n",
    "    i1,\n",
    "    i2,\n",
    "    c1,\n",
    "    c2,\n",
    "    m1,\n",
    "    m2,\n",
    "    m3,\n",
    "    m4,\n",
    "    m5,\n",
    "    cm1,\n",
    "    r1,\n",
    "    r2,\n",
    "    max_concurrency,\n",
    "    avg_io_speed,\n",
    "    memory_size,\n",
    "):\n",
    "    \"\"\"\n",
    "    An analytical function that can consider 3 types of resource sharing/contention: IO, memory, CPU\n",
    "    x:: input tuple containing:\n",
    "        isolated_runtime: the isolated runtime without concurrency of a query\n",
    "        avg_runtime: average or median observed runtime of a query under any concurrency\n",
    "        num_concurrency: number of concurrent queries running with this query\n",
    "        sum_concurrent_runtime: sum of the estimated runtime of all queries concurrently running with this query (CPU)\n",
    "        est_scan: estimated MB of data that this query will need to scan (IO)\n",
    "        est_concurrent_scan: estimated MB of data that the concurrently running queries will need to scan (IO)\n",
    "        scan_sharing_percentage: estimated percentage of data in cache (sharing) according to concurrent queries\n",
    "        max_est_card: maximum estimated cardinality in the query plan of this query (reflect peak memory usage)\n",
    "        avg_est_card: average estimated cardinality in the query plan of this query (reflect average memory usage)\n",
    "        max_concurrent_card: maximum estimated cardinality for all concurrent queries\n",
    "        avg_concurrent_card: average estimated cardinality for all concurrent queries\n",
    "    TODO: adding memory and CPU information\n",
    "    \"\"\"\n",
    "    (\n",
    "        isolated_runtime,\n",
    "        avg_runtime,\n",
    "        num_concurrency_pre,\n",
    "        num_concurrency_post,\n",
    "        sum_concurrent_runtime_pre,\n",
    "        sum_concurrent_runtime_post,\n",
    "        avg_time_elapsed_pre,\n",
    "        sum_time_overlap_post,\n",
    "        est_scan,\n",
    "        est_concurrent_scan_pre,\n",
    "        est_concurrent_scan_post,\n",
    "        scan_sharing_percentage,\n",
    "        max_est_card,\n",
    "        avg_est_card,\n",
    "        max_concurrent_card_pre,\n",
    "        max_concurrent_card_post,\n",
    "        avg_concurrent_card_pre,\n",
    "        avg_concurrent_card_post\n",
    "    ) = x\n",
    "    # fraction of running queries (as opposed to queueing queries)\n",
    "    running_frac = np.minimum(num_concurrency_pre + num_concurrency_post, max_concurrency) / np.maximum(\n",
    "        num_concurrency_pre + num_concurrency_post, 1\n",
    "    )\n",
    "    # estimate queueing time of a query based on the sum of concurrent queries' run time\n",
    "    queueing_time = (\n",
    "        q1\n",
    "        * (\n",
    "            np.maximum(num_concurrency_pre + n1 * num_concurrency_post - max_concurrency, 0)\n",
    "            / np.maximum(num_concurrency_pre + n1 * num_concurrency_post, 1)\n",
    "        )\n",
    "        *\n",
    "        (sum_concurrent_runtime_pre + n1 * sum_concurrent_runtime_post - avg_time_elapsed_pre * num_concurrency_pre)\n",
    "    )\n",
    "    queueing_time = np.maximum(queueing_time, 0)\n",
    "    discount_pre = (sum_concurrent_runtime_pre - avg_time_elapsed_pre * num_concurrency_pre) * running_frac / np.maximum(sum_concurrent_runtime_pre, 0.1)\n",
    "    discount_pre = np.maximum(discount_pre, 0)\n",
    "    discount_post = sum_time_overlap_post / np.maximum(sum_concurrent_runtime_post, 0.1)\n",
    "    # estimate io_speed of a query assuming each query has a base io_speed of i1 + the io speed due to contention\n",
    "    io_speed = i1 + avg_io_speed / np.minimum(\n",
    "        np.maximum(num_concurrency_pre * discount_pre + n1 * num_concurrency_post * discount_post, 1), max_concurrency\n",
    "    )\n",
    "    # estimate time speed on IO as the (estimated scan - data in cache) / estimated io_speed\n",
    "    # use i2 to adjust the estimation error in est_scan and scan_sharing_percentage\n",
    "    print(\"est_scan:\", np.min(est_scan), np.mean(est_scan), np.max(est_scan))\n",
    "    io_time = i2 * est_scan * (1 - scan_sharing_percentage * running_frac) / io_speed\n",
    "    io_time_old = i2 * est_scan / io_speed\n",
    "    # estimate the amount of CPU work/time as the weighted average of isolated_runtime and avg_runtime - io_time\n",
    "    cpu_time_isolated = np.maximum((r1 * isolated_runtime + r2 * avg_runtime) - io_time_old, 0.1)\n",
    "    # estimate the amount of CPU work imposed by the concurrent queries (approximated by their estimate runtime)\n",
    "    cpu_concurrent_pre = (sum_concurrent_runtime_pre * discount_pre) / np.maximum(avg_runtime, 2)\n",
    "    cpu_concurrent_post = sum_time_overlap_post / np.maximum(avg_runtime, 2)\n",
    "    print(\"cpu_concurrent_pre:\", np.min(cpu_concurrent_pre), np.mean(cpu_concurrent_pre), np.max(cpu_concurrent_pre))\n",
    "    print(\"cpu_concurrent_post:\", np.min(cpu_concurrent_post), np.mean(cpu_concurrent_post), np.max(cpu_concurrent_post))\n",
    "    # estimate the amount of memory load imposed by the concurrent queries\n",
    "    max_mem_usage_perc_pre = max_concurrent_card_pre / (max_concurrent_card_pre + max_est_card)\n",
    "    avg_mem_usage_perc_pre = avg_concurrent_card_pre / (avg_concurrent_card_pre + avg_est_card)\n",
    "    max_mem_usage_perc_post = max_concurrent_card_post / (max_concurrent_card_post + max_est_card)\n",
    "    avg_mem_usage_perc_post = avg_concurrent_card_post / (avg_concurrent_card_post + avg_est_card)\n",
    "    print(\"max_est_card:\", np.min(max_est_card), np.mean(max_est_card), np.max(max_est_card))\n",
    "    print(\"max_concurrent_card_pre:\", np.min(max_concurrent_card_pre), np.mean(max_concurrent_card_pre), np.max(max_concurrent_card_pre))\n",
    "    print(\"max_concurrent_card_post:\", np.min(max_concurrent_card_post), np.mean(max_concurrent_card_post), np.max(max_concurrent_card_post))\n",
    "    print(\"avg_est_card:\", np.min(avg_est_card), np.mean(avg_est_card), np.max(avg_est_card))\n",
    "    print(\"avg_concurrent_card_pre:\", np.min(avg_concurrent_card_pre), np.mean(avg_concurrent_card_pre), np.max(avg_concurrent_card_pre))\n",
    "    print(\"avg_concurrent_card_post:\", np.min(avg_concurrent_card_post), np.mean(avg_concurrent_card_post), np.max(avg_concurrent_card_post))\n",
    "    memory_concurrent = np.log(\n",
    "        m1\n",
    "        * np.maximum(max_concurrent_card_pre + max_est_card - memory_size, 0.01)\n",
    "        * max_mem_usage_perc_pre\n",
    "        + m2\n",
    "        * np.maximum(avg_concurrent_card_pre + avg_est_card - memory_size, 0.01)\n",
    "        * avg_mem_usage_perc_pre\n",
    "        + m3\n",
    "        * np.maximum(max_concurrent_card_post + max_est_card - memory_size, 0.01)\n",
    "        * max_mem_usage_perc_post\n",
    "        + m4\n",
    "        * np.maximum(avg_concurrent_card_post + avg_est_card - memory_size, 0.01)\n",
    "        * avg_mem_usage_perc_post\n",
    "        + 0.0001\n",
    "    ) * np.log((m1 + m3) * max_est_card + (m2 + m4) * avg_est_card + 0.0001)\n",
    "    memory_concurrent = np.maximum(memory_concurrent, 0)\n",
    "    print(\"memory_concurrent:\", np.min(memory_concurrent), np.mean(memory_concurrent), np.max(memory_concurrent))\n",
    "    print(\"cpu_time_isolated\", np.min(cpu_time_isolated), np.mean(cpu_time_isolated),  np.max(cpu_time_isolated))\n",
    "    memory_concurrent = np.maximum(memory_concurrent, 0)\n",
    "    # estimate the CPU time of a query by considering the contention of CPU and memory of other queries\n",
    "    cpu_time = (\n",
    "        1\n",
    "        + c1 * cpu_concurrent_pre\n",
    "        + c1 * cpu_concurrent_post\n",
    "        + m5 * memory_concurrent\n",
    "        + cm1 * np.sqrt((cpu_concurrent_pre + cpu_concurrent_post) * memory_concurrent)\n",
    "    ) * cpu_time_isolated\n",
    "    # final runtime of a query is estimated to be the queueing time + io_time + cpu_time\n",
    "    print(\"queueing time:\", np.min(queueing_time), np.mean(queueing_time), np.max(queueing_time))\n",
    "    print(\"io time:\", np.min(io_time), np.mean(io_time), np.max(io_time))\n",
    "    print(\"CPU time:\", np.min(cpu_time), np.mean(cpu_time), np.max(cpu_time))\n",
    "    return np.maximum(queueing_time + io_time + cpu_time, 0.01)\n",
    "    \n",
    "\n",
    "class ComplexFitCurveSeparation(ComplexFitCurve):\n",
    "    \"\"\"\n",
    "    Complex fit curve model for runtime prediction with concurrency\n",
    "    See interaction_func_scipy for detailed analytical functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, is_column_store=False, opt_method='scipy'):\n",
    "        super().__init__(is_column_store, opt_method)\n",
    "        self.analytic_params = [0.3, 0.5, 20, 2, 0.2, 0.9, 0.3, 0.3, 0.3, 0.3, 0.1, 0.2, 0.5, 0.5, 10, 200, 16000]\n",
    "        self.param_names = ['n1', 'q1', 'i1', 'i2', 'c1', 'c2', 'm1', 'm2', 'm3', 'm4', 'm5', 'cm1', \n",
    "                            'r1', 'r2', 'max_concurrency', 'avg_io_speed', 'memory_size',]\n",
    "        self.bound = optimization.Bounds(\n",
    "            [0.01, 0.1, 10, 0.1, 0.0001, 0.0001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.4, 0.4, 10, 20, 10000],\n",
    "            [1, 1, 200, 2, 1, 1, 1, 0.9, 0.5, 0.5, 0.5, 0.5, 0.8, 0.8, 20, 2000, 25000],\n",
    "        )\n",
    "        self.constrain = optimization.Bounds(\n",
    "            [0.1, 0.1, 10, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.5, 0.05, 2, 20, 10000],\n",
    "            [1, 1, 200, 2, 1, 0.9, 0.9, 0.9, 0.5, 0.5, 0.5, 0.5, 0.95, 0.4, 20, 2000, 50000],\n",
    "        )\n",
    "        self.penalty = [100, 100, 0.1, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1, 0.1, 0.01]\n",
    "\n",
    "    def featurize_data(self, concurrent_df):\n",
    "        global_y = []\n",
    "        global_isolated_runtime = []\n",
    "        global_avg_runtime = []\n",
    "        global_num_concurrency_pre = []\n",
    "        global_num_concurrency_post = []\n",
    "        global_sum_concurrent_runtime_pre = []\n",
    "        global_sum_concurrent_runtime_post = []\n",
    "        global_avg_time_elapsed_pre = []\n",
    "        global_sum_time_overlap_post = []\n",
    "        global_est_scan = []\n",
    "        global_est_concurrent_scan_pre = []\n",
    "        global_est_concurrent_scan_post = []\n",
    "        global_scan_sharing_percentage = []\n",
    "        global_max_est_card = []\n",
    "        global_avg_est_card = []\n",
    "        global_max_concurrent_card_pre = []\n",
    "        global_max_concurrent_card_post = []\n",
    "        global_avg_concurrent_card_pre = []\n",
    "        global_avg_concurrent_card_post = []\n",
    "        global_query_idx = dict()\n",
    "        start = 0\n",
    "        for i, rows in concurrent_df.groupby(\"query_idx\"):\n",
    "            if (\n",
    "                    i not in self.isolated_rt_cache\n",
    "                    or i not in self.query_info\n",
    "                    or i not in self.average_rt_cache\n",
    "            ):\n",
    "                continue\n",
    "            concurrent_rt = rows[\"runtime\"].values\n",
    "            start_time = rows[\"start_time\"].values\n",
    "            end_time = rows[\"end_time\"].values\n",
    "            query_info = self.query_info[i]\n",
    "            n_rows = len(rows)\n",
    "            num_concurrency_pre = rows[\"num_concurrent_queries_train\"].values\n",
    "            global_num_concurrency_pre.append(num_concurrency_pre)\n",
    "            concur_info_prev = rows[\"concur_info_train\"].values\n",
    "            full_concur_info = rows[\"concur_info\"].values\n",
    "            concur_info_post = []\n",
    "            for j in range(len(full_concur_info)):\n",
    "                new_info = [c for c in full_concur_info[j] if c not in full_concur_info[j]]\n",
    "                concur_info_post.append(new_info)\n",
    "            pre_exec_info = rows[\"pre_exec_info\"].values\n",
    "\n",
    "            global_query_idx[i] = (start, start + n_rows)\n",
    "            start += n_rows\n",
    "            global_y.append(concurrent_rt)\n",
    "            global_isolated_runtime.append(np.ones(n_rows) * self.isolated_rt_cache[i])\n",
    "            global_avg_runtime.append(np.ones(n_rows) * self.average_rt_cache[i])\n",
    "            global_est_scan.append(np.ones(n_rows) * query_info[\"est_scan\"])\n",
    "            global_max_est_card.append(\n",
    "                np.ones(n_rows) * np.max(query_info[\"all_cardinality\"]) / (1024 * 1024)\n",
    "            )\n",
    "            global_avg_est_card.append(\n",
    "                np.ones(n_rows)\n",
    "                * np.average(query_info[\"all_cardinality\"])\n",
    "                / (1024 * 1024)\n",
    "            )\n",
    "            for j in range(n_rows):\n",
    "                sum_concurrent_runtime_pre = 0\n",
    "                sum_concurrent_runtime_post = 0\n",
    "                sum_concurrent_scan_pre = 0\n",
    "                sum_concurrent_scan_post = 0\n",
    "                avg_time_elapsed_pre = 0\n",
    "                sum_time_overlap_post = 0\n",
    "                concurrent_card_pre = []\n",
    "                concurrent_card_post = []\n",
    "                for c in full_concur_info[j]:\n",
    "                    if c[0] in self.average_rt_cache:\n",
    "                        if c in concur_info_prev[j]:\n",
    "                            sum_concurrent_runtime_pre += self.average_rt_cache[c[0]]\n",
    "                            avg_time_elapsed_pre += (start_time[j] - c[1])\n",
    "                        else:\n",
    "                            sum_concurrent_runtime_post += self.average_rt_cache[c[0]]\n",
    "                            # TODO: this is not practical, make it an estimation\n",
    "                            sum_time_overlap_post += (end_time[j] - c[1])\n",
    "                    else:\n",
    "                        print(c[0])\n",
    "                    if c[0] in self.query_info:\n",
    "                        if c in concur_info_prev[j]:\n",
    "                            sum_concurrent_scan_pre += self.query_info[c[0]][\"est_scan\"]\n",
    "                            concurrent_card_pre.extend(self.query_info[c[0]][\"all_cardinality\"])\n",
    "                        else:\n",
    "                            sum_concurrent_scan_post += self.query_info[c[0]][\"est_scan\"]\n",
    "                            concurrent_card_post.extend(self.query_info[c[0]][\"all_cardinality\"])\n",
    "                    else:\n",
    "                        print(c[0])\n",
    "\n",
    "                global_sum_concurrent_runtime_pre.append(sum_concurrent_runtime_pre)\n",
    "                global_avg_time_elapsed_pre.append(avg_time_elapsed_pre / (len(concur_info_prev[j]) + 0.001))\n",
    "                global_est_concurrent_scan_pre.append(sum_concurrent_scan_pre)\n",
    "                if len(concurrent_card_pre) == 0:\n",
    "                    global_max_concurrent_card_pre.append(0)\n",
    "                    global_avg_concurrent_card_pre.append(0)\n",
    "                else:\n",
    "                    global_max_concurrent_card_pre.append(\n",
    "                        np.max(concurrent_card_pre) / (1024 * 1024)\n",
    "                    )\n",
    "                    global_avg_concurrent_card_pre.append(\n",
    "                        np.average(concurrent_card_pre) / (1024 * 1024)\n",
    "                    )\n",
    "                # TODO: may be able to change concur_info_prev to full_concur_info?\n",
    "                global_scan_sharing_percentage.append(\n",
    "                    self.estimate_data_share_percentage(\n",
    "                        i, concur_info_prev[j], pre_exec_info[j]\n",
    "                    )\n",
    "                )\n",
    "                if self.use_pre_info:\n",
    "                    global_sum_concurrent_runtime_post.append(0)\n",
    "                    global_est_concurrent_scan_post.append(0)\n",
    "                    global_sum_time_overlap_post.append(0)\n",
    "                    global_max_concurrent_card_post.append(0)\n",
    "                    global_avg_concurrent_card_post.append(0)\n",
    "                else:\n",
    "                    global_sum_concurrent_runtime_post.append(sum_concurrent_runtime_post)\n",
    "                    global_est_concurrent_scan_post.append(sum_concurrent_scan_post)\n",
    "                    global_sum_time_overlap_post.append(sum_time_overlap_post)\n",
    "                    if len(concurrent_card_post) == 0:\n",
    "                        global_max_concurrent_card_post.append(0)\n",
    "                        global_avg_concurrent_card_post.append(0)\n",
    "                    else:\n",
    "                        global_max_concurrent_card_post.append(\n",
    "                            np.max(concurrent_card_post) / (1024 * 1024)\n",
    "                        )\n",
    "                        global_avg_concurrent_card_post.append(\n",
    "                            np.average(concurrent_card_post) / (1024 * 1024)\n",
    "                        )\n",
    "\n",
    "            if self.use_pre_info:\n",
    "                num_concurrency_post = np.zeros(n_rows)\n",
    "            else:\n",
    "                num_concurrency_post = rows[\"num_concurrent_queries\"].values - rows[\"num_concurrent_queries_train\"].values\n",
    "            global_num_concurrency_post.append(num_concurrency_post)\n",
    "\n",
    "        global_y = np.concatenate(global_y)\n",
    "        global_isolated_runtime = np.concatenate(global_isolated_runtime)\n",
    "        global_avg_runtime = np.concatenate(global_avg_runtime)\n",
    "        global_num_concurrency_pre = np.concatenate(global_num_concurrency_pre)\n",
    "        global_num_concurrency_post = np.concatenate(global_num_concurrency_post)\n",
    "\n",
    "        global_est_scan = np.concatenate(global_est_scan)\n",
    "        global_max_est_card = np.concatenate(global_max_est_card)\n",
    "        global_avg_est_card = np.concatenate(global_avg_est_card)\n",
    "        global_avg_time_elapsed_pre = np.asarray(global_avg_time_elapsed_pre)\n",
    "        global_sum_time_overlap_post = np.asarray(global_sum_time_overlap_post)\n",
    "        global_sum_concurrent_runtime_pre = np.asarray(global_sum_concurrent_runtime_pre)\n",
    "        global_sum_concurrent_runtime_post = np.asarray(global_sum_concurrent_runtime_post)\n",
    "        global_est_concurrent_scan_pre = np.asarray(global_est_concurrent_scan_pre)\n",
    "        global_est_concurrent_scan_post = np.asarray(global_est_concurrent_scan_post)\n",
    "        global_max_concurrent_card_pre = np.asarray(global_max_concurrent_card_pre)\n",
    "        global_max_concurrent_card_post = np.asarray(global_max_concurrent_card_post)\n",
    "        global_avg_concurrent_card_pre = np.asarray(global_avg_concurrent_card_pre)\n",
    "        global_avg_concurrent_card_post = np.asarray(global_avg_concurrent_card_post)\n",
    "        global_scan_sharing_percentage = np.asarray(global_scan_sharing_percentage)\n",
    "        feature = (\n",
    "            global_isolated_runtime,\n",
    "            global_avg_runtime,\n",
    "            global_num_concurrency_pre,\n",
    "            global_num_concurrency_post,\n",
    "            global_sum_concurrent_runtime_pre,\n",
    "            global_sum_concurrent_runtime_post,\n",
    "            global_avg_time_elapsed_pre,\n",
    "            global_sum_time_overlap_post,\n",
    "            global_est_scan,\n",
    "            global_est_concurrent_scan_pre,\n",
    "            global_est_concurrent_scan_post,\n",
    "            global_scan_sharing_percentage,\n",
    "            global_max_est_card,\n",
    "            global_avg_est_card,\n",
    "            global_max_concurrent_card_pre,\n",
    "            global_max_concurrent_card_post,\n",
    "            global_avg_concurrent_card_pre,\n",
    "            global_avg_concurrent_card_post\n",
    "        )\n",
    "        if self.opt_method == \"torch\" or self.opt_method == \"nn\":\n",
    "            feature = list(feature)\n",
    "            for i in range(len(feature)):\n",
    "                feature[i] = torch.from_numpy(feature[i])\n",
    "            feature = tuple(feature)\n",
    "            global_y = torch.from_numpy(global_y)\n",
    "        return feature, global_y, global_query_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e3bb812-bcd0-4d66-924d-7bfb1793501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 57, initial cost 3.1496e+06, final cost 1.0937e+06, first-order optimality 4.40e+04.\n",
      "===========Performance for simple linear regression model (all query)=============\n",
      "50% absolute error is 6.873689942427311, q-error is 2.149383549802416\n",
      "90% absolute error is 73.00344264934647, q-error is 9.98984272489963\n",
      "95% absolute error is 114.58397064382326, q-error is 18.04297299371214\n",
      "================================================================\n",
      "For query in range 0s to 10s, there are 5846 executions\n",
      "50% absolute error is 2.0037470354583697, q-error is 2.826971688793038\n",
      "90% absolute error is 20.43418214532607, q-error is 14.52683551902678\n",
      "95% absolute error is 38.617396136679595, q-error is 25.31544213101032\n",
      "================================================================\n",
      "For query in range 10s to 60s, there are 3041 executions\n",
      "50% absolute error is 16.01190956477727, q-error is 1.955986761454129\n",
      "90% absolute error is 85.47447987795465, q-error is 6.250272760038555\n",
      "95% absolute error is 120.33381263721336, q-error is 10.708050329496764\n",
      "================================================================\n",
      "For query in range 60s to infs, there are 2020 executions\n",
      "50% absolute error is 42.38566484175186, q-error is 1.5357749777232224\n",
      "90% absolute error is 149.56247682399047, q-error is 3.7122943771106853\n",
      "95% absolute error is 208.00439811269388, q-error is 5.097198086009246\n"
     ]
    }
   ],
   "source": [
    "parsed_queries_path = \"/Users/ziniuw/Desktop/research/Data/AWS_trace/mixed_aurora/aurora_mixed_parsed_queries.json\"\n",
    "cfc = ComplexFitCurveSeparation(opt_method='scipy')\n",
    "cfc.pre_process_queries(parsed_queries_path)\n",
    "cfc.train(concurrency_df.iloc[train_idx], use_train=False, isolated_trace_df=isolated_trace_df, analytic_func=interaction_separation_func_scipy)\n",
    "predictions_cfc, labels = cfc.predict(eval_trace_df)\n",
    "print(\"===========Performance for simple linear regression model (all query)=============\")\n",
    "result_overall_cfc, result_per_query_cfc, result_by_interval_cfc = cfc.evaluate_performance(eval_trace_df, interval=[0, 10, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a4e998-afa9-4979-945a-b5614db42c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n1', 0.012499458441714753),\n",
       " ('q1', 0.4912910173928935),\n",
       " ('i1', 10.666223544774548),\n",
       " ('i2', 0.10000000733581918),\n",
       " ('c1', 0.09015059272427761),\n",
       " ('c2', 0.9999999999999986),\n",
       " ('m1', 0.00124510895434049),\n",
       " ('m2', 0.7887514688970306),\n",
       " ('m3', 0.0010617133613253205),\n",
       " ('m4', 0.44040905712707007),\n",
       " ('m5', 0.10000000000001112),\n",
       " ('cm1', 0.1350892942224451),\n",
       " ('r1', 0.44551870235072577),\n",
       " ('r2', 0.49999999999999994),\n",
       " ('max_concurrency', 14.669684433414567),\n",
       " ('avg_io_speed', 810.6615017617146),\n",
       " ('memory_size', 15891.37518824329)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cfc.param_names, cfc.analytic_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040900eb-d213-4454-b817-326177f726eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% absolute error is 7.213989113269395, q-error is 2.535096108619231\n",
      "90% absolute error is 101.86023724664493, q-error is 11.608351268273935\n",
      "95% absolute error is 169.66487127283168, q-error is 20.167396314492343\n",
      "================================================================\n",
      "For query in range 0s to 10s, there are 5846 executions\n",
      "50% absolute error is 2.0161857725518644, q-error is 2.922016291055555\n",
      "90% absolute error is 21.101341952919626, q-error is 15.825346779218211\n",
      "95% absolute error is 40.94259227729892, q-error is 27.701214268426714\n",
      "================================================================\n",
      "For query in range 10s to 60s, there are 3041 executions\n",
      "50% absolute error is 17.075821605857076, q-error is 2.2855775126280466\n",
      "90% absolute error is 109.68263671144541, q-error is 9.481384742030585\n",
      "95% absolute error is 156.89793774582043, q-error is 14.729372288284859\n",
      "================================================================\n",
      "For query in range 60s to infs, there are 2020 executions\n",
      "50% absolute error is 56.844251060391215, q-error is 2.161494635754143\n",
      "90% absolute error is 262.154409631, q-error is 5.819698978656869\n",
      "95% absolute error is 394.04743281914335, q-error is 7.879423768918252\n"
     ]
    }
   ],
   "source": [
    "cfc.use_pre_info = True\n",
    "result_overall_cfc, result_per_query_cfc, result_by_interval_cfc = cfc.evaluate_performance(eval_trace_df, interval=[0, 10, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cc898-f600-4197-a142-7bac29537138",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_queries_path = \"/Users/ziniuw/Desktop/research/Data/AWS_trace/mixed_aurora/aurora_mixed_parsed_queries.json\"\n",
    "cfc = ComplexFitCurve()\n",
    "cfc.pre_process_queries(parsed_queries_path)\n",
    "cfc.train(concurrency_df.iloc[train_idx], isolated_trace_df=isolated_trace_df)\n",
    "predictions_cfc, labels = cfc.predict(eval_trace_df, use_global=True)\n",
    "print(\"===========Performance for simple linear regression model (all query)=============\")\n",
    "result_overall_cfc, result_per_query_cfc, result_by_interval_cfc = cfc.evaluate_performance(concurrency_df.iloc[train_idx], interval=[0, 10, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1e54df-ca83-48ac-bba9-ebaf363216a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 2.6643e+06, final cost 1.0648e+06, first-order optimality 6.10e+00.\n",
      "===========Performance for simple linear regression model (all query)=============\n",
      "50% absolute error is 4.036703018599082, q-error is 1.7931724607708919\n",
      "90% absolute error is 75.84357167996453, q-error is 6.745197463893984\n",
      "95% absolute error is 118.95869234293372, q-error is 11.446624135729719\n",
      "================================================================\n",
      "For query in range 0s to 10s, there are 5846 executions\n",
      "50% absolute error is 0.9379855044678616, q-error is 1.9348106224447796\n",
      "90% absolute error is 15.975506831743893, q-error is 9.326160673146102\n",
      "95% absolute error is 34.927829142785164, q-error is 17.24132031156027\n",
      "================================================================\n",
      "For query in range 10s to 60s, there are 3041 executions\n",
      "50% absolute error is 12.15656395727639, q-error is 1.6958280271748678\n",
      "90% absolute error is 80.82107307544314, q-error is 5.47245173051059\n",
      "95% absolute error is 114.05081573250816, q-error is 8.243076907290371\n",
      "================================================================\n",
      "For query in range 60s to infs, there are 2020 executions\n",
      "50% absolute error is 46.44120161091159, q-error is 1.6505004567666073\n",
      "90% absolute error is 166.93077234984892, q-error is 3.6717498498860737\n",
      "95% absolute error is 226.848612057679, q-error is 5.207428041516277\n"
     ]
    }
   ],
   "source": [
    "parsed_queries_path = \"/Users/ziniuw/Desktop/research/Data/AWS_trace/mixed_aurora/aurora_mixed_parsed_queries.json\"\n",
    "cfc = ComplexFitCurve(opt_method='scipy')\n",
    "cfc.pre_process_queries(parsed_queries_path)\n",
    "cfc.train(concurrency_df.iloc[train_idx], use_train=False, isolated_trace_df=isolated_trace_df)\n",
    "predictions_cfc, labels = cfc.predict(eval_trace_df)\n",
    "print(\"===========Performance for simple linear regression model (all query)=============\")\n",
    "result_overall_cfc, result_per_query_cfc, result_by_interval_cfc = cfc.evaluate_performance(eval_trace_df, interval=[0, 10, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151ebdd-3e50-4b1d-b45e-5d47f8d3d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfc.analytic_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35cca09-e256-4630-8eb1-312c38f8dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result_per_query_cfc:\n",
    "    if cfc.average_rt_cache[i] > 5:\n",
    "        print(i, result_per_query_cfc[i][0], result_per_query_cfc[i][1], result_per_query_sfc[i][0], result_per_query_sfc[i][1],\n",
    "              result_per_query_xgb[i][0], result_per_query_xgb[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a7d466c-5999-47e6-9a97-fd57d85a7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfc.use_pre_info = False\n",
    "feature, global_y, global_query_idx = cfc.featurize_data(eval_trace_df)\n",
    "f_t = np.stack(feature).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d49b0951-9ebd-467d-ae26-b0f769483f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "80.01038942729303 8.943703889846802\n",
      "(44.55030298233032, 109.1729221343994, 1.0, 0.0, 55.44309878349304, 0.0, 71.57834865134723, 0.0, 6077.552390098572, 3684.9148273468018, 0.0, 0.9954112765064694, 0.7232437133789062, 0.09085226058959961, 467.9256896972656, 0.0, 175.4721441268921, 0.0)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.00339550323484207\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.004578267321313804\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 80.0069939240582\n",
      "==================================\n",
      "80.45937365547326 4.748476505279541\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 0.0, 41.40066194534302, 0.0, 9.772476841053, 0.0, 6077.552390098572, 6258.341488838196, 0.0, 0.9698032634704855, 0.7232437133789062, 0.09085226058959961, 267.6192169189453, 0.0, 11.289948743932387, 0.0)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.29186082672147234\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.02234458378505416\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.009977844812044952\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 80.4370290716882\n",
      "==================================\n",
      "81.16240512715184 11.418222188949583\n",
      "(44.55030298233032, 109.1729221343994, 2.0, 1.0, 148.54287433624268, 51.31472861766815, 123.24335482259195, 8.225773188954918, 6077.552390098572, 24430.897609710693, 0.0664215087890625, 0.9970747548253337, 0.7232437133789062, 0.09085226058959961, 451.748779296875, 0.0052337646484375, 42.902656343248154, 0.0019194863059303977)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.0021645844355819696\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.019058582518074494\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 81.16024054271627\n",
      "==================================\n",
      "81.69466001058171 24.43374466896057\n",
      "(44.55030298233032, 109.1729221343994, 2.0, 2.0, 203.69249153137207, 1.1617432832717896, 278.0411944027989, 10.710544337925967, 6077.552390098572, 2967.4686584472656, 90692.71961212158, 0.9887651730148994, 0.7232437133789062, 0.09085226058959961, 399.7790222167969, 363.5890197753906, 27.191129302978517, 17.080192076854217)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.008313399450758586\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.025664439040279638\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 81.68634661113096\n",
      "==================================\n",
      "82.01476390115761 13.106426477432253\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 0.0, 163.53967094421387, 0.0, 42.517013662112795, 0.0, 6077.552390098572, 56888.86200141907, 0.0, 0.9924517855000723, 0.7232437133789062, 0.09085226058959961, 241.0993766784668, 0.0, 25.338701934814452, 0.0)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.22006055014108353\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.005585428450400402\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.02971795806695631\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 82.0091784727072\n",
      "==================================\n",
      "83.96224133303663 8.071391820907593\n",
      "(44.55030298233032, 109.1729221343994, 4.0, 0.0, 239.17638504505157, 0.0, 43.0350602349412, 0.0, 6077.552390098572, 104042.25675582886, 0.0, 0.9946669283109032, 0.7232437133789062, 0.09085226058959961, 7.4698638916015625, 0.0, 1.060574213663737, 0.0)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.2802791090460698\n",
      "io_speed 733.750352541047\n",
      "io_time 0.00441730962800614\n",
      "io_time_old 0.8282861895588443\n",
      "cpu_time_isolated 79.55405051770559\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.055355742128088435\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.55405051770559\n",
      "cpu_time 83.95782402340862\n",
      "==================================\n",
      "84.20839136085353 39.24779963493347\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 4.0, 166.55718052387238, 76.21282291412354, 41.49601799400055, 27.2518925397344, 6077.552390098572, 33568.21716880798, 42292.932868003845, 0.9904142110009891, 0.7232437133789062, 0.09085226058959961, 122.48797607421875, 796.0234985351562, 7.862936120284231, 44.03441166233372)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.2525806837600797\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.007093166018947027\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.057242499662730456\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 84.20129819483458\n",
      "==================================\n",
      "85.37212726793679 24.57741522789001\n",
      "(44.55030298233032, 109.1729221343994, 2.0, 2.0, 299.7795350551605, 19.042438983917236, 120.77474912544079, 28.852885455788055, 6077.552390098572, 68483.48443317413, 13699.698941230774, 0.9963384348428118, 0.7232437133789062, 0.09085226058959961, 385.38311767578125, 225.19639205932617, 13.771964106066473, 35.1165894402398)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1942428684918882\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.002709436808155038\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.07190956241184626\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 85.36941783112863\n",
      "==================================\n",
      "86.30751509772399 54.59518480300903\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 0.0, 988.4709972143173, 0.0, 385.18158480507486, 0.0, 6077.552390098572, 85082.96670722961, 0.0, 0.7777997892229243, 0.7232437133789062, 0.09085226058959961, 5185.160516738892, 0.0, 370.36836229960124, 0.0)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.16442078838262097\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.08162394534051802\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 86.14309430934138\n",
      "==================================\n",
      "86.43981581292711 17.606234550476074\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 0.0, 150.7876968383789, 0.0, 10.36397367544146, 0.0, 6077.552390098572, 53236.26915073395, 0.0, 0.99150535691036, 0.7232437133789062, 0.09085226058959961, 755.0124807357788, 0.0, 44.24844068469423, 0.0)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.7938033295935933\n",
      "io_speed 351.0786286244862\n",
      "io_time 0.014705150923593395\n",
      "io_time_old 1.7311087432887797\n",
      "cpu_time_isolated 78.65122796397564\n",
      "mem_usage 0.0\n",
      "cpu_scale 0.0988399405739542\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 78.65122796397564\n",
      "cpu_time 86.42511066200352\n",
      "==================================\n",
      "209.8325523826061 167.74741888046265\n",
      "(44.55030298233032, 109.1729221343994, 4.0, 23.0, 395.53082263469696, 1501.8546231985092, 26.70962859285176, 1839.8944282506409, 6077.552390098572, 89969.72718906403, 483908.60809230804, 0.9744363511498677, 0.7232437133789062, 0.09085226058959961, 451.748779296875, 5185.160516738892, 23.701284726460774, 32.943219418506544)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.39656272291633154\n",
      "io_speed 428.8678432992198\n",
      "io_time 0.6668487106232264\n",
      "io_time_old 1.4171155359149963\n",
      "cpu_time_isolated 78.96522117134943\n",
      "mem_usage 0.0\n",
      "cpu_scale 1.6488332530356227\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 78.96522117134943\n",
      "cpu_time 209.1657036719829\n",
      "==================================\n",
      "211.3610013603619 223.23195362091064\n",
      "(44.55030298233032, 109.1729221343994, 2.0, 16.0, 156.9091283082962, 526.8966971635818, 124.07875462268585, 1984.9723609345565, 6077.552390098572, 3853.716911315918, 308893.52391815186, 0.9880691037829306, 0.7232437133789062, 0.09085226058959961, 119.91464233398438, 522.0503234863281, 8.53349583943685, 12.85676196416219)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.1441018849033668\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 1.6520669818620977\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 211.21689947545855\n",
      "==================================\n",
      "214.64386323659184 254.3448679447174\n",
      "(44.55030298233032, 109.1729221343994, 2.0, 15.0, 229.20533990859985, 446.44612061977386, 97.07105097451726, 2024.1554861708719, 6077.552390098572, 49263.46140289307, 139143.73671340942, 0.9948650699189262, 0.7232437133789062, 0.09085226058959961, 208.7379913330078, 1105.257740020752, 14.455052439371745, 39.33498249689738)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.13200766159278837\n",
      "io_speed 738.3105129131221\n",
      "io_time 0.11648553916395013\n",
      "io_time_old 0.8231702961883706\n",
      "cpu_time_isolated 79.55916641107606\n",
      "mem_usage 0.0\n",
      "cpu_scale 1.6964507972466871\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.55916641107606\n",
      "cpu_time 214.52737769742788\n",
      "==================================\n",
      "214.81407504360573 283.43108224868774\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 16.0, 456.87322771549225, 645.2461987733841, 165.69817060980898, 2007.0489789791463, 6077.552390098572, 96541.41944694519, 265190.952085495, 0.993134541380739, 0.7232437133789062, 0.09085226058959961, 207.81272888183594, 1194.0352478027344, 10.949555495689655, 27.14498469727864)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1\n",
      "io_speed 821.3277253064891\n",
      "io_time 0.17256921263629302\n",
      "io_time_old 0.7399668425498369\n",
      "cpu_time_isolated 79.6423698647146\n",
      "mem_usage 0.0\n",
      "cpu_scale 1.695066786630943\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.6423698647146\n",
      "cpu_time 214.64150583096944\n",
      "==================================\n",
      "254.99274788882457 212.0332856178284\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 19.0, 264.04667937755585, 684.8922877311707, 180.2590643118944, 2642.4796197387113, 6077.552390098572, 144957.9731054306, 487396.0663738251, 0.9404363298953926, 0.7232437133789062, 0.09085226058959961, 275167.55976104736, 2212.1754302978516, 5422.115383338928, 49.06458765406941)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1\n",
      "io_speed 677.1682780523515\n",
      "io_time 0.33468803019836096\n",
      "io_time_old 0.897495206570644\n",
      "cpu_time_isolated 79.48484150069379\n",
      "mem_usage 0.0\n",
      "cpu_scale 2.203856924799975\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 79.48484150069379\n",
      "cpu_time 254.65805985862622\n",
      "==================================\n",
      "325.4863133154196 290.1597146987915\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 16.0, 742.6320645809174, 1264.4252203702927, 161.47712462512297, 3477.0620761806567, 6077.552390098572, 127263.76302719116, 556787.3526983261, 0.9926296282605245, 0.7232437133789062, 0.09085226058959961, 207.81272888183594, 8263353.288513184, 16.70251395485618, 36367.717232726776)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.2684422520349657\n",
      "io_speed 608.814161390134\n",
      "io_time 0.2331956347157252\n",
      "io_time_old 0.9982607536690117\n",
      "cpu_time_isolated 79.38407595359541\n",
      "mem_usage 0.0006245746631386727\n",
      "cpu_scale 3.0358358648737105\n",
      "mem_scale 1.020216087106283\n",
      "cpu_time_isolated 79.38407595359541\n",
      "cpu_time 325.25311768070384\n",
      "==================================\n",
      "352.7504723217001 374.78761529922485\n",
      "(44.55030298233032, 109.1729221343994, 5.0, 23.0, 649.3061761856079, 614.6967798471451, 101.83206538692222, 4139.328414882191, 6077.552390098572, 83929.1564617157, 185944.22318077087, 0.992452251545042, 0.7232437133789062, 0.09085226058959961, 207.81272888183594, 522.0503234863281, 20.125141877394455, 17.479751371259066)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.11308199090970489\n",
      "io_speed 334.75808207803647\n",
      "io_time 0.8715101929101338\n",
      "io_time_old 1.815505931390797\n",
      "cpu_time_isolated 78.56683077587363\n",
      "mem_usage 0.0\n",
      "cpu_scale 3.4787216011371207\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 78.56683077587363\n",
      "cpu_time 351.87896212878996\n",
      "==================================\n",
      "576.7504295055168 531.7484085559845\n",
      "(44.55030298233032, 109.1729221343994, 7.0, 36.0, 617.2335087060928, 969.6702500581741, 68.85299028709572, 7726.593715015173, 6077.552390098572, 108369.5693435669, 707050.0096759796, 0.9955057885433224, 0.7232437133789062, 0.09085226058959961, 482.1987533569336, 166675.04537200928, 25.73223382548282, 458.14526805362186)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1\n",
      "io_speed 199.82712559116237\n",
      "io_time 2.0084764738528067\n",
      "io_time_old 3.0414053237052685\n",
      "cpu_time_isolated 77.34093138355917\n",
      "mem_usage 0.0\n",
      "cpu_scale 6.431277885461829\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 77.34093138355917\n",
      "cpu_time 574.7419530316639\n",
      "==================================\n",
      "637.0562214225162 442.74169516563416\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 35.0, 397.1678698062897, 987.2733891010284, 184.94158013994968, 8683.770251797108, 6077.552390098572, 28902.24023914337, 506792.62624549866, 0.9828717236759118, 0.7232437133789062, 0.09085226058959961, 207.81272888183594, 467.9256896972656, 14.226294403076173, 17.77833779754153)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.1\n",
      "io_speed 206.10258714614872\n",
      "io_time 1.829930684844496\n",
      "io_time_old 2.9487998768434633\n",
      "cpu_time_isolated 77.43353683042096\n",
      "mem_usage 0.0\n",
      "cpu_scale 7.203503504286701\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 77.43353683042096\n",
      "cpu_time 635.2262907376717\n",
      "==================================\n",
      "670.4112428415484 472.2169952392578\n",
      "(44.55030298233032, 109.1729221343994, 3.0, 49.0, 411.55269157886505, 880.965222120285, 51.38061979339025, 9409.031695723359, 6077.552390098572, 6184.64555644989, 736478.7872772217, 0.992505484237141, 0.7232437133789062, 0.09085226058959961, 133.3151397705078, 8263353.288513184, 8.911422856648763, 15603.661686365804)\n",
      "queueing_time 0.0\n",
      "discount_pre 0.17644883703950012\n",
      "io_speed 125.31561349338658\n",
      "io_time 3.4918778629626845\n",
      "io_time_old 4.8497969778183805\n",
      "cpu_time_isolated 75.53253972944604\n",
      "mem_usage 0.0\n",
      "cpu_scale 7.82956362075814\n",
      "mem_scale 1.0\n",
      "cpu_time_isolated 75.53253972944604\n",
      "cpu_time 666.9193649785857\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "idx = np.argsort(predictions_cfc[i])\n",
    "curr_label = global_y[global_query_idx[i][0]: global_query_idx[i][1]]\n",
    "for j in list(idx[:10]) + list(idx[-10:]):\n",
    "    print(\"==================================\")\n",
    "    print(predictions_cfc[i][j], curr_label[j])\n",
    "    feature = tuple(f_t[global_query_idx[i][0]: global_query_idx[i][1]][j])\n",
    "    print(feature)\n",
    "    #pred = interaction_separation_func_scipy_debug(feature, *cfc.analytic_params)\n",
    "    interaction_separation_func_scipy(feature, *cfc.analytic_params, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "011ffc49-3f08-4401-ada2-90c792c8c26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.34782457351685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 80.01038943,  36.6914102 ,  29.46135712,   8.94370389],\n",
       "       [ 80.45937366,  33.95785477,  23.1088047 ,   4.74847651],\n",
       "       [ 81.16240513,  33.95785477,  29.51144981,  11.41822219],\n",
       "       [ 81.69466001,  47.15126465,  36.1072731 ,  24.43374467],\n",
       "       [ 82.0147639 ,  33.95785477,  26.43943977,  13.10642648],\n",
       "       [ 83.96224133,  47.15126465,   0.001     ,   8.07139182],\n",
       "       [ 84.20839136,  86.73149429,  44.2942009 ,  39.24779963],\n",
       "       [ 85.37212727,  47.15126465,  53.06978226,  24.57741523],\n",
       "       [ 86.3075151 ,  33.95785477,  91.8082962 ,  54.5951848 ],\n",
       "       [ 86.43981581,  33.95785477,  26.53706551,  17.60623455],\n",
       "       [ 87.04921786,  99.92490417,  82.92233276,  85.27525115],\n",
       "       [ 87.98704869,  47.15126465,  49.38063431,  36.34676528],\n",
       "       [ 91.0339356 ,  33.95785477,  42.28642273,  23.84352231],\n",
       "       [ 91.83915691,  60.34467453,  35.54413223,   7.25911045],\n",
       "       [ 92.66448067, 139.50513381,  68.061203  ,  38.31848145],\n",
       "       [ 92.87943291,  60.34467453,  31.58169556,  22.04174924],\n",
       "       [ 94.37012903,  60.34467453,   4.50755024,  33.02771139],\n",
       "       [ 99.19051945,  47.15126465,  23.05506134,  40.59318066],\n",
       "       [ 99.23238329,  33.95785477,  21.6889267 ,  32.94049072],\n",
       "       [ 99.70172754,  99.92490417,  59.44152832,  65.70071173],\n",
       "       [102.15078222, 139.50513381,  93.37589264,  38.17366219],\n",
       "       [107.38337286,  99.92490417, 252.90112305,  56.73206425],\n",
       "       [107.99859429, 126.31172393,  63.56893539,  75.24287057],\n",
       "       [110.8278835 , 139.50513381, 113.83679199, 170.03329468],\n",
       "       [112.30104412, 205.47218321, 225.06738281,  82.78239441],\n",
       "       [113.90707914, 218.66559309, 106.13223267,  66.66565442],\n",
       "       [115.29012172, 192.27877333,  99.0868454 , 131.5728786 ],\n",
       "       [115.65455818, 126.31172393,  44.16788101,  61.91137075],\n",
       "       [117.3715836 ,  99.92490417, 106.52239227, 147.92449832],\n",
       "       [118.36545477, 139.50513381, 120.13728333, 137.55826092],\n",
       "       [118.96986599,  99.92490417,  86.23543549, 131.94944143],\n",
       "       [129.87786732, 205.47218321, 132.92871094,  74.67654872],\n",
       "       [147.43973914, 218.66559309, 235.39892578, 148.56347084],\n",
       "       [150.24761619, 218.66559309, 161.38085938,  95.82676506],\n",
       "       [150.49595489, 324.21287214, 211.09284973, 116.00309491],\n",
       "       [154.08503182, 245.05241286,  76.92745209,  99.44286633],\n",
       "       [165.19551508, 126.31172393, 173.38438416, 211.4788456 ],\n",
       "       [182.56385318, 165.89195357, 113.44961548, 197.28308487],\n",
       "       [189.74498182, 192.27877333, 127.01737976, 213.94148636],\n",
       "       [208.21547554, 192.27877333, 191.30096436, 248.54315329],\n",
       "       [209.83255238, 350.5996919 , 243.41716003, 167.74741888],\n",
       "       [211.36100136, 231.85900298, 168.17190552, 223.23195362],\n",
       "       [214.64386324, 218.66559309, 164.2828064 , 254.34486794],\n",
       "       [214.81407504, 245.05241286, 218.56994629, 283.43108225],\n",
       "       [254.99274789, 284.6326425 , 269.08709717, 212.03328562],\n",
       "       [325.48631332, 245.05241286, 279.77813721, 290.1597147 ],\n",
       "       [352.75047232, 363.79310178, 291.39788818, 374.7876153 ],\n",
       "       [576.75042951, 561.69424999, 450.19641113, 531.74840856],\n",
       "       [637.05622142, 495.72720059, 351.43771362, 442.74169517],\n",
       "       [670.41124284, 680.43493892, 542.10144043, 472.21699524]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "print(isolated_trace_df[\"runtime\"].iloc[i])\n",
    "idx = np.argsort(predictions_cfc[i])\n",
    "np.stack((predictions_cfc[i][idx], predictions_sfc[i][idx], predictions_xgb[i][idx], labels[i][idx]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecfeaaa-7e86-4a4d-82a0-f49d2cb593ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07224cb7-e676-461a-a49f-0c59c389d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72a633-e8ed-479a-a85e-83b49e6b0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan[\"parsed_queries\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ab464-9d5e-41e2-818f-b789154d312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255382cb-7340-421a-85a1-3507627c66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.maximum(np.zeros(3), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d81e9aee-f78d-4f9a-b98c-b7000855886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Performance for simple curve fitting model (all query)=============\n",
      "50% absolute error is 10.26358612688191, q-error is 4.330766611975611\n",
      "90% absolute error is 88.78408571569167, q-error is 43.665750587953184\n",
      "95% absolute error is 116.4081436502695, q-error is 109.10279384618602\n",
      "================================================================\n",
      "For query in range 0s to 10s, there are 540 executions\n",
      "50% absolute error is 1.9812749360839172, q-error is 3.0131166356278847\n",
      "90% absolute error is 19.950304748371643, q-error is 18.271560707627014\n",
      "95% absolute error is 24.9536131213566, q-error is 28.925998084923908\n",
      "================================================================\n",
      "For query in range 10s to 60s, there are 256 executions\n",
      "50% absolute error is 17.597095441949197, q-error is 7.511464942587086\n",
      "90% absolute error is 46.609297356320226, q-error is 53.48318296037619\n",
      "95% absolute error is 59.5536873006706, q-error is 92.06065881195197\n",
      "================================================================\n",
      "For query in range 60s to infs, there are 253 executions\n",
      "50% absolute error is 75.17097942926829, q-error is 5.70061428823845\n",
      "90% absolute error is 153.61593521237623, q-error is 170.6253688588455\n",
      "95% absolute error is 240.02729516233825, q-error is 350.438823322945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziniuw/.local/lib/python3.11/site-packages/scipy/optimize/_minpack_py.py:1010: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n"
     ]
    }
   ],
   "source": [
    "sfc = SimpleFitCurve()\n",
    "sfc.train(concurrency_df.iloc[train_idx], use_train=False, isolated_trace_df=isolated_trace_df)\n",
    "#predictions, labels = sfc.predict(eval_trace_df)\n",
    "#print(\"===========Performance for simple curve fitting model (per query)=============\")\n",
    "#result_overall, result_per_query = sfc.evaluate_performance(eval_trace_df, use_train=True)\n",
    "predictions_sfc, labels = sfc.predict(eval_trace_df, use_global=True)\n",
    "print(\"===========Performance for simple curve fitting model (all query)=============\")\n",
    "result_overall_sfc, result_per_query_sfc, result_by_interval_sfc = sfc.evaluate_performance(eval_trace_df, use_global=True, interval=[0, 10, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbd0ee3d-0783-4f1c-b9c6-bb106e1b0f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Performance for XGBoost model (train on full)=============\n",
      "50% absolute error is 6.82193911075592, q-error is 1.8462710247892797\n",
      "90% absolute error is 33.401027417182924, q-error is 15.358922600463911\n",
      "95% absolute error is 47.82344834804532, q-error is 136.7646268972089\n",
      "================================================================\n",
      "For query in range 0s to 10s, there are 535 executions\n",
      "50% absolute error is 3.1627433300018315, q-error is 3.2662633237851946\n",
      "90% absolute error is 13.892200040817267, q-error is 125.3731191213906\n",
      "95% absolute error is 17.533620405197137, q-error is 886.7988403637504\n",
      "================================================================\n",
      "For query in range 10s to 60s, there are 254 executions\n",
      "50% absolute error is 10.94163000583649, q-error is 1.6870888337045005\n",
      "90% absolute error is 30.393349456787114, q-error is 3.8482550475213686\n",
      "95% absolute error is 38.70606662034988, q-error is 5.407276915872149\n",
      "================================================================\n",
      "For query in range 60s to infs, there are 253 executions\n",
      "50% absolute error is 23.480167865753174, q-error is 1.2679038067436363\n",
      "90% absolute error is 62.416790246963565, q-error is 1.911761592391889\n",
      "95% absolute error is 78.46281461715694, q-error is 2.265439836515198\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBoostPredictor(k=240)\n",
    "xgb.train(concurrency_df.iloc[train_idx], use_train=False, isolated_trace_df=isolated_trace_df, use_pre_exec_info=True)\n",
    "predictions_xgb, labels = xgb.predict(eval_trace_df)\n",
    "#predictions_xgb, labels = xgb.predict(concurrency_df.iloc[train_idx], use_train=False)\n",
    "print(\"===========Performance for XGBoost model (train on full)=============\")\n",
    "result_overall_xgb, result_per_query_xgb, result_by_interval_xgb = xgb.evaluate_performance(eval_trace_df, interval=[0, 10, 60])\n",
    "#result_overall_xgb, result_per_query_xgb = xgb.evaluate_performance(concurrency_df.iloc[train_idx], use_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ba10d-ac59-4c3a-9bd7-c0b8000e2df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
