{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c22c477-d91e-4105-8faf-4f47a8305469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.load_brad_trace import load_trace, create_concurrency_dataset, load_trace_all_version\n",
    "from models.concurrency.analytical_models import SimpleFitCurve, ComplexFitCurve\n",
    "from models.concurrency.xgboost import XGBoostPredictor\n",
    "from models.concurrency.linear_regression import SimpleLinearReg\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06226fd1-03ad-4fb5-ba19-11108c4be863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client 4 trace not found\n",
      "client 5 trace not found\n",
      "client 6 trace not found\n",
      "client 7 trace not found\n",
      "client 4 trace not found\n",
      "client 5 trace not found\n",
      "client 6 trace not found\n",
      "client 7 trace not found\n",
      "client 4 trace not found\n",
      "client 5 trace not found\n",
      "client 6 trace not found\n",
      "client 7 trace not found\n",
      "client 4 trace not found\n",
      "client 5 trace not found\n",
      "client 6 trace not found\n",
      "client 7 trace not found\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"mixed_aurora\"\n",
    "directory = f\"/Users/ziniuw/Desktop/research/Data/AWS_trace/{folder_name}/\"\n",
    "all_raw_trace, all_trace = load_trace_all_version(directory, 8, concat=True)\n",
    "all_concurrency_df = []\n",
    "for trace in all_trace:\n",
    "    concurrency_df = create_concurrency_dataset(trace, engine=None, pre_exec_interval=60)\n",
    "    all_concurrency_df.append(concurrency_df)\n",
    "concurrency_df = pd.concat(all_concurrency_df, ignore_index=True)\n",
    "isolated_trace_df = pd.read_csv(f\"/Users/ziniuw/Desktop/research/Data/AWS_trace/{folder_name}/repeating_olap_batch_warmup.csv\")\n",
    "#isolated_trace_df = pd.read_csv(f\"/Users/ziniuw/Desktop/research/Data/AWS_trace/mixed_redshift/repeating_olap_batch_warmup.csv\")\n",
    "isolated_trace_df[\"runtime\"] = isolated_trace_df[\"run_time_s\"]\n",
    "isolated_rt_cache = dict()\n",
    "for i, rows in isolated_trace_df.groupby(\"query_idx\"):\n",
    "    isolated_rt_cache[i] = np.median(rows[\"runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41f999-2e9a-4545-a17d-2d486cd4e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rows in concurrency_df.groupby(\"query_idx\"):\n",
    "    runtime = rows[\"runtime\"].values\n",
    "    print(i, len(rows), isolated_rt_cache[i], np.mean(runtime), np.min(runtime), np.max(runtime), np.std(runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baed6340-0010-4701-ab3a-fe7dbd0f05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "train_idx = np.random.choice(len(concurrency_df), size=int(0.8 * len(concurrency_df)), replace=False)\n",
    "test_idx = [i for i in range(len(concurrency_df)) if i not in train_idx]\n",
    "eval_trace_df = concurrency_df.iloc[test_idx]\n",
    "eval_trace_df = eval_trace_df[eval_trace_df['num_concurrent_queries'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c83529b-a7d2-4f17-a7cf-25749e882269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import l1_loss\n",
    "import scipy.optimize as optimization\n",
    "from torch.utils.data import DataLoader\n",
    "from models.concurrency.base_model import ConcurPredictor\n",
    "from models.concurrency.utils import QueryFeatureDataset, SimpleNet\n",
    "from parser.utils import load_json, dfs_cardinality, estimate_scan_in_mb\n",
    "\n",
    "\n",
    "def simple_queueing_func(x, a1, a2, b1):\n",
    "    \"\"\"\n",
    "    a1 represents the average exec-time of a random query under concurrency\n",
    "    b1 represents the max level of concurrency in a system\n",
    "    a2 represents the average impact on a query's runtime when executed concurrently with other queries\n",
    "    \"\"\"\n",
    "    num_concurrency, isolated_runtime = x\n",
    "    return (a1 * np.maximum(num_concurrency - b1, 0)) + (\n",
    "        1 + a2 * np.minimum(num_concurrency, b1)\n",
    "    ) * isolated_runtime\n",
    "\n",
    "\n",
    "class SimpleFitCurve(ConcurPredictor):\n",
    "    \"\"\"\n",
    "    Simple fit curve model for runtime prediction with concurrency\n",
    "    runtime = queue_time(num_concurrency) + alpha(num_concurrency) * isolated_runtime\n",
    "            = (a1 * max(num_concurrency-b1, 0)) + (1 + a2*min(num_concurrency, b1)) * isolated_runtime\n",
    "    optimize a1, b1, b2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.isolated_rt_cache = dict()\n",
    "        self.use_train = True\n",
    "        self.a1_global = 0\n",
    "        self.a1 = dict()\n",
    "        self.b1_global = 0\n",
    "        self.b1 = dict()\n",
    "        self.a2_global = 0\n",
    "        self.a2 = dict()\n",
    "\n",
    "    def train(self, trace_df, use_train=True, isolated_trace_df=None):\n",
    "        self.use_train = use_train\n",
    "        self.get_isolated_runtime_cache(trace_df, isolated_trace_df)\n",
    "        concurrent_df = trace_df[trace_df[\"num_concurrent_queries\"] > 0]\n",
    "\n",
    "        global_y = []\n",
    "        global_x = []\n",
    "        global_ir = []\n",
    "        for i, rows in concurrent_df.groupby(\"query_idx\"):\n",
    "            if i not in self.isolated_rt_cache:\n",
    "                continue\n",
    "            isolated_rt = self.isolated_rt_cache[i]\n",
    "            concurrent_rt = rows[\"runtime\"].values\n",
    "            if use_train:\n",
    "                num_concurrency = rows[\"num_concurrent_queries_train\"].values\n",
    "            else:\n",
    "                num_concurrency = rows[\"num_concurrent_queries\"].values\n",
    "            if len(num_concurrency) < 10:\n",
    "                continue\n",
    "            global_y.append(concurrent_rt)\n",
    "            global_x.append(num_concurrency)\n",
    "            global_ir.append(np.ones(len(num_concurrency)) * isolated_rt)\n",
    "            fit, _ = optimization.curve_fit(\n",
    "                simple_queueing_func,\n",
    "                (num_concurrency, np.ones(len(num_concurrency)) * isolated_rt),\n",
    "                concurrent_rt,\n",
    "                np.array([5, 0.1, 20]),\n",
    "            )\n",
    "            self.a1[i] = fit[0]\n",
    "            self.a2[i] = fit[1]\n",
    "            self.b1[i] = fit[2]\n",
    "        global_y = np.concatenate(global_y)\n",
    "        global_x = np.concatenate(global_x)\n",
    "        global_ir = np.concatenate(global_ir)\n",
    "        fit, _ = optimization.curve_fit(\n",
    "            simple_queueing_func,\n",
    "            (global_x, global_ir),\n",
    "            global_y,\n",
    "            np.array([5, 0.1, 20]),\n",
    "        )\n",
    "        self.a1_global = fit[0]\n",
    "        self.a2_global = fit[1]\n",
    "        self.b1_global = fit[2]\n",
    "\n",
    "    def predict(self, eval_trace_df, use_global=False):\n",
    "        predictions = dict()\n",
    "        labels = dict()\n",
    "        for i, rows in eval_trace_df.groupby(\"query_idx\"):\n",
    "            if i not in self.isolated_rt_cache or i not in self.a1:\n",
    "                continue\n",
    "            isolated_rt = self.isolated_rt_cache[i]\n",
    "            label = rows[\"runtime\"].values\n",
    "            labels[i] = label\n",
    "            if self.use_train:\n",
    "                num_concurrency = rows[\"num_concurrent_queries_train\"].values\n",
    "            else:\n",
    "                num_concurrency = rows[\"num_concurrent_queries\"].values\n",
    "            x = (num_concurrency, np.ones(len(num_concurrency)) * isolated_rt)\n",
    "            if use_global:\n",
    "                pred = simple_queueing_func(\n",
    "                    x, self.a1_global, self.a2_global, self.b1_global\n",
    "                )\n",
    "            else:\n",
    "                pred = simple_queueing_func(x, self.a1[i], self.a2[i], self.b1[i])\n",
    "            pred = np.maximum(pred, 0.001)\n",
    "            predictions[i] = pred\n",
    "        return predictions, labels\n",
    "\n",
    "\n",
    "def interaction_func_scipy(\n",
    "    x,\n",
    "    q1,\n",
    "    i1,\n",
    "    i2,\n",
    "    c1,\n",
    "    m1,\n",
    "    m2,\n",
    "    m3,\n",
    "    cm1,\n",
    "    r1,\n",
    "    r2,\n",
    "    max_concurrency,\n",
    "    avg_io_speed,\n",
    "    memory_size,\n",
    "):\n",
    "    \"\"\"\n",
    "    An analytical function that can consider 3 types of resource sharing/contention: IO, memory, CPU\n",
    "    x:: input tuple containing:\n",
    "        isolated_runtime: the isolated runtime without concurrency of a query\n",
    "        avg_runtime: average or median observed runtime of a query under any concurrency\n",
    "        num_concurrency: number of concurrent queries running with this query\n",
    "        sum_concurrent_runtime: sum of the estimated runtime of all queries concurrently running with this query (CPU)\n",
    "        est_scan: estimated MB of data that this query will need to scan (IO)\n",
    "        est_concurrent_scan: estimated MB of data that the concurrently running queries will need to scan (IO)\n",
    "        scan_sharing_percentage: estimated percentage of data in cache (sharing) according to concurrent queries\n",
    "        max_est_card: maximum estimated cardinality in the query plan of this query (reflect peak memory usage)\n",
    "        avg_est_card: average estimated cardinality in the query plan of this query (reflect average memory usage)\n",
    "        max_concurrent_card: maximum estimated cardinality for all concurrent queries\n",
    "        avg_concurrent_card: average estimated cardinality for all concurrent queries\n",
    "    TODO: adding memory and CPU information\n",
    "    \"\"\"\n",
    "    (\n",
    "        isolated_runtime,\n",
    "        avg_runtime,\n",
    "        num_concurrency,\n",
    "        sum_concurrent_runtime,\n",
    "        est_scan,\n",
    "        est_concurrent_scan,\n",
    "        scan_sharing_percentage,\n",
    "        max_est_card,\n",
    "        avg_est_card,\n",
    "        max_concurrent_card,\n",
    "        avg_concurrent_card,\n",
    "    ) = x\n",
    "    # fraction of running queries (as opposed to queueing queries)\n",
    "    running_frac = np.minimum(num_concurrency, max_concurrency) / np.maximum(\n",
    "        num_concurrency, 1\n",
    "    )\n",
    "    # estimate queueing time of a query based on the sum of concurrent queries' run time\n",
    "    queueing_time = (\n",
    "        q1\n",
    "        * (\n",
    "            np.maximum(num_concurrency - max_concurrency, 0)\n",
    "            / np.maximum(num_concurrency, 1)\n",
    "        )\n",
    "        * sum_concurrent_runtime\n",
    "    )\n",
    "    # estimate io_speed of a query assuming each query has a base io_speed of i1 + the io speed due to contention\n",
    "    io_speed = i1 + avg_io_speed / np.minimum(\n",
    "        np.maximum(num_concurrency, 1), max_concurrency\n",
    "    )\n",
    "    # estimate time speed on IO as the (estimated scan - data in cache) / estimated io_speed\n",
    "    # use i2 to adjust the estimation error in est_scan and scan_sharing_percentage\n",
    "    io_time = i2 * est_scan * (1 - scan_sharing_percentage) / io_speed\n",
    "    # estimate the amount of CPU work/time as the weighted average of isolated_runtime and avg_runtime - io_time\n",
    "    cpu_time_isolated = (r1 * isolated_runtime + r2 * avg_runtime) - io_time\n",
    "    # estimate the amount of CPU work imposed by the concurrent queries (approximated by their estimate runtime)\n",
    "    cpu_concurrent = (running_frac * sum_concurrent_runtime) / avg_runtime\n",
    "    # estimate the amount of memory load imposed by the concurrent queries\n",
    "    max_mem_usage_perc = max_concurrent_card / (max_concurrent_card + max_est_card)\n",
    "    avg_mem_usage_perc = avg_concurrent_card / (avg_concurrent_card + avg_est_card)\n",
    "    memory_concurrent = np.log(\n",
    "        m1\n",
    "        * np.maximum(max_concurrent_card + max_est_card - memory_size, 0.01)\n",
    "        * max_mem_usage_perc\n",
    "        + m2\n",
    "        * np.maximum(avg_concurrent_card + avg_est_card - memory_size, 0.01)\n",
    "        * avg_mem_usage_perc\n",
    "        + 0.0001\n",
    "    ) * np.log(m1 * max_est_card + m2 * avg_est_card + 0.0001)\n",
    "    memory_concurrent = np.maximum(memory_concurrent, 0)\n",
    "    # estimate the CPU time of a query by considering the contention of CPU and memory of other queries\n",
    "    cpu_time = (\n",
    "        1\n",
    "        + c1 * cpu_concurrent\n",
    "        + m3 * memory_concurrent\n",
    "        + cm1 * np.sqrt(cpu_concurrent * memory_concurrent)\n",
    "    ) * cpu_time_isolated\n",
    "    # final runtime of a query is estimated to be the queueing time + io_time + cpu_time\n",
    "    return np.maximum(queueing_time + io_time + cpu_time, 0.01)\n",
    "\n",
    "\n",
    "def interaction_func_torch(\n",
    "    x,\n",
    "    q1,\n",
    "    i1,\n",
    "    i2,\n",
    "    c1,\n",
    "    m1,\n",
    "    m2,\n",
    "    m3,\n",
    "    cm1,\n",
    "    r1,\n",
    "    r2,\n",
    "    max_concurrency,\n",
    "    avg_io_speed,\n",
    "    memory_size,\n",
    "):\n",
    "    # See interaction_func_scipy for explanation\n",
    "    (\n",
    "        isolated_runtime,\n",
    "        avg_runtime,\n",
    "        num_concurrency,\n",
    "        sum_concurrent_runtime,\n",
    "        est_scan,\n",
    "        est_concurrent_scan,\n",
    "        scan_sharing_percentage,\n",
    "        max_est_card,\n",
    "        avg_est_card,\n",
    "        max_concurrent_card,\n",
    "        avg_concurrent_card,\n",
    "    ) = x\n",
    "    num_query = len(num_concurrency)\n",
    "    running_frac = torch.minimum(num_concurrency, max_concurrency) / torch.maximum(\n",
    "        num_concurrency, torch.tensor(1)\n",
    "    )\n",
    "    # estimate queueing time of a query based on the sum of concurrent queries' run time\n",
    "    queueing_time = (\n",
    "        q1\n",
    "        * (\n",
    "            torch.maximum(num_concurrency - max_concurrency, torch.tensor(0))\n",
    "            / torch.maximum(num_concurrency, torch.tensor(1))\n",
    "        )\n",
    "        * sum_concurrent_runtime\n",
    "    )\n",
    "    # estimate io_speed of a query assuming each query has a base io_speed of i1 + the io speed due to contention\n",
    "    io_speed = i1 + avg_io_speed / torch.minimum(\n",
    "        torch.maximum(num_concurrency, torch.tensor(1)), max_concurrency\n",
    "    )\n",
    "    # estimate time speed on IO as the (estimated scan - data in cache) / estimated io_speed\n",
    "    # use i2 to adjust the estimation error in est_scan and scan_sharing_percentage\n",
    "    io_time = i2 * est_scan * (1 - scan_sharing_percentage) / io_speed\n",
    "    # estimate the amount of CPU work/time as the weighted average of isolated_runtime and avg_runtime - io_time\n",
    "    cpu_time_isolated = (r1 * isolated_runtime + r2 * avg_runtime) - io_time\n",
    "    # estimate the amount of CPU work imposed by the concurrent queries (approximated by their estimate runtime)\n",
    "    cpu_concurrent = (running_frac * sum_concurrent_runtime) / avg_runtime\n",
    "    # estimate the amount of memory load imposed by the concurrent queries\n",
    "    max_mem_usage_perc = max_concurrent_card / (max_concurrent_card + max_est_card)\n",
    "    avg_mem_usage_perc = avg_concurrent_card / (avg_concurrent_card + avg_est_card)\n",
    "    memory_concurrent = torch.log(\n",
    "        m1\n",
    "        * torch.maximum(max_concurrent_card + max_est_card - memory_size, torch.tensor(0) + 0.01)\n",
    "        * max_mem_usage_perc\n",
    "        + m2\n",
    "        * torch.maximum(avg_concurrent_card + avg_est_card - memory_size, torch.tensor(0) + 0.01)\n",
    "        * avg_mem_usage_perc\n",
    "        + 0.0001\n",
    "    ) * torch.log(m1 * max_est_card + m2 * avg_est_card + 0.0001)\n",
    "    memory_concurrent = torch.maximum(memory_concurrent, torch.tensor(0))\n",
    "    # estimate the CPU time of a query by considering the contention of CPU and memory of other queries\n",
    "    cpu_time = (\n",
    "        1\n",
    "        + c1 * cpu_concurrent\n",
    "        + m3 * memory_concurrent\n",
    "        + cm1 * torch.sqrt(cpu_concurrent * memory_concurrent)\n",
    "    ) * cpu_time_isolated\n",
    "    # final runtime of a query is estimated to be the queueing time + io_time + cpu_time\n",
    "    return torch.maximum(queueing_time + io_time + cpu_time, torch.tensor(0) + 0.01)\n",
    "\n",
    "\n",
    "def fit_curve_loss_torch(x, y, params, constrain, loss_func=\"soft_l1\", penalties=None):\n",
    "    pred = interaction_func_torch(x, *params)\n",
    "    lb = constrain.lb\n",
    "    ub = constrain.ub\n",
    "    if loss_func == \"mae\":\n",
    "        loss = torch.abs(pred - y)\n",
    "    elif loss_func == \"mse\":\n",
    "        loss = (pred - y) ** 2\n",
    "    elif loss_func == \"soft_l1\":\n",
    "        loss = torch.sqrt(1 + (pred - y) ** 2) - 1\n",
    "    else:\n",
    "        assert False, f\"loss func {loss_func} not implemented\"\n",
    "    loss = torch.mean(loss)\n",
    "    for i, p in enumerate(params):\n",
    "        if penalties is not None:\n",
    "            penalty = penalties[i]\n",
    "        else:\n",
    "            penalty = 1\n",
    "        pen = torch.exp(penalty * (p - ub[i])) + torch.exp(-1 * penalty * (p - lb[i]))\n",
    "        loss += pen\n",
    "    return loss\n",
    "\n",
    "\n",
    "class ComplexFitCurve(ConcurPredictor):\n",
    "    \"\"\"\n",
    "    Complex fit curve model for runtime prediction with concurrency\n",
    "    See interaction_func_scipy for detailed analytical functions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, is_column_store=False, opt_method='scipy'):\n",
    "        \"\"\"\n",
    "\n",
    "        :param is_column_store:\n",
    "        :param opt_method:\n",
    "        \"\"\"\n",
    "        # indicate whether the DBMS is a column_store\n",
    "        #\n",
    "        super().__init__()\n",
    "        self.isolated_rt_cache = dict()\n",
    "        self.average_rt_cache = dict()\n",
    "        self.query_info = dict()\n",
    "        self.db_stats = None\n",
    "        self.table_sizes = dict()\n",
    "        self.table_sizes_by_index = dict()\n",
    "        self.table_nrows_by_index = dict()\n",
    "        self.table_column_map = dict()\n",
    "        self.use_train = True\n",
    "        self.is_column_store = is_column_store\n",
    "        self.opt_method = opt_method\n",
    "        self.batch_size = 1024\n",
    "        self.analytic_params = [0.5, 20, 2, 0.2, 0.5, 0.5, 0.1, 0.2, 0.8, 0.2, 10, 200, 16000]\n",
    "        self.bound = optimization.Bounds(\n",
    "            [0.1, 10, 0.01, 0.001, 0.001, 0.001, 0.001, 0.001, 0.5, 0.05, 2, 20, 10000],\n",
    "            [1, 200, 2, 1, 0.9, 0.9, 0.5, 0.5, 0.95, 0.4, 20, 2000, 50000],\n",
    "        )\n",
    "        self.constrain = optimization.Bounds(\n",
    "            [0.1, 10, 0.1, 0.01, 0.01, 0.01, 0.01, 0.1, 0.5, 0.05, 2, 20, 10000],\n",
    "            [1, 200, 2, 1, 0.9, 0.9, 0.5, 0.5, 0.95, 0.4, 20, 2000, 50000],\n",
    "        )\n",
    "        self.penalty = [100, 0.1, 100, 100, 100, 100, 100, 100, 100, 100, 1, 0.1, 0.01]\n",
    "        self.loss_func = \"soft_l1\"\n",
    "        self.model = None\n",
    "\n",
    "    def _compute_table_size(self):\n",
    "        for col in self.db_stats[\"column_stats\"]:\n",
    "            table = col[\"tablename\"]\n",
    "            if table not in self.table_column_map:\n",
    "                self.table_sizes[table] = 0\n",
    "                self.table_column_map[table] = []\n",
    "            self.table_column_map[table].append(col[\"attname\"])\n",
    "            if col[\"avg_width\"] is not None and col[\"avg_width\"] > 0:\n",
    "                self.table_sizes[table] += col[\"avg_width\"]\n",
    "        all_table_names = [t[\"relname\"] for t in self.db_stats[\"table_stats\"]]\n",
    "        for table in self.table_sizes:\n",
    "            if table in all_table_names:\n",
    "                idx = all_table_names.index(table)\n",
    "                num_tuples = self.db_stats[\"table_stats\"][idx][\"reltuples\"]\n",
    "                self.table_nrows_by_index[idx] = num_tuples\n",
    "                size_in_mb = (num_tuples * self.table_sizes[table]) / (1024 * 1024)\n",
    "                self.table_sizes[table] = size_in_mb\n",
    "                self.table_sizes_by_index[idx] = size_in_mb\n",
    "\n",
    "    def pre_process_queries(\n",
    "        self, parsed_queries_path, with_width=True, use_true_card=False\n",
    "    ):\n",
    "        plans = load_json(parsed_queries_path, namespace=False)\n",
    "        self.db_stats = plans[\"database_stats\"]\n",
    "        self._compute_table_size()\n",
    "        self.query_info = dict()\n",
    "        for i in range(len(plans[\"sql_queries\"])):\n",
    "            curr_query_info = dict()\n",
    "            curr_query_info[\"sql\"] = plans[\"sql_queries\"][i]\n",
    "            all_cardinality = []\n",
    "            dfs_cardinality(\n",
    "                plans[\"parsed_plans\"][i], all_cardinality, with_width, use_true_card\n",
    "            )\n",
    "            curr_query_info[\"all_cardinality\"] = all_cardinality\n",
    "            est_scan, est_scan_per_table = estimate_scan_in_mb(\n",
    "                self.db_stats,\n",
    "                plans[\"parsed_queries\"][i],\n",
    "                use_true_card,\n",
    "                self.is_column_store,\n",
    "            )\n",
    "            curr_query_info[\"est_scan\"] = est_scan\n",
    "            curr_query_info[\"est_scan_per_table\"] = est_scan_per_table\n",
    "            self.query_info[i] = curr_query_info\n",
    "\n",
    "    def estimate_data_share_percentage(self, idx, concur_info, pre_exec_info=None):\n",
    "        # TODO: make it smarter by considering buffer pool behavior\n",
    "        curr_scan = self.query_info[idx][\"est_scan_per_table\"]\n",
    "        curr_total_scan = self.query_info[idx][\"est_scan\"]\n",
    "        if pre_exec_info is not None:\n",
    "            concur_info = concur_info + pre_exec_info\n",
    "        all_shared_scan = 0\n",
    "        for table in curr_scan:\n",
    "            table_size = self.table_sizes_by_index[table]\n",
    "            table_shared_scan = 0\n",
    "            for c in concur_info:\n",
    "                concur_scan = self.query_info[c[0]][\"est_scan_per_table\"]\n",
    "                if table in concur_scan:\n",
    "                    concur_scan_perc = concur_scan[table] / table_size\n",
    "                    overlap_scan = concur_scan_perc * curr_scan[table]\n",
    "                    table_shared_scan += overlap_scan\n",
    "            table_shared_scan = min(table_shared_scan, curr_scan[table])\n",
    "            all_shared_scan += table_shared_scan\n",
    "        return min(all_shared_scan / curr_total_scan, 1.0)\n",
    "\n",
    "    def featurize_data(self, concurrent_df):\n",
    "        global_y = []\n",
    "        global_isolated_runtime = []\n",
    "        global_avg_runtime = []\n",
    "        global_num_concurrency = []\n",
    "        global_sum_concurrent_runtime = []\n",
    "        global_est_scan = []\n",
    "        global_est_concurrent_scan = []\n",
    "        global_scan_sharing_percentage = []\n",
    "        global_max_est_card = []\n",
    "        global_avg_est_card = []\n",
    "        global_max_concurrent_card = []\n",
    "        global_avg_concurrent_card = []\n",
    "        global_query_idx = dict()\n",
    "        start = 0\n",
    "        for i, rows in concurrent_df.groupby(\"query_idx\"):\n",
    "            if (\n",
    "                i not in self.isolated_rt_cache\n",
    "                or i not in self.query_info\n",
    "                or i not in self.average_rt_cache\n",
    "            ):\n",
    "                continue\n",
    "            concurrent_rt = rows[\"runtime\"].values\n",
    "            query_info = self.query_info[i]\n",
    "            n_rows = len(rows)\n",
    "            if self.use_train:\n",
    "                num_concurrency = rows[\"num_concurrent_queries_train\"].values\n",
    "                concur_info = rows[\"concur_info_train\"].values\n",
    "            else:\n",
    "                num_concurrency = rows[\"num_concurrent_queries\"].values\n",
    "                concur_info = rows[\"concur_info\"].values\n",
    "            pre_exec_info = rows[\"pre_exec_info\"].values\n",
    "\n",
    "            global_query_idx[i] = (start, start + n_rows)\n",
    "            start += n_rows\n",
    "            global_y.append(concurrent_rt)\n",
    "            global_isolated_runtime.append(np.ones(n_rows) * self.isolated_rt_cache[i])\n",
    "            global_avg_runtime.append(np.ones(n_rows) * self.average_rt_cache[i])\n",
    "            global_num_concurrency.append(num_concurrency)\n",
    "            global_est_scan.append(np.ones(n_rows) * query_info[\"est_scan\"])\n",
    "            global_max_est_card.append(\n",
    "                np.ones(n_rows) * np.max(query_info[\"all_cardinality\"]) / (1024 * 1024)\n",
    "            )\n",
    "            global_avg_est_card.append(\n",
    "                np.ones(n_rows)\n",
    "                * np.average(query_info[\"all_cardinality\"])\n",
    "                / (1024 * 1024)\n",
    "            )\n",
    "            for j in range(n_rows):\n",
    "                sum_concurrent_runtime = 0\n",
    "                sum_concurrent_scan = 0\n",
    "                concurrent_card = []\n",
    "                for c in concur_info[j]:\n",
    "                    if c[0] in self.average_rt_cache:\n",
    "                        sum_concurrent_runtime += self.average_rt_cache[c[0]]\n",
    "                    else:\n",
    "                        print(c[0])\n",
    "                    if c[0] in self.query_info:\n",
    "                        sum_concurrent_scan += self.query_info[c[0]][\"est_scan\"]\n",
    "                        concurrent_card.extend(self.query_info[c[0]][\"all_cardinality\"])\n",
    "                    else:\n",
    "                        print(c[0])\n",
    "\n",
    "                global_sum_concurrent_runtime.append(sum_concurrent_runtime)\n",
    "                global_est_concurrent_scan.append(sum_concurrent_scan)\n",
    "                if len(concurrent_card) == 0:\n",
    "                    global_max_concurrent_card.append(0)\n",
    "                    global_avg_concurrent_card.append(0)\n",
    "                else:\n",
    "                    global_max_concurrent_card.append(\n",
    "                        np.max(concurrent_card) / (1024 * 1024)\n",
    "                    )\n",
    "                    global_avg_concurrent_card.append(\n",
    "                        np.average(concurrent_card) / (1024 * 1024)\n",
    "                    )\n",
    "                global_scan_sharing_percentage.append(\n",
    "                    self.estimate_data_share_percentage(\n",
    "                        i, concur_info[j], pre_exec_info[j]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        global_y = np.concatenate(global_y)\n",
    "        global_isolated_runtime = np.concatenate(global_isolated_runtime)\n",
    "        global_avg_runtime = np.concatenate(global_avg_runtime)\n",
    "        global_num_concurrency = np.concatenate(global_num_concurrency)\n",
    "        global_est_scan = np.concatenate(global_est_scan)\n",
    "        global_max_est_card = np.concatenate(global_max_est_card)\n",
    "        global_avg_est_card = np.concatenate(global_avg_est_card)\n",
    "        global_sum_concurrent_runtime = np.asarray(global_sum_concurrent_runtime)\n",
    "        global_est_concurrent_scan = np.asarray(global_est_concurrent_scan)\n",
    "        global_max_concurrent_card = np.asarray(global_max_concurrent_card)\n",
    "        global_avg_concurrent_card = np.asarray(global_avg_concurrent_card)\n",
    "        global_scan_sharing_percentage = np.asarray(global_scan_sharing_percentage)\n",
    "        feature = (\n",
    "            global_isolated_runtime,\n",
    "            global_avg_runtime,\n",
    "            global_num_concurrency,\n",
    "            global_sum_concurrent_runtime,\n",
    "            global_est_scan,\n",
    "            global_est_concurrent_scan,\n",
    "            global_scan_sharing_percentage,\n",
    "            global_max_est_card,\n",
    "            global_avg_est_card,\n",
    "            global_max_concurrent_card,\n",
    "            global_avg_concurrent_card,\n",
    "        )\n",
    "        if self.opt_method == \"torch\" or self.opt_method == \"nn\":\n",
    "            feature = list(feature)\n",
    "            for i in range(len(feature)):\n",
    "                feature[i] = torch.from_numpy(feature[i])\n",
    "            feature = tuple(feature)\n",
    "            global_y = torch.from_numpy(global_y)\n",
    "        return feature, global_y, global_query_idx\n",
    "\n",
    "    def train(self, trace_df, use_train=True, isolated_trace_df=None):\n",
    "        self.use_train = use_train\n",
    "        self.get_isolated_runtime_cache(\n",
    "            trace_df, isolated_trace_df, get_avg_runtime=True\n",
    "        )\n",
    "        concurrent_df = trace_df[trace_df[\"num_concurrent_queries\"] > 0]\n",
    "        feature, label, _ = self.featurize_data(concurrent_df)\n",
    "\n",
    "        initial_param_value = np.asarray(self.analytic_params)\n",
    "        if self.opt_method == \"scipy\":\n",
    "            fit, _ = optimization.curve_fit(\n",
    "                interaction_func_scipy,\n",
    "                feature,\n",
    "                label,\n",
    "                initial_param_value,\n",
    "                bounds=self.bound,\n",
    "                jac=\"3-point\",\n",
    "                method=\"trf\",\n",
    "                #loss=\"soft_l1\",\n",
    "                verbose=1\n",
    "            )\n",
    "            self.analytic_params = list(fit)\n",
    "        elif self.opt_method == \"torch\":\n",
    "            torch_analytic_params = []\n",
    "            torch_analytic_params_lr = []\n",
    "            for p in self.analytic_params:\n",
    "                if p == 10:\n",
    "                    t_p = torch.tensor(float(p), requires_grad=False)\n",
    "                else:\n",
    "                    t_p = torch.tensor(float(p), requires_grad=True)\n",
    "                torch_analytic_params.append(t_p)\n",
    "                torch_analytic_params_lr.append({'params': t_p, 'lr': 0.01 * p ** 0.3})\n",
    "            optimizer = optim.Adam(torch_analytic_params_lr, weight_decay=2e-5)\n",
    "            dataset = QueryFeatureDataset(feature, label)\n",
    "            train_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            for epoch in range(200):\n",
    "                for X, y in train_dataloader:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = fit_curve_loss_torch(X, y, torch_analytic_params,\n",
    "                                                self.constrain, loss_func=self.loss_func, penalties=self.penalty)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                if epoch % 10 == 0:\n",
    "                    print(epoch, loss.item())\n",
    "                    print(torch_analytic_params)\n",
    "            for i in range(len(self.analytic_params)):\n",
    "                self.analytic_params[i] = torch_analytic_params[i].detach()\n",
    "        elif self.opt_method == \"nn\":\n",
    "            dataset = QueryFeatureDataset(feature, label)\n",
    "            train_dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            self.model = SimpleNet(len(feature))\n",
    "            optimizer = optim.Adam(self.model.parameters(), lr=0.01, weight_decay=2e-5)\n",
    "            for epoch in range(200):\n",
    "                for X, y in train_dataloader:\n",
    "                    X = torch.stack(X).float()\n",
    "                    X = torch.transpose(X, 0, 1)\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = self.model(X)\n",
    "                    pred = pred.reshape(-1)\n",
    "                    loss = l1_loss(pred, y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                if epoch % 10 == 0:\n",
    "                    print(epoch, loss.item())\n",
    "        elif self.opt_method == \"xgboost\":\n",
    "            feature = np.stack(feature).T\n",
    "            model = XGBRegressor(\n",
    "                n_estimators=1000,\n",
    "                max_depth=8,\n",
    "                eta=0.2,\n",
    "                subsample=1.0,\n",
    "                eval_metric=\"mae\",\n",
    "                early_stopping_rounds=100,\n",
    "            )\n",
    "            train_idx = np.random.choice(\n",
    "                len(feature), size=int(0.8 * len(feature)), replace=False\n",
    "            )\n",
    "            val_idx = [i for i in range(len(feature)) if i not in train_idx]\n",
    "            model.fit(\n",
    "                feature[train_idx],\n",
    "                label[train_idx],\n",
    "                eval_set=[(feature[val_idx], label[val_idx])],\n",
    "                verbose=False,\n",
    "            )\n",
    "            self.model = model\n",
    "        else:\n",
    "            assert False, f\"unrecognized optimization method {self.opt_method}\"\n",
    "\n",
    "    def predict(self, eval_trace_df, use_global=False, return_per_query=True):\n",
    "        feature, labels, query_idx = self.featurize_data(eval_trace_df)\n",
    "        if self.opt_method == \"scipy\":\n",
    "            preds = interaction_func_scipy(\n",
    "                feature,\n",
    "                *self.analytic_params\n",
    "            )\n",
    "        elif self.opt_method == \"torch\":\n",
    "            preds = interaction_func_torch(\n",
    "                feature,\n",
    "                *self.analytic_params\n",
    "            )\n",
    "            preds = preds.numpy()\n",
    "            labels = labels.numpy()\n",
    "        elif self.opt_method == \"nn\":\n",
    "            feature = torch.stack(feature).float()\n",
    "            feature = torch.transpose(feature, 0, 1)\n",
    "            preds = self.model(feature)\n",
    "            preds = preds.reshape(-1)\n",
    "            preds = preds.detach().numpy()\n",
    "            labels = labels.numpy()\n",
    "        elif self.opt_method == \"xgboost\":\n",
    "            feature = np.stack(feature).T\n",
    "            preds = self.model.predict(feature)\n",
    "            preds = np.maximum(preds, 0.001)\n",
    "        else:\n",
    "            assert False, f\"unrecognized optimization method {self.opt_method}\"\n",
    "        if return_per_query:\n",
    "            preds_per_query = dict()\n",
    "            labels_per_query = dict()\n",
    "            for i in query_idx:\n",
    "                start, end = query_idx[i]\n",
    "                preds_per_query[i] = preds[start:end]\n",
    "                labels_per_query[i] = labels[start:end]\n",
    "            return preds_per_query, labels_per_query\n",
    "        else:\n",
    "            return preds, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cc898-f600-4197-a142-7bac29537138",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_queries_path = \"/Users/ziniuw/Desktop/research/Data/AWS_trace/mixed_aurora/aurora_mixed_parsed_queries.json\"\n",
    "cfc = ComplexFitCurve()\n",
    "cfc.pre_process_queries(parsed_queries_path)\n",
    "cfc.train(concurrency_df.iloc[train_idx], isolated_trace_df=isolated_trace_df)\n",
    "predictions_cfc, labels = cfc.predict(eval_trace_df, use_global=True)\n",
    "print(\"===========Performance for simple linear regression model (all query)=============\")\n",
    "result_overall_cfc, result_per_query_cfc = cfc.evaluate_performance(concurrency_df.iloc[train_idx], use_global=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab1e54df-ca83-48ac-bba9-ebaf363216a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 3.3346e+08, final cost 5.5839e+07, first-order optimality 7.51e+02.\n",
      "===========Performance for simple linear regression model (all query)=============\n",
      "50% absolute error is 5.436205015541748, q-error is 2.0866504343820074\n",
      "90% absolute error is 74.22621238144698, q-error is 12.12002125949252\n",
      "95% absolute error is 114.76209694732064, q-error is 27.084548610382537\n"
     ]
    }
   ],
   "source": [
    "parsed_queries_path = \"/Users/ziniuw/Desktop/research/Data/AWS_trace/mixed_aurora/aurora_mixed_parsed_queries.json\"\n",
    "cfc = ComplexFitCurve(opt_method='scipy')\n",
    "cfc.pre_process_queries(parsed_queries_path)\n",
    "cfc.train(concurrency_df.iloc[train_idx], use_train=False, isolated_trace_df=isolated_trace_df)\n",
    "predictions_cfc, labels = cfc.predict(concurrency_df.iloc[train_idx], use_global=True)\n",
    "print(\"===========Performance for simple linear regression model (all query)=============\")\n",
    "result_overall_cfc, result_per_query_cfc = cfc.evaluate_performance(concurrency_df.iloc[train_idx], use_global=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5323f7fb-ce66-4443-97a0-33be6bc2eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Performance for simple linear regression model (all query)=============\n",
      "50% absolute error is 5.661937418674135, q-error is 2.10329112364105\n",
      "90% absolute error is 75.90385075638284, q-error is 11.512979169070585\n",
      "95% absolute error is 119.0894088532552, q-error is 25.410259635121143\n"
     ]
    }
   ],
   "source": [
    "predictions_cfc, labels = cfc.predict(eval_trace_df, use_global=True)\n",
    "print(\"===========Performance for simple linear regression model (all query)=============\")\n",
    "result_overall_cfc, result_per_query_cfc = cfc.evaluate_performance(eval_trace_df, use_global=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b35cca09-e256-4630-8eb1-312c38f8dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 51.82382569600055 1.7247650271130417 51.22344125883993 1.6370317833217243 37.80836582183839 1.450638647264475\n",
      "1 2.671035890011117 16.95079370664506 9.162169084777199 22.113613320078173 1.3425602316856384 84.20188574546069\n",
      "2 55.94572149242434 1.5840677671241252 52.353389160758546 1.8018835159294326 38.74426138401032 1.3671155104772483\n",
      "3 1.1440348529815674 25.991297294589494 9.246921200096308 23.78898572476075 0.31357495684642345 124.35531025554901\n",
      "4 5.2738345414635255 2.0669263956193085 9.995737244376748 2.6146849225270765 8.100630760192871 2.3497256889568483\n",
      "5 2.378194674468218 1.5616459652245138 8.383089867236698 3.227604855467194 6.548046827316284 2.7529165339994384\n",
      "6 2.230724239102172 1.7144862467184558 8.189598985742462 3.279328779957821 2.9037328233243898 4.393588383279897\n",
      "7 2.1779135631770448 1.7714973966397078 8.694922407953747 4.0242551201804275 7.637907981872559 4.845469317418319\n",
      "8 1.7670155280991926 5.5969947753034255 8.443826408700197 7.890019923848901 0.8219994773389772 45.21716394623314\n",
      "9 20.54896174654497 376.1803684093027 9.939381237419031 149.51217243466232 0.22576380521059042 59.461438921134324\n",
      "10 11.59421030875188 1.6744801760925285 18.404078815415147 2.0599054004554067 11.061795115470886 1.6316176349314384\n",
      "11 37.875410625460404 1.8464354932344156 34.862212889964525 1.774274167984859 41.20747947692871 1.5827004754857472\n",
      "12 1.274437858838087 1.6639218352014824 7.2056229234126565 2.755201397377987 3.251845061779022 4.3682845838000866\n",
      "13 2.180443486681536 5.369547086024525 7.5304462931740765 4.619616412410024 1.4286030997755006 100.44557743002979\n",
      "14 2.4946444598577417 3.3803372346661065 4.321815927979428 3.014189283002654 3.0354299545288086 3.773146170378554\n",
      "15 3.2820275837901476 3.0734160509254957 8.609406653989037 4.675015897071138 4.496277570724487 5.811062404463785\n",
      "16 37.04985239839179 1.5675830561967916 46.57137682573701 1.907216436563088 34.73650443553925 1.5696197838841166\n",
      "17 73.97697636129767 1.5389589395073964 56.3282674925472 1.387289081866625 43.93999850749969 1.336542565455045\n",
      "18 33.70973311313614 1.741663567159707 37.52136745730142 1.7689062304924787 24.532870292663574 1.4829217860641186\n",
      "19 0.984076280398726 3.78329218116105 2.157479402283799 7.007412217312356 0.46279947657603765 279.2467938348776\n",
      "20 2.0978745149419824 2.1744384542503896 7.199925115518607 2.6637073615313493 4.158838474249933 6.078078668535232\n",
      "21 1.2243132160928327 4.174050289700478 8.46068353017178 8.585228255371794 0.564227819442749 66.68941584248465\n",
      "22 130.01884897032414 1.94260751583424 111.35400024140549 1.8098774297912001 50.672586679458604 1.4289690900600074\n",
      "23 0.41799997612601947 16.648865474572297 9.215914399491977 41.85421305180742 0.25859539408702403 108.27683888178427\n",
      "24 2.183614841791755 4.85410810111896 9.465954833937575 8.38963210080377 1.1657721633673646 15.90306253240075\n",
      "25 2.086069717894701 2.6720477784727046 9.191961409984621 5.205410040148281 4.961615324020386 8.504068999582325\n",
      "26 2.509101167845185 3.258904823929668 8.860192461204006 6.430885866766108 2.1612401838065125 13.859874366577188\n",
      "27 88.32409030083905 1.8753484876146427 67.7310042106923 1.7024116756931236 34.36752665042877 1.42093976678753\n",
      "28 18.50130704978288 1.8278163210423717 36.20758232320913 2.5187917666524866 20.856873989105225 1.8419276554014872\n",
      "29 91.50875021440501 1.7924237752146914 90.07295393426031 1.734672141648998 34.64831817150116 1.2639683502324885\n",
      "30 0.895491029029992 12.871123246353902 8.98479386557054 20.58662320695939 0.3165098895551636 120.46026611377148\n",
      "31 8.472709552642115 1.9363950484455406 8.694781604497267 2.3877389234617943 15.045686841011047 2.832256372249162\n",
      "32 1.1097053475705438 17.6098346710205 8.30550348963573 7.878050653067606 0.7162067164899781 121.9174804000263\n",
      "33 1.8544358227299234 15.722585259809035 2.0893136881351833 2.806895958805622 0.7714585532667115 48.61211545838231\n",
      "34 55.395284345624546 1.5993601110306441 64.91881714508685 1.8157092844767624 39.756623148918166 1.430557240444558\n",
      "35 2.207721164158381 19.11406405793221 9.281604381811782 57.77152432595303 0.19353382487315685 107.08355395005891\n",
      "36 1.135233392715454 10.275983810424801 8.28112042124259 8.925109277085552 1.0551611651899293 39.98332439215628\n",
      "37 4.727988437670815 5.293717499818764 10.145964132744645 9.990639339379506 11.25237973878393 12.735859339822824\n",
      "38 2.8746953468946295 2.027410106106665 7.003997325897217 2.210306718662129 9.230855703353882 3.3580516247965653\n",
      "39 22.21827706835201 1.633087062767478 17.47981718335979 1.6011674036668821 21.001088976860046 1.460111276762182\n",
      "40 2.538413728465463 2.190851732053388 8.916406828452368 5.017467744401757 5.499102519941516 6.54411569271913\n",
      "41 2.4710121343252096 5.847358274921692 8.656877139076965 3.798449903060008 3.508081793785095 5.691522335338455\n",
      "42 1.7838933474226804 4.402070498592896 8.480305064348178 7.290159490741655 1.0100871791364625 447.3347451406791\n",
      "43 2.235009530573478 3.027417448655515 8.760043803871259 4.011925092691248 3.859952926635742 6.362471803430903\n",
      "44 1.1912982240260195 3.3426208853837656 8.29407886466849 12.815835066744285 0.6831090917112306 339.2884570139355\n",
      "45 5.637784196886335 1.8192900913650265 8.984604515512663 1.899033567559916 7.842929363250732 1.8658906644492985\n",
      "46 31.6874842541355 2.6398199733558547 33.034554407351955 2.527938103771529 35.06804823875427 1.6044239951124977\n",
      "47 0.9387226065128698 2.1665417687990285 6.653691549608158 3.174849410618185 3.3600597381591797 9.174850455279573\n",
      "48 27.7088293549671 2.42281048397698 32.899452113889076 2.2616341507167737 29.586105823516846 2.048714949915662\n",
      "49 10.726310480475078 2.0706862865447975 17.038021420521943 1.8975014649361848 14.585431098937981 1.6111379480776673\n",
      "50 2.1867426197150834 1.3831034955248096 7.0904993461538925 2.0414376778177807 5.999722242355347 1.9709822832060964\n",
      "51 1.3123620104926723 9.393870092508426 9.0188604639614 15.84755287396245 1.4830583333969116 51.406176108236465\n",
      "52 2.89075004366885 5.426562877051887 6.086963155289915 4.467573696948019 5.528533220291138 4.7671726695917815\n",
      "53 1.2259928469850452 14.170615586915417 8.734278296517251 14.534515801367247 0.44123058865079656 68.01531929357844\n",
      "54 2.950113960937827 2.093933109458674 8.534894535333743 4.112906779041196 4.164794610929675 3.173546086783226\n",
      "55 2.792113216506861 4.7147479270660195 6.64792238059816 2.778176310685712 3.949799418449402 9.929931305998345\n",
      "56 0.5238761638318037 14.228676556614019 9.12601050557338 29.181881935416676 0.29074196715373546 150.51197290782756\n",
      "57 1.3671489052571597 25.269242656162547 9.254337921033958 50.119912688823845 1.4928269665688276 63.79445349424276\n",
      "58 34.087977537380965 1.6268223155857544 42.21122988264732 1.789537927720547 37.0948600769043 1.3803429264883116\n",
      "59 1.9087956774869843 2.652229440900193 8.546207485801098 6.340594143840477 1.1577769984724 798.1173613071577\n",
      "60 2.37879561306526 2.4002269623736625 7.643028912687006 3.897940309658615 4.248966217041016 2.7348878657700118\n",
      "61 11.782249779568541 2.1377122956900036 9.511517344459627 1.8185499555750506 11.71222734451294 1.7800410890801173\n",
      "62 1.161070807314918 6.350200365166534 7.903729933320465 7.77650536919017 1.4825537204742432 21.843431898626402\n",
      "63 1.0392084333722726 9.845529953498207 9.087701380905314 24.39410420006918 0.4732324351789429 115.66781448288022\n",
      "64 1.3265038717369286 5.195975615897043 9.025993528775315 17.971606231397917 1.644628690672107 135.67542385361466\n",
      "65 44.87756355032499 1.5453332651718454 42.78031057470797 1.6165724630231766 39.48365116119386 1.5761337719402049\n",
      "66 1.719527399086219 3.8860480081155333 7.336151098666061 4.865239757859826 3.5227216482162476 9.905434613559315\n",
      "67 2.899174060002151 2.2299083071136447 8.610725646579494 4.915617211166575 12.016731977462769 6.540209821221329\n",
      "68 1.7694409541744982 74.4217976472021 9.343980920962592 290.84791924443596 0.02590029139537355 25.152443644800535\n",
      "69 18.171319223240808 2.8432149622070946 20.458529038003093 2.4464306764194954 29.01383638381958 2.4292493164305244\n",
      "70 2.0399368553742625 7.961412791018721 9.140090600872904 30.90011946190499 2.3001134395599365 34.43035920735047\n",
      "71 0.5797708950897107 9.347566204473866 9.050285765786743 26.884048683719424 0.44445555109996343 101.9008111237163\n",
      "72 1.5009464661695642 3.1956020713815256 8.904301962550722 10.84870790247533 3.9028788805007935 14.704229580147704\n",
      "73 0.6979292167255193 9.771114173237196 9.228036663498143 42.783577567125576 1.1426903476240113 65.48404382570992\n",
      "74 24.10853325596198 1.7662399706918892 25.11468393039524 1.9083718218140913 23.30975306034088 1.5674076770384193\n",
      "75 30.705498990681455 1.5763401060656974 42.90555139986685 1.4707912442727544 44.161638259887695 1.5733776625142297\n",
      "76 4.548699054161809 3.639392761730704 8.239232122873615 3.177403323363938 2.7018687725066997 13.834357854009973\n",
      "77 178.00231687555544 1.5554286108978221 155.39096160139218 1.5311397461968208 115.88237953186035 1.355485859499721\n",
      "78 3.370433848313067 2.2359533326666843 7.329181566783788 2.5252490972714656 4.668763720488641 2.749562799280389\n",
      "79 10.614943014800087 1.695826128294079 18.842838852063494 2.222607821407675 18.31540596485138 2.043034190850007\n",
      "80 5.707215425907634 1.5369940465594323 11.066725805660745 2.5202976600601055 8.133123159408566 2.0604659881521235\n",
      "81 83.14344413312583 1.5603499916050874 81.38802526675784 1.5631822770765116 50.22119927406311 1.4501375219678556\n",
      "82 1.9130634892298204 1.860355969962997 8.780007452381733 4.922821812942374 2.026334635040257 893.0044105486348\n",
      "83 3.6156633205689506 1.7619666001119865 8.20935219666805 2.66398159453407 5.16755485534668 3.4953795298597514\n",
      "84 2.9764900721175414 2.2787946036094016 11.749218539740092 2.69608689032576 6.743113994598389 2.907857311314105\n",
      "85 1.7348816868141408 15.84469217764775 9.343112685357204 36.64930490388485 4.648427963256836 33.89005777370914\n",
      "86 3.7450459491975483 2.21876902734139 8.569244109741168 2.496084583503575 5.462441444396973 2.7752498001273977\n",
      "87 1.7846459970889654 3.73788848279514 8.739298254141382 9.992019136517042 0.8650838603498414 438.4169370315375\n",
      "88 0.5468847813340465 15.995803723625666 9.142916864488457 31.74446364787373 0.302432702970691 108.97397477396504\n",
      "89 1.4379059949529829 2.67203900584017 8.86865545622224 7.389578032055255 1.8808000087738037 17.034981116481326\n",
      "90 1.1948643448473997 16.53013229370117 9.235951776175488 57.10364613351018 1.8720245361328125 55.96470567006612\n",
      "91 15.267512086929292 1.4977167241838107 21.186075075693772 1.6606487523038476 22.204212069511417 1.8129055411675363\n",
      "92 2.5088310047511984 3.727369996280369 9.051169233860872 5.179643675715531 8.443132758140566 6.786549097678231\n",
      "93 8.575723044065835 2.1341895546338563 11.787397980690004 1.915970773500387 10.604274988174438 1.9427301993403103\n",
      "94 36.68010568323612 2.482138778465164 38.675081153408435 2.3277230628683734 39.3666455745697 1.71619729096759\n",
      "95 2.276408888733844 16.706710863470136 9.271778183831897 43.38160496002676 0.2305807342054322 160.64857673544674\n",
      "96 1.2175919582316186 13.231640040172897 9.030442462811093 17.350075301861107 0.615592168760486 244.7132948037441\n",
      "97 1.229916910322831 12.981867790222159 8.784607704854054 14.06240270105281 1.0392816066741943 86.63773125174978\n",
      "98 2.342892489054936 2.1504025973442524 8.030805580938855 3.858244098097519 6.887146472930908 3.8519171231362814\n",
      "99 1.360780888777536 7.44079866195104 8.579965018216354 10.952922680894796 1.7628189325332642 19.58137446282369\n",
      "100 6.574263046038834 1.6357006689958038 17.005765740383843 2.3202368010937144 9.763499975204468 2.29793326915357\n",
      "101 16.72067750241159 1.8975097900164861 30.500907394600397 2.3654782194273216 17.90193223953247 2.069381972747099\n",
      "102 17.470879575989912 2.148132526337933 24.027477114103917 2.849990383105648 28.27434253692627 2.2134824023977893\n",
      "103 290.70541009812786 1.4314760359114977 350.2835257833499 2.0725709802557475 105.89561915397644 1.1638721458750036\n",
      "104 2.6752079646423503 2.2955618692233855 6.986673593521118 2.671553728418126 7.782880187034607 3.308964549088768\n",
      "105 3.046056446295495 1.7832973795974563 8.209488656403076 3.0011032695287323 4.399014711380005 2.6737536027251156\n",
      "106 38.90704076717803 1.8225232174850792 34.724866795204264 1.6927985220984234 32.140666007995605 1.5932868166884633\n",
      "107 50.260701479981364 1.6871917670558587 55.981043934822075 1.9021214269658695 37.08853089809418 1.4704579930841661\n",
      "108 4.248210311123487 2.1369866974670484 7.001546677513373 1.9903449378172005 3.7678717841627076 1.6581668782100651\n",
      "109 14.30855311258044 1.750762007120986 23.615884952509884 2.1458432814140007 16.115898847579956 1.9045961056353282\n",
      "110 3.6848736927094388 1.819986400192927 8.768478820345553 3.000712251079695 5.926647150015924 2.8391675832628978\n",
      "111 1.546732105637429 2.0151552137414246 8.332442054588912 5.760844682247327 2.6955686807632446 16.405927207629865\n",
      "112 29.226659544831165 1.881824164802686 33.73371280501948 1.715866100808666 28.22290563583374 1.61869975428817\n",
      "113 4.757954809912055 1.4007464994215966 10.463070853889644 1.8845826342248342 9.646044313907623 1.7283331580086128\n",
      "114 4.033379409128175 1.5868943908815731 8.389148367366996 2.097381598475748 10.731847286224365 2.733976215522722\n",
      "115 40.77499343577209 1.7873222906284711 49.35143364410585 2.2036452549536754 30.706540107727058 1.4118955630792065\n",
      "116 27.401580605523158 1.917642447365352 30.342330733982735 2.4564007510794132 30.344449758529663 2.071692599790222\n",
      "117 3.7828529107814033 1.509985465090337 8.117506191617942 2.063045720120565 6.748033785319421 1.8687769626159034\n",
      "118 3.6785397089082643 1.3337260118043748 12.869221725802099 2.037110141575357 8.946703910827637 2.5169615425071625\n",
      "119 1.8272830776353515 1.7415937187525468 8.083859286505906 3.236719528456125 8.804399371147156 7.894665888970356\n",
      "120 23.90166626217015 1.7958746385726803 33.73693566254425 1.8904828432143435 33.920658826828 1.6685672372327112\n",
      "121 1.5554309489291764 1.9166205373738094 7.169213275308994 3.1270099158982037 4.410417437553406 4.593065666943836\n",
      "122 5.896550878139431 1.4009804918806936 25.56701663369411 2.022294143066595 9.228223085403442 1.7442012328016294\n",
      "123 7.358317824030946 1.6738539267428254 21.195734792610637 2.3588947495416317 14.327574610710144 1.7399159880695518\n",
      "124 20.23740460351185 1.8984442449069183 23.584945402894085 1.7978839183595876 40.22873544692993 2.0086202058379836\n",
      "125 1.7703241286471842 2.0223939574806673 7.806168566591024 3.8370393891663475 3.1643758649588563 4.326539234477449\n",
      "126 10.10113298338473 1.521156257119654 21.9788542357515 2.0568525721598556 17.25755739212036 2.2791300164138364\n",
      "127 2.6419670587436306 1.8825115226928344 8.132338148806683 3.5401828685043695 5.680108428001404 3.6680416571442507\n",
      "128 1.9695655102660408 2.0776918439301912 8.553255311600275 5.707107713203514 2.274322831130121 16.779822719128934\n",
      "129 2.56273928349165 4.485220467832145 7.169999397785176 3.358197823402856 4.928680181503296 3.5882777974199587\n",
      "130 2.0184566580491974 2.0255359160934394 7.602265533912222 2.3090435582552726 3.7626099586486816 7.193763093581334\n",
      "131 7.909075812839891 1.7950971187746423 21.017496122078683 2.2847325639314473 14.310495138168335 1.8020790410659515\n",
      "132 45.73325451868022 1.5797666022572678 38.56476891388409 1.4467798532662173 39.3364679813385 1.4824561328490113\n",
      "133 5.801645807788599 1.6457192840607955 19.48339394049009 2.171152430961902 15.626067161560059 2.1836011113313667\n",
      "134 2.5470623201825235 3.2577376197804613 7.213302762517515 3.9795583714348344 2.375416361785028 31.31031193495169\n",
      "135 1.5037371003531708 3.082444425600059 6.3082413312092385 6.595836777404034 2.0103325843811035 415.21547252685843\n",
      "136 3.888867699109978 1.6586929248379185 8.526135919659408 2.293518600610411 7.949661016464233 2.8563653232185597\n",
      "137 3.340577684815887 1.7330123084883235 7.9385551054159365 2.59801409544301 4.486660480499268 3.313323922341273\n",
      "138 3.760941496925734 1.7331799684319027 10.220979539174454 2.950182846271457 7.711771213507745 2.777691379602367\n",
      "139 1.716429256754484 1.6131269795619416 7.636580421981513 3.406323933039605 3.685386144614313 3.708454388103959\n",
      "140 18.449451723354183 1.5767406215134983 19.126897121154194 1.776761627164514 16.181798458099365 1.5323381824965132\n",
      "141 24.94848239730264 1.4716781610160512 33.333784108273946 2.039550134605271 23.820610284805298 1.7443871228304975\n",
      "142 2.7644572985430873 1.6253675792813969 8.60880116217077 2.940149827561581 6.940480828285217 2.6399505323944603\n",
      "143 37.25600121468747 1.6093673425513064 30.57135835649619 1.6055167041611242 24.660377502441406 1.5946635036857542\n",
      "144 3.8193278632870316 1.30437840081628 17.887190518930943 2.0851598911237623 13.19538414478302 2.017790239682801\n",
      "145 1.8309921523537576 5.665116236693692 8.982263074814153 9.38271566395618 5.939820170402527 30.079231396522673\n",
      "146 1.572604291847234 2.593121939932584 8.677563147269424 8.936306437416196 3.8810858001234 26.222566984436074\n",
      "147 3.6500525796682384 1.9245552281244638 6.42724607559169 2.0394219715679176 3.7107413281919435 2.112329089039004\n",
      "148 6.549342321071413 1.4842837884996651 15.724188183858454 2.074446679331035 6.657726526260377 1.485004277906958\n",
      "149 34.00690883322693 2.0381515708744824 38.51876697104615 2.065239037018264 32.53931510448456 1.6002329174445147\n",
      "150 5.956358814718333 1.5839403401261425 16.653834764629615 1.947338855811147 14.967154502868652 1.8963405009370151\n",
      "151 2.436605611206185 3.229334690433129 7.089375441455292 3.8389209045621633 2.9780993928434327 3.7018420273512556\n",
      "152 1.4685898255904084 2.3629296422938797 8.644362701103358 6.021466294947164 3.656122409796808 5.193702597389381\n",
      "153 6.140889808120166 1.434762634222368 10.43375573191146 1.7314606720233214 13.044641017913818 1.8192059405391545\n",
      "154 4.342866334941209 1.8905648849229921 7.8596469946872585 1.7470906038555643 11.02414584159851 2.144206033249379\n",
      "155 6.474755880144135 1.4516005222680677 14.390302170392928 1.8381491131541676 18.8244845867157 2.2189634978998773\n",
      "156 3.7279371809075927 1.8613276212707752 8.288718816712874 2.7669123494075984 5.907885670661926 2.7673588078559312\n",
      "157 1.2038302781735868 3.3156728515427867 8.075996309065037 7.138656299239445 2.9569942951202393 47.75415985578887\n",
      "158 26.228828046314206 2.2624408885893925 23.723341152900794 2.525835639640365 30.39517307281494 1.6896950523431518\n",
      "159 9.309652033119143 2.0524020027659775 19.956631233912404 2.0969720058051555 17.11555325984955 1.9719326471052163\n",
      "160 3.3783632126946035 1.3552530990730476 7.80808380854773 2.0300250322941977 10.056322263670154 2.024725506279114\n",
      "161 37.62199781528781 1.8239754158273271 32.15198670225277 1.8637317836095026 30.30273985862732 1.4425113641661096\n",
      "162 5.962548799118501 1.5147525188876532 16.054747717702284 1.7647939654152038 14.518188238143921 1.8330478405537076\n",
      "163 25.334903327237342 1.9227239658945028 19.35041427363976 1.6918079254680856 16.85602569580078 1.6052472778896447\n",
      "164 4.4448085622120965 1.6777182178685026 7.817494091910202 2.0893356643976726 5.845333755016327 1.945063079184717\n",
      "165 4.109087500209451 1.4007236289864013 15.64019227027893 1.8689792381698451 9.050512671470642 1.961091493614897\n",
      "166 23.732346182692872 1.683969956585037 55.763408918370615 2.1079585569462402 17.71753680706024 1.3821153003790907\n",
      "167 7.256479242807336 1.975203891709429 10.619598768087883 2.0104138885531166 10.771439790725708 2.158379357474863\n",
      "168 1.4902252414661565 2.4870247312788636 8.496297635077466 7.346229950654186 2.999455690383911 9.487931382296175\n",
      "169 2.5210597145018774 1.4139640151977266 7.807470380691919 2.0505159319537682 5.195062087965198 2.0058751374956736\n",
      "170 2.981444209189518 1.390294195009354 7.755078553750144 2.07509499555221 8.272006750106812 2.0423603879595396\n",
      "171 3.997602631871059 2.0177517372106815 8.112452880862127 2.6233315974375757 7.032283067703247 3.732286111725746\n",
      "172 25.78760634995992 2.4195096208477644 24.677728348198297 2.1426159572346655 45.03680467605591 2.1552050402096206\n",
      "173 3.2743090912421318 2.40700015204199 8.466592987075625 2.817544332750896 4.009080254531 3.618411671797971\n",
      "174 2.327886608596364 1.400995670044933 7.8469322081590835 2.492888795637932 4.252210067701526 2.5617592398674596\n",
      "175 3.9041917794918266 3.042990696334138 4.783584133078458 1.8573079528176755 4.405043601989746 2.618958495377562\n",
      "176 4.066416823162094 1.8790185900444494 8.29257364465377 2.1572994288464997 3.2708678245544434 2.13260300240377\n",
      "177 7.653245722018619 2.8420865903630026 16.64147654275881 2.623615719734211 8.408918619155884 2.7869968816757527\n",
      "178 1.6818907690975031 3.0030686281351966 7.225786141527951 3.8032413153252165 3.020193338394165 6.504983184605716\n",
      "179 14.263785675237303 1.7405482776199515 20.03393150612349 1.6849495129281644 10.844019412994392 1.5037315708552683\n",
      "180 7.07295699585074 1.6017211756153913 7.873070815744629 1.585967333886086 16.87507963180542 2.292266592176018\n",
      "181 2.807545111219629 3.693520259137504 7.976964042116723 3.905055173030089 5.264825344085693 2.5769645943172725\n",
      "182 5.587185257626189 1.3617484354028258 19.338136230001176 1.9615035831544794 11.976207256317139 1.6318545587428646\n",
      "183 22.15872358625263 2.322363535460091 27.052612849646437 2.0061030628320955 22.520479202270508 1.8760405081795317\n",
      "184 13.373379000369717 1.8121610099725176 24.57056297733771 1.9816980120950896 14.7896089553833 1.7813269963044407\n",
      "185 1.5391877931927964 2.5867716621381214 7.13691166646759 4.101960144134873 2.3703545798780397 137.94793417255923\n",
      "186 1.9167568726761393 1.855010298313254 5.596311998220132 2.3418667269034277 2.1893389225006086 4.095211608119906\n",
      "187 63.481358881057844 1.5820094960329225 53.911099266187236 1.6509766806826012 32.47843027114868 1.2696666294055163\n",
      "188 2.3341467545484536 2.696458545380224 7.841761260778416 5.116250076406439 6.294450044631958 7.778921366480545\n",
      "189 3.04565967298355 2.4119227283983893 8.627147773952249 3.3958339890300477 3.921168327331544 2.580612581463816\n",
      "190 8.499319059957777 1.3284537656574407 30.212260992610204 1.992456187474148 14.661956071853638 1.917770015457507\n",
      "191 24.133955713737468 2.086793212773124 29.927727690239223 2.135865730255329 39.08571147918701 1.7502337463753728\n",
      "192 24.09523349871843 1.6991129076758555 27.911027144484677 1.5544686737348063 25.448894262313843 1.607731393435071\n",
      "193 5.954492165101051 1.4977242805514674 15.353191264975877 1.7607204011409046 18.081534385681156 2.1108501706933906\n",
      "194 20.25687644519706 1.5481534819159215 29.799425678830307 1.7618307569402312 21.533539295196533 1.4430902571222042\n",
      "195 1.46761430457006 1.4783882712275753 7.032969632056867 3.073845781246567 3.135099732375238 2.5995425779255523\n",
      "196 2.893642687535882 3.9388650904971025 8.16070190266221 3.537698847463225 0.862392591428943 17.162566093130266\n",
      "197 2.4846752622161876 1.4313912503215065 8.129644978039188 2.280586826646819 8.19988226890564 2.7394944029778863\n",
      "198 38.86523941567282 1.846892264393791 41.507051868700955 1.8794461259196111 38.850188970565796 1.6823038213952315\n",
      "199 4.734571062295184 1.488723679308598 13.125811917715215 1.7455191414828104 10.25987923145294 2.0413591691908253\n",
      "200 11.863582163767305 1.9186576038103216 18.367992849987345 1.6453770269130996 11.981256783008575 1.5084113842977678\n",
      "201 5.756588737290624 3.6634599238158057 10.565065273525555 3.5187583589253952 11.01536762714386 6.883608518963157\n",
      "202 2.656612409067973 1.7364593357334797 8.625068262796882 3.2992744266266936 5.207863092422485 3.0759041071217847\n",
      "203 27.8071131111911 1.742966740380278 37.478264472278255 2.139434336623422 18.52632451057434 1.6013662651882858\n",
      "204 5.4943592337961125 1.981275345815711 11.531536675021124 3.08033593469855 18.248632192611694 3.2031328053796977\n",
      "205 60.47038941004132 1.5190369027475332 86.98934146104492 1.9554566100992332 49.04316055774687 1.4078111285164763\n",
      "206 59.33595859310624 1.816008985011139 66.49322472114002 2.0099760181597626 74.39938354492188 1.4781289416574197\n",
      "207 24.12343133897785 2.644963191590789 22.770845081757344 2.0557151509434366 39.61898493766785 2.105461152969353\n",
      "208 43.37800704700882 1.7478517409403844 53.66596574707212 1.8856935845992193 26.206101655960083 1.567744257020293\n",
      "209 2.323198594815214 2.5604723660890976 8.935681365026232 5.981389087683141 3.2492170333862305 12.43535895888663\n",
      "210 5.016704234849712 1.877833374242242 7.332126177901433 2.130784988264423 9.517066478729248 2.644797393898072\n",
      "211 58.98879753681388 1.3653279178077917 67.52959617633823 1.6754459866667772 35.79153537750244 1.2532301167073958\n",
      "212 3.6054979915937793 1.5879879596416693 13.262715243479974 2.1566113822480135 13.9378662109375 2.3393535684367026\n",
      "213 53.731850836279165 1.6250036803149706 51.05289543461439 1.8245605086273682 57.14778518676758 1.502093448154501\n",
      "214 73.48066580789431 2.0439974263184015 96.97403754176725 2.403272978307789 55.187915563583374 1.467365455761487\n",
      "215 17.92964659046114 2.4503146246915373 23.528418737051744 2.6483897698962107 38.27261471748352 2.554736928244987\n",
      "216 16.775203738205427 1.7032657596673095 18.9166696916402 1.7078628978084092 25.428398489952087 1.7458208287439012\n",
      "217 2.962349399242516 3.0081783474834873 8.74816305683988 2.788699540251449 5.247154951095581 4.624743500404421\n",
      "218 5.475062024299584 1.8016544076598444 8.634117764469805 1.4260601040677847 14.858087301254272 2.1803159030754937\n",
      "219 64.02411816611026 1.803126627649188 55.13515132570774 1.9919617393968982 47.709447503089905 1.4963494445776004\n",
      "220 9.968930895362522 2.4934823060362383 13.505324093953455 2.3001591168925124 12.957431077957153 1.8077237842485654\n",
      "221 41.70743243267887 2.4896705514212623 31.712029205348934 2.1093703859572686 24.170115470886287 1.9407583509754534\n",
      "222 52.88458685841951 1.4290514346958185 53.56047354535331 1.547406235237827 33.83184456825256 1.390772298796079\n",
      "223 14.362298108752949 1.6354116197135782 17.630716966903684 1.7969885501199285 12.844985961914062 1.7054359164960768\n",
      "224 19.26965641461001 1.757249299349184 15.245452279939883 2.289701645404515 21.163416385650635 2.1801915155588736\n",
      "225 8.800461286218237 4.326954889196289 10.272774384193044 2.81398838812523 7.473646521568298 7.7083583599523156\n",
      "226 3.120495423916889 1.8341442919511124 9.890405623551445 2.3162862214011013 3.9086225032806396 2.8256326490361534\n",
      "227 52.189939568246 1.56754885883915 43.00197870677677 1.809859728184651 28.213231801986694 1.3212015996691415\n",
      "228 8.109885720847464 2.3299612915965087 21.230792029925034 3.4739120387533875 14.891788125038143 2.4094170288564483\n",
      "229 49.55721500244829 1.418547747104484 57.70536857339333 1.8214912436162125 51.80534207820892 1.3405124449104744\n",
      "230 36.31795388776513 1.3011915989781804 63.126487152183586 2.0535518366765078 54.995699405670166 1.3979557352953058\n",
      "231 20.591442687672078 2.1765675005590346 19.017818444999108 1.7644359588479999 28.624948740005493 2.117428802509155\n",
      "232 51.0245908506158 2.000874069996035 51.74042508850641 1.8547680078361297 14.750982522964478 1.3616239570131743\n",
      "233 5.263520454404395 3.9949107167249913 10.609693272308057 4.045035473057867 7.7632519006729135 3.3130224394653665\n",
      "234 7.191691305184663 2.5413552506298185 11.803664570683772 3.602787849307744 8.681593418121338 3.810051527683061\n",
      "235 137.40379920444906 1.529283541000312 83.00868846412666 1.52282200692449 41.955758571624756 1.2438596310910575\n",
      "236 4.356624322118474 1.9068798534811728 8.344543631836519 2.569425770903356 9.228102803230286 2.8288302637329448\n",
      "237 54.98017574537431 1.8112045170620232 60.894883556715435 2.273553767134376 75.66135334968567 1.5943346111426953\n",
      "238 50.95163105394623 1.7572801160451745 58.07548109114838 2.119041958175419 54.08880484104157 1.4951309549890843\n",
      "239 30.041523990631347 2.279661679133112 27.264994385692404 2.385113828579717 43.204360008239746 1.9305023124637917\n"
     ]
    }
   ],
   "source": [
    "for i in result_per_query_cfc:\n",
    "    print(i, result_per_query_cfc[i][0], result_per_query_cfc[i][1], result_per_query_sfc[i][0], result_per_query_sfc[i][1],\n",
    "          result_per_query_xgb[i][0], result_per_query_xgb[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "011ffc49-3f08-4401-ada2-90c792c8c26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.924950122833252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 43.99655748,  34.94623108,  17.72149467,  10.56022811],\n",
       "       [ 44.24343477,  34.94623108,  27.44502831,  16.47497368],\n",
       "       [ 44.40851256,  13.24915453,  27.04289436,  57.60951018],\n",
       "       [ 44.85594944,  22.40939974,  30.49825859,   4.00279546],\n",
       "       [ 45.05420997,  34.94623108,  33.12750244,  15.77505875],\n",
       "       [ 45.40674458,  22.40939974,  39.985672  ,   2.13486624],\n",
       "       [ 48.75521397,  34.94623108, 178.01794434, 153.18231106],\n",
       "       [ 54.94138748,  22.40939974,  30.96467972,   2.75144792],\n",
       "       [ 65.71767275,  60.01989378,  33.15547562,  33.16273236],\n",
       "       [ 86.31415185,  60.01989378,  59.86411285,  71.74322939],\n",
       "       [ 89.16649693, 160.31454456,  62.6312294 ,  58.17491651],\n",
       "       [ 95.1809856 , 122.70405052, 109.89292145, 312.86754394],\n",
       "       [ 97.30431529,  60.01989378,  42.58627701,  30.59504151],\n",
       "       [100.98178197,  60.01989378,  50.93345261,  38.58145213],\n",
       "       [104.85802359, 160.31454456,  88.37911987,  66.89298582],\n",
       "       [106.18721107,  85.09355648,  46.75362015,  56.54027414],\n",
       "       [115.34599246,  97.63038782, 139.04110718,  85.87236667],\n",
       "       [116.15064642,  97.63038782, 128.81037903, 181.68677855],\n",
       "       [122.13016515,  85.09355648,  24.5381794 ,  42.09157777],\n",
       "       [132.63039365, 197.9250386 , 172.23661804, 147.01784205],\n",
       "       [133.69491466, 122.70405052,  99.41881561,  61.19624114],\n",
       "       [158.43949965, 172.85137591, 124.86359406, 184.6730299 ],\n",
       "       [162.04811759, 273.14602669, 221.21820068, 103.84171915],\n",
       "       [164.11570577, 135.24088187, 164.73368835, 132.50536299],\n",
       "       [166.09265942, 210.46186995, 166.71170044, 270.34568071],\n",
       "       [170.44734718, 122.70405052,  72.72597504,  74.98490024],\n",
       "       [172.72227197, 235.53553265, 223.69631958,  99.54465294],\n",
       "       [175.1428882 ,  85.09355648, 256.26669312, 179.83020163],\n",
       "       [181.5189996 , 122.70405052,  96.12817383,  87.13339329],\n",
       "       [195.47811307, 185.38820726, 175.37162781, 130.72873735],\n",
       "       [212.21452534, 122.70405052, 345.15869141, 272.05857682],\n",
       "       [224.44738256,  97.63038782, 225.99049377, 256.83262563],\n",
       "       [225.63579825, 248.07236399, 391.78607178, 390.25599051],\n",
       "       [228.92783674, 248.07236399, 233.58288574, 255.41880393],\n",
       "       [234.21965986, 197.9250386 , 289.14428711, 183.51547289],\n",
       "       [263.97062419, 260.60919534, 193.39703369, 254.39087868],\n",
       "       [273.71498626, 260.60919534, 188.66110229, 150.09467673],\n",
       "       [307.98622845, 398.51434017, 498.36987305, 400.68429756],\n",
       "       [308.75909678, 310.75652073, 358.08959961, 369.08968568],\n",
       "       [338.3684506 , 436.12483421, 419.76296997, 402.3540926 ],\n",
       "       [444.53437266, 448.66166556, 513.8916626 , 669.86433196]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 103\n",
    "print(isolated_trace_df[\"runtime\"].iloc[i])\n",
    "idx = np.argsort(predictions_cfc[i])\n",
    "np.stack((predictions_cfc[i][idx], predictions_sfc[i][idx], predictions_xgb[i][idx], labels[i][idx]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecfeaaa-7e86-4a4d-82a0-f49d2cb593ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = load_json(parsed_queries_path, namespace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07224cb7-e676-461a-a49f-0c59c389d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72a633-e8ed-479a-a85e-83b49e6b0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan[\"parsed_queries\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ab464-9d5e-41e2-818f-b789154d312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255382cb-7340-421a-85a1-3507627c66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.maximum(np.zeros(3), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d81e9aee-f78d-4f9a-b98c-b7000855886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Performance for simple curve fitting model (all query)=============\n",
      "50% absolute error is 9.627042932918474, q-error is 2.4357127503878613\n",
      "90% absolute error is 75.47100542916611, q-error is 15.68507968881842\n",
      "95% absolute error is 123.25611489299501, q-error is 38.380486692719245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziniuw/.local/lib/python3.11/site-packages/scipy/optimize/_minpack_py.py:1010: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n"
     ]
    }
   ],
   "source": [
    "sfc = SimpleFitCurve()\n",
    "sfc.train(concurrency_df.iloc[train_idx], use_train=False, isolated_trace_df=isolated_trace_df)\n",
    "#predictions, labels = sfc.predict(eval_trace_df)\n",
    "#print(\"===========Performance for simple curve fitting model (per query)=============\")\n",
    "#result_overall, result_per_query = sfc.evaluate_performance(eval_trace_df, use_train=True)\n",
    "predictions_sfc, labels = sfc.predict(eval_trace_df, use_global=True)\n",
    "print(\"===========Performance for simple curve fitting model (all query)=============\")\n",
    "result_overall_sfc, result_per_query_sfc = sfc.evaluate_performance(eval_trace_df, use_global=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbd0ee3d-0783-4f1c-b9c6-bb106e1b0f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Performance for XGBoost model (train on full)=============\n",
      "50% absolute error is 9.593931913375854, q-error is 2.605207308176676\n",
      "90% absolute error is 64.77609083652494, q-error is 476.7287504736639\n",
      "95% absolute error is 99.9914370179175, q-error is 1584.1335855509935\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBoostPredictor(k=240)\n",
    "xgb.train(concurrency_df.iloc[train_idx], use_train=False, isolated_trace_df=isolated_trace_df, use_pre_exec_info=True)\n",
    "predictions_xgb, labels = xgb.predict(eval_trace_df)\n",
    "#predictions_xgb, labels = xgb.predict(concurrency_df.iloc[train_idx], use_train=False)\n",
    "print(\"===========Performance for XGBoost model (train on full)=============\")\n",
    "result_overall_xgb, result_per_query_xgb = xgb.evaluate_performance(eval_trace_df)\n",
    "#result_overall_xgb, result_per_query_xgb = xgb.evaluate_performance(concurrency_df.iloc[train_idx], use_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00fa37-c1cd-48bf-ad01-87e8549bc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2ca25-49ba-40ef-b3a7-3b2469d9e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(x, a, b):\n",
    "    return x * a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c14a5-d91f-4cc3-8eec-f1bbdd8f00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (np.ones(3), np.ones(3)+1, np.ones(3)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23c395-0eaa-4f49-b38b-77cb58948ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in a:\n",
    "    b = torch.from_numpy(b)\n",
    "    print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba0372-c2ec-446c-a206-97ea05836647",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (torch.ones(5), torch.ones(5), torch.ones(5))\n",
    "torch.stack(a, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b042f-a495-44ec-a7fd-b1bd2bed9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1 = torch.tensor(self.q1, requires_grad=True)\n",
    "#i1 = torch.tensor(self.i1, requires_grad=True)\n",
    "#i2 = torch.tensor(self.i2, requires_grad=True)\n",
    "#c1 = torch.tensor(self.c1, requires_grad=True)\n",
    "#m1 = torch.tensor(self.m1, requires_grad=True)\n",
    "#m2 = torch.tensor(self.m2, requires_grad=True)\n",
    "#m3 = torch.tensor(self.m3, requires_grad=True)\n",
    "#cm1 = torch.tensor(self.cm1, requires_grad=True)\n",
    "#r1 = torch.tensor(self.r1, requires_grad=True)\n",
    "#r2 = torch.tensor(self.r2, requires_grad=True)\n",
    "#max_concurrency = torch.tensor(self.max_concurrency, requires_grad=True)\n",
    "#avg_io_speed = torch.tensor(self.avg_io_speed, requires_grad=True)\n",
    "#memory_size = torch.tensor(self.memory_size, requires_grad=True)\n",
    "#optimizer = optim.Adam([q1, ], lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
